{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9\n",
    "\n",
    "## Task 1: Toy Problem: Palindrome Numbers\n",
    "\n",
    "### Question 1.1\n",
    "\n",
    "- $W_{hx}$ denotes the **input-to-hidden** weight matrix,\n",
    "- $W_{hh}$ is the **hidden-to-hidden** (or recurrent) weight matrix,\n",
    "- $W_{ph}$ represents the **hidden-to-output** weight matrix and the $b_h$ and $b_p$ vectors denote the biases.\n",
    "\n",
    "Given:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\mathbf{h}^{(t)}=\\tanh(\\mathbf{W}_{hx}\\mathbf{x}^{(t)}+\\mathbf{W}_{hh}\\mathbf{h}^{(t-1)}+\\mathbf{b}_{h})\\\\\n",
    "&\\mathbf{p}^{(t)}=\\mathbf{W}_{ph}\\mathbf{h}^{(t)}+\\mathbf{b}_p \\\\\n",
    "&\\mathcal{L}=-\\sum_{k=1}^K\\mathbf{y}_k\\log\\hat{\\mathbf{y}}_k\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "We can fist assume that $y^{(t)}$ is the softmax of $p^{(t)}$:\n",
    "$$\n",
    "y^{(t)} = \\text{softmax}{(p^{(t)})}\n",
    "$$\n",
    "\n",
    "Also, The gradient of the loss with respect to $p^{(t)}$ is:\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial\\mathbf{p}^{(t)}}=\\hat{\\mathbf{y}}-\\mathbf{y}$$\n",
    "\n",
    "Compute the gradient of $p^{(t)}$ w.r.t. $\\mathbf{W}_{ph}$:\n",
    "\n",
    "$$\n",
    "\\mathbf{p}^{(t)}=\\mathbf{W}_{ph}\\mathbf{h}^{(t)}+\\mathbf{b}_p\n",
    "\\implies \\frac{\\partial\\mathbf{p}^{(t)}}{\\partial\\mathbf{W}_{ph}}=\\mathbf{h}^{(t)}\n",
    "$$\n",
    "\n",
    "Applying the chain rule we get:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\frac{\\partial\\mathcal{L}}{\\partial\\mathbf{W}_{ph}}=\\frac{\\partial\\mathcal{L}}{\\partial\\mathbf{p}^{(t)}}\\cdot\\frac{\\partial\\mathbf{p}^{(t)}}{\\partial\\mathbf{W}_{ph}} \\\\\n",
    "&\\implies \\frac{\\partial\\mathcal{L}}{\\partial\\mathbf{W}_{ph}}=(\\hat{\\mathbf{y}}-\\mathbf{y})\\cdot\\mathbf{h}^{(t)} \\\\\n",
    "&\\implies \\frac{\\partial\\mathcal{L}}{\\partial\\mathbf{W}_{ph}}=\\sum_{t=1}^T(\\hat{\\mathbf{y}}^{(t)}-\\mathbf{y}^{(t)})(\\mathbf{h}^{(t)})^T\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us repeat this for $\\mathbf{W}_{hh}$:\n",
    "\n",
    "We can fist assume that $y^{(t)}$ is the softmax of $p^{(t)}$:\n",
    "$$\n",
    "y^{(t)} = \\text{softmax}{(p^{(t)})}\n",
    "$$\n",
    "\n",
    "Also, The gradient of the loss with respect to $p^{(t)}$ is:\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial\\mathbf{p}^{(t)}}=\\hat{\\mathbf{y}}-\\mathbf{y}$$\n",
    "\n",
    "Compute the gradient of $p^{(t)}$ w.r.t. $\\mathbf{h}^{(t)}$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial\\mathbf{p}^{(t)}}{\\partial\\mathbf{h}^{(t)}}=\\mathbf{W}_{ph}\n",
    "$$\n",
    "\n",
    "Applying the chain rule we get:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial\\mathcal{L}}{\\partial\\mathbf{h}^{(t)}}=\\frac{\\partial\\mathcal{L}}{\\partial\\mathbf{p}^{(t)}}\\cdot\\frac{\\partial\\mathbf{p}^{(t)}}{\\partial\\mathbf{h}^{(t)}}=(\\hat{\\mathbf{y}}^{(t)}-\\mathbf{y}^{(t)})\\mathbf{W}_{ph}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "We can now backpropagate through the tanh non-linearity:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\mathbf{z}^{(t)}=\\mathbf{W}_{hx}\\mathbf{x}^{(t)}+\\mathbf{W}_{hh}\\mathbf{h}^{(t-1)}+\\mathbf{b}_h\\\\\n",
    "&\\mathbf{h}^{(t)}=\\tanh(\\mathbf{z}^{(t)})\\\\\n",
    "&\\implies\\frac{\\partial\\mathbf{h}^{(t)}}{\\partial\\mathbf{z}^{(t)}}=\\operatorname{diag}(1-\\mathbf{h}^{(t)}\\circ\\mathbf{h}^{(t)})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "∘ denotes the Hadamard (element-wise) product\n",
    "\n",
    "Compute the gradient of the loss w.r.t. $z^{(t)}$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\frac{\\partial\\mathcal{L}}{\\partial\\mathbf{z}^{(t)}}=\\frac{\\partial\\mathcal{L}}{\\partial\\mathbf{h}^{(t)}}\\cdot\\frac{\\partial\\mathbf{h}^{(t)}}{\\partial\\mathbf{z}^{(t)}}\\\\&=(\\hat{\\mathbf{y}}^{(t)}-\\mathbf{y}^{(t)})\\mathbf{W}_{ph}\\cdot\\mathrm{diag}(1-\\mathbf{h}^{(t)}\\circ\\mathbf{h}^{(t)})\\\\\n",
    "&\\implies \\frac{\\partial\\mathbf{z}^{(t)}}{\\partial\\mathbf{W}_{hh}}=\\mathbf{h}^{(t-1)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Apply the chain rule to get the gradient of the loss with respect to $\\mathbf{W}_{hh}$:\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial\\mathbf{W}_{hh}}=\\sum_{t=1}^T\\frac{\\partial\\mathcal{L}}{\\partial\\mathbf{z}^{(t)}}\\cdot\\frac{\\partial\\mathbf{z}^{(t)}}{\\partial\\mathbf{W}_{hh}}$$\n",
    "\n",
    "Substitution by computed gradients:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial\\mathcal{L}}{\\partial\\mathbf{W}_{hh}}=\n",
    "\\sum_{t=1}^T\n",
    "[(\\hat{\\mathbf{y}}^{(t)}-\\mathbf{y}^{(t)})\\mathbf{W}_{ph}\\cdot\\mathrm{diag}(1-\\mathbf{h}^{(t)}\\circ\\mathbf{h}^{(t)})]\n",
    "\\cdot\n",
    "\\mathbf{h}^{(t-1)}\n",
    "$$\n",
    "\n",
    "The gradient $\\frac{\\partial\\mathcal{L}}{\\partial\\mathbf{W}_{hh}}$ has a temporal dependency that accumulates over the entire sequence, unlike $\\frac{\\partial\\mathcal{L}}{\\partial\\mathbf{W}_{ph}}$ which depends only on the current time step. This temporal dependency can lead to vanishing or exploding gradients, making it challenging to train RNNs effectively for long sequences. This necessitates techniques like gradient clipping, and specialized architecture like **LSTMs** to address these issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from part1.dataset import PalindromeDataset\n",
    "from part1.train import train\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.model_type = \"RNN\"\n",
    "        self.input_length = 5\n",
    "        self.input_dim = 1\n",
    "        self.num_classes = 10\n",
    "        self.num_hidden = 128\n",
    "        self.batch_size = 128\n",
    "        self.learning_rate = 0.001\n",
    "        self.train_steps = 10000\n",
    "        self.max_norm = 10.0\n",
    "        self.device = \"mps\"\n",
    "\n",
    "config = Config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flyboy/Documents/LMU/SoSe 25/GenAI/Exercise9/part1/train.py:101: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), max_norm=config.max_norm)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-28 08:58] Train Step 0000/10000, Batch Size = 128, Examples/Sec = 552.81, Accuracy = 0.13, Loss = 20.599\n",
      "[2024-06-28 08:58] Train Step 0010/10000, Batch Size = 128, Examples/Sec = 13380.63, Accuracy = 0.16, Loss = 10.547\n",
      "[2024-06-28 08:58] Train Step 0020/10000, Batch Size = 128, Examples/Sec = 13727.91, Accuracy = 0.10, Loss = 9.434\n",
      "[2024-06-28 08:58] Train Step 0030/10000, Batch Size = 128, Examples/Sec = 11652.36, Accuracy = 0.14, Loss = 8.539\n",
      "[2024-06-28 08:58] Train Step 0040/10000, Batch Size = 128, Examples/Sec = 10143.42, Accuracy = 0.15, Loss = 7.898\n",
      "[2024-06-28 08:58] Train Step 0050/10000, Batch Size = 128, Examples/Sec = 12003.28, Accuracy = 0.18, Loss = 7.948\n",
      "[2024-06-28 08:58] Train Step 0060/10000, Batch Size = 128, Examples/Sec = 13341.39, Accuracy = 0.25, Loss = 6.058\n",
      "[2024-06-28 08:58] Train Step 0070/10000, Batch Size = 128, Examples/Sec = 13531.72, Accuracy = 0.23, Loss = 5.621\n",
      "[2024-06-28 08:58] Train Step 0080/10000, Batch Size = 128, Examples/Sec = 13800.24, Accuracy = 0.23, Loss = 4.791\n",
      "[2024-06-28 08:58] Train Step 0090/10000, Batch Size = 128, Examples/Sec = 14532.02, Accuracy = 0.33, Loss = 4.510\n",
      "[2024-06-28 08:58] Train Step 0100/10000, Batch Size = 128, Examples/Sec = 12989.86, Accuracy = 0.31, Loss = 4.488\n",
      "[2024-06-28 08:58] Train Step 0110/10000, Batch Size = 128, Examples/Sec = 14216.10, Accuracy = 0.30, Loss = 4.836\n",
      "[2024-06-28 08:58] Train Step 0120/10000, Batch Size = 128, Examples/Sec = 13362.64, Accuracy = 0.16, Loss = 6.244\n",
      "[2024-06-28 08:58] Train Step 0130/10000, Batch Size = 128, Examples/Sec = 13919.03, Accuracy = 0.34, Loss = 4.211\n",
      "[2024-06-28 08:58] Train Step 0140/10000, Batch Size = 128, Examples/Sec = 14282.28, Accuracy = 0.34, Loss = 3.746\n",
      "[2024-06-28 08:58] Train Step 0150/10000, Batch Size = 128, Examples/Sec = 13433.19, Accuracy = 0.27, Loss = 4.108\n",
      "[2024-06-28 08:58] Train Step 0160/10000, Batch Size = 128, Examples/Sec = 13156.34, Accuracy = 0.36, Loss = 3.882\n",
      "[2024-06-28 08:58] Train Step 0170/10000, Batch Size = 128, Examples/Sec = 13074.64, Accuracy = 0.34, Loss = 3.713\n",
      "[2024-06-28 08:58] Train Step 0180/10000, Batch Size = 128, Examples/Sec = 12503.40, Accuracy = 0.41, Loss = 3.128\n",
      "[2024-06-28 08:58] Train Step 0190/10000, Batch Size = 128, Examples/Sec = 12710.91, Accuracy = 0.34, Loss = 3.809\n",
      "[2024-06-28 08:58] Train Step 0200/10000, Batch Size = 128, Examples/Sec = 12626.91, Accuracy = 0.35, Loss = 3.504\n",
      "[2024-06-28 08:58] Train Step 0210/10000, Batch Size = 128, Examples/Sec = 12997.72, Accuracy = 0.37, Loss = 3.277\n",
      "[2024-06-28 08:58] Train Step 0220/10000, Batch Size = 128, Examples/Sec = 11603.75, Accuracy = 0.39, Loss = 2.866\n",
      "[2024-06-28 08:58] Train Step 0230/10000, Batch Size = 128, Examples/Sec = 13459.46, Accuracy = 0.42, Loss = 2.895\n",
      "[2024-06-28 08:58] Train Step 0240/10000, Batch Size = 128, Examples/Sec = 11619.33, Accuracy = 0.39, Loss = 3.145\n",
      "[2024-06-28 08:58] Train Step 0250/10000, Batch Size = 128, Examples/Sec = 13307.00, Accuracy = 0.35, Loss = 3.230\n",
      "[2024-06-28 08:58] Train Step 0260/10000, Batch Size = 128, Examples/Sec = 12856.72, Accuracy = 0.41, Loss = 2.805\n",
      "[2024-06-28 08:58] Train Step 0270/10000, Batch Size = 128, Examples/Sec = 13220.49, Accuracy = 0.41, Loss = 2.443\n",
      "[2024-06-28 08:58] Train Step 0280/10000, Batch Size = 128, Examples/Sec = 12000.87, Accuracy = 0.41, Loss = 3.020\n",
      "[2024-06-28 08:58] Train Step 0290/10000, Batch Size = 128, Examples/Sec = 12729.90, Accuracy = 0.35, Loss = 2.791\n",
      "[2024-06-28 08:58] Train Step 0300/10000, Batch Size = 128, Examples/Sec = 12842.57, Accuracy = 0.51, Loss = 2.051\n",
      "[2024-06-28 08:58] Train Step 0310/10000, Batch Size = 128, Examples/Sec = 12757.73, Accuracy = 0.44, Loss = 2.751\n",
      "[2024-06-28 08:58] Train Step 0320/10000, Batch Size = 128, Examples/Sec = 12855.18, Accuracy = 0.43, Loss = 2.155\n",
      "[2024-06-28 08:58] Train Step 0330/10000, Batch Size = 128, Examples/Sec = 12427.28, Accuracy = 0.38, Loss = 2.996\n",
      "[2024-06-28 08:58] Train Step 0340/10000, Batch Size = 128, Examples/Sec = 12194.96, Accuracy = 0.48, Loss = 2.115\n",
      "[2024-06-28 08:58] Train Step 0350/10000, Batch Size = 128, Examples/Sec = 12131.58, Accuracy = 0.41, Loss = 2.664\n",
      "[2024-06-28 08:58] Train Step 0360/10000, Batch Size = 128, Examples/Sec = 12982.95, Accuracy = 0.45, Loss = 2.628\n",
      "[2024-06-28 08:58] Train Step 0370/10000, Batch Size = 128, Examples/Sec = 13925.53, Accuracy = 0.41, Loss = 2.356\n",
      "[2024-06-28 08:58] Train Step 0380/10000, Batch Size = 128, Examples/Sec = 14141.95, Accuracy = 0.55, Loss = 2.079\n",
      "[2024-06-28 08:58] Train Step 0390/10000, Batch Size = 128, Examples/Sec = 11533.95, Accuracy = 0.44, Loss = 2.434\n",
      "[2024-06-28 08:58] Train Step 0400/10000, Batch Size = 128, Examples/Sec = 13943.61, Accuracy = 0.45, Loss = 2.489\n",
      "[2024-06-28 08:58] Train Step 0410/10000, Batch Size = 128, Examples/Sec = 14395.25, Accuracy = 0.56, Loss = 1.572\n",
      "[2024-06-28 08:58] Train Step 0420/10000, Batch Size = 128, Examples/Sec = 12947.26, Accuracy = 0.52, Loss = 2.039\n",
      "[2024-06-28 08:58] Train Step 0430/10000, Batch Size = 128, Examples/Sec = 13950.86, Accuracy = 0.52, Loss = 2.273\n",
      "[2024-06-28 08:59] Train Step 0440/10000, Batch Size = 128, Examples/Sec = 14319.23, Accuracy = 0.52, Loss = 1.765\n",
      "[2024-06-28 08:59] Train Step 0450/10000, Batch Size = 128, Examples/Sec = 13516.39, Accuracy = 0.45, Loss = 1.916\n",
      "[2024-06-28 08:59] Train Step 0460/10000, Batch Size = 128, Examples/Sec = 12027.76, Accuracy = 0.52, Loss = 2.285\n",
      "[2024-06-28 08:59] Train Step 0470/10000, Batch Size = 128, Examples/Sec = 11119.71, Accuracy = 0.51, Loss = 2.176\n",
      "[2024-06-28 08:59] Train Step 0480/10000, Batch Size = 128, Examples/Sec = 13202.93, Accuracy = 0.58, Loss = 1.396\n",
      "[2024-06-28 08:59] Train Step 0490/10000, Batch Size = 128, Examples/Sec = 13052.07, Accuracy = 0.48, Loss = 1.946\n",
      "[2024-06-28 08:59] Train Step 0500/10000, Batch Size = 128, Examples/Sec = 12942.26, Accuracy = 0.48, Loss = 1.621\n",
      "[2024-06-28 08:59] Train Step 0510/10000, Batch Size = 128, Examples/Sec = 13799.54, Accuracy = 0.54, Loss = 1.664\n",
      "[2024-06-28 08:59] Train Step 0520/10000, Batch Size = 128, Examples/Sec = 13036.23, Accuracy = 0.60, Loss = 1.432\n",
      "[2024-06-28 08:59] Train Step 0530/10000, Batch Size = 128, Examples/Sec = 12193.85, Accuracy = 0.55, Loss = 1.847\n",
      "[2024-06-28 08:59] Train Step 0540/10000, Batch Size = 128, Examples/Sec = 12473.19, Accuracy = 0.44, Loss = 1.974\n",
      "[2024-06-28 08:59] Train Step 0550/10000, Batch Size = 128, Examples/Sec = 13087.71, Accuracy = 0.51, Loss = 1.806\n",
      "[2024-06-28 08:59] Train Step 0560/10000, Batch Size = 128, Examples/Sec = 13086.43, Accuracy = 0.50, Loss = 1.915\n",
      "[2024-06-28 08:59] Train Step 0570/10000, Batch Size = 128, Examples/Sec = 13715.98, Accuracy = 0.54, Loss = 1.627\n",
      "[2024-06-28 08:59] Train Step 0580/10000, Batch Size = 128, Examples/Sec = 11527.27, Accuracy = 0.41, Loss = 1.921\n",
      "[2024-06-28 08:59] Train Step 0590/10000, Batch Size = 128, Examples/Sec = 12861.65, Accuracy = 0.60, Loss = 1.485\n",
      "[2024-06-28 08:59] Train Step 0600/10000, Batch Size = 128, Examples/Sec = 9920.19, Accuracy = 0.52, Loss = 1.569\n",
      "[2024-06-28 08:59] Train Step 0610/10000, Batch Size = 128, Examples/Sec = 14280.76, Accuracy = 0.56, Loss = 1.344\n",
      "[2024-06-28 08:59] Train Step 0620/10000, Batch Size = 128, Examples/Sec = 12915.18, Accuracy = 0.53, Loss = 1.672\n",
      "[2024-06-28 08:59] Train Step 0630/10000, Batch Size = 128, Examples/Sec = 14138.60, Accuracy = 0.53, Loss = 1.601\n",
      "[2024-06-28 08:59] Train Step 0640/10000, Batch Size = 128, Examples/Sec = 14450.27, Accuracy = 0.61, Loss = 1.175\n",
      "[2024-06-28 08:59] Train Step 0650/10000, Batch Size = 128, Examples/Sec = 12553.98, Accuracy = 0.62, Loss = 1.288\n",
      "[2024-06-28 08:59] Train Step 0660/10000, Batch Size = 128, Examples/Sec = 13791.74, Accuracy = 0.58, Loss = 1.334\n",
      "[2024-06-28 08:59] Train Step 0670/10000, Batch Size = 128, Examples/Sec = 14160.98, Accuracy = 0.59, Loss = 1.594\n",
      "[2024-06-28 08:59] Train Step 0680/10000, Batch Size = 128, Examples/Sec = 14307.78, Accuracy = 0.58, Loss = 1.656\n",
      "[2024-06-28 08:59] Train Step 0690/10000, Batch Size = 128, Examples/Sec = 12074.28, Accuracy = 0.59, Loss = 1.676\n",
      "[2024-06-28 08:59] Train Step 0700/10000, Batch Size = 128, Examples/Sec = 14873.42, Accuracy = 0.55, Loss = 1.484\n",
      "[2024-06-28 08:59] Train Step 0710/10000, Batch Size = 128, Examples/Sec = 14252.33, Accuracy = 0.55, Loss = 1.993\n",
      "[2024-06-28 08:59] Train Step 0720/10000, Batch Size = 128, Examples/Sec = 14378.67, Accuracy = 0.59, Loss = 1.216\n",
      "[2024-06-28 08:59] Train Step 0730/10000, Batch Size = 128, Examples/Sec = 14242.87, Accuracy = 0.59, Loss = 1.640\n",
      "[2024-06-28 08:59] Train Step 0740/10000, Batch Size = 128, Examples/Sec = 14049.06, Accuracy = 0.58, Loss = 1.080\n",
      "[2024-06-28 08:59] Train Step 0750/10000, Batch Size = 128, Examples/Sec = 12774.43, Accuracy = 0.53, Loss = 1.393\n",
      "[2024-06-28 08:59] Train Step 0760/10000, Batch Size = 128, Examples/Sec = 13359.65, Accuracy = 0.54, Loss = 1.545\n",
      "[2024-06-28 08:59] Train Step 0770/10000, Batch Size = 128, Examples/Sec = 13536.49, Accuracy = 0.61, Loss = 1.289\n",
      "[2024-06-28 08:59] Train Step 0780/10000, Batch Size = 128, Examples/Sec = 13441.26, Accuracy = 0.62, Loss = 1.302\n",
      "[2024-06-28 08:59] Train Step 0790/10000, Batch Size = 128, Examples/Sec = 12347.82, Accuracy = 0.59, Loss = 1.338\n",
      "[2024-06-28 08:59] Train Step 0800/10000, Batch Size = 128, Examples/Sec = 5003.36, Accuracy = 0.69, Loss = 1.010\n",
      "[2024-06-28 08:59] Train Step 0810/10000, Batch Size = 128, Examples/Sec = 12677.00, Accuracy = 0.64, Loss = 1.114\n",
      "[2024-06-28 08:59] Train Step 0820/10000, Batch Size = 128, Examples/Sec = 12593.44, Accuracy = 0.66, Loss = 0.935\n",
      "[2024-06-28 08:59] Train Step 0830/10000, Batch Size = 128, Examples/Sec = 13475.00, Accuracy = 0.61, Loss = 1.205\n",
      "[2024-06-28 08:59] Train Step 0840/10000, Batch Size = 128, Examples/Sec = 14754.88, Accuracy = 0.52, Loss = 1.908\n",
      "[2024-06-28 08:59] Train Step 0850/10000, Batch Size = 128, Examples/Sec = 14190.92, Accuracy = 0.73, Loss = 0.910\n",
      "[2024-06-28 08:59] Train Step 0860/10000, Batch Size = 128, Examples/Sec = 14246.28, Accuracy = 0.57, Loss = 1.405\n",
      "[2024-06-28 08:59] Train Step 0870/10000, Batch Size = 128, Examples/Sec = 13932.40, Accuracy = 0.71, Loss = 0.870\n",
      "[2024-06-28 08:59] Train Step 0880/10000, Batch Size = 128, Examples/Sec = 14165.46, Accuracy = 0.70, Loss = 0.866\n",
      "[2024-06-28 08:59] Train Step 0890/10000, Batch Size = 128, Examples/Sec = 13754.99, Accuracy = 0.67, Loss = 1.030\n",
      "[2024-06-28 08:59] Train Step 0900/10000, Batch Size = 128, Examples/Sec = 14173.31, Accuracy = 0.68, Loss = 0.902\n",
      "[2024-06-28 08:59] Train Step 0910/10000, Batch Size = 128, Examples/Sec = 14341.42, Accuracy = 0.66, Loss = 1.010\n",
      "[2024-06-28 08:59] Train Step 0920/10000, Batch Size = 128, Examples/Sec = 12188.32, Accuracy = 0.56, Loss = 1.359\n",
      "[2024-06-28 08:59] Train Step 0930/10000, Batch Size = 128, Examples/Sec = 12688.38, Accuracy = 0.62, Loss = 1.182\n",
      "[2024-06-28 08:59] Train Step 0940/10000, Batch Size = 128, Examples/Sec = 13208.13, Accuracy = 0.70, Loss = 1.007\n",
      "[2024-06-28 08:59] Train Step 0950/10000, Batch Size = 128, Examples/Sec = 14404.91, Accuracy = 0.65, Loss = 0.911\n",
      "[2024-06-28 08:59] Train Step 0960/10000, Batch Size = 128, Examples/Sec = 14159.48, Accuracy = 0.73, Loss = 0.945\n",
      "[2024-06-28 08:59] Train Step 0970/10000, Batch Size = 128, Examples/Sec = 14124.84, Accuracy = 0.66, Loss = 0.974\n",
      "[2024-06-28 08:59] Train Step 0980/10000, Batch Size = 128, Examples/Sec = 13806.63, Accuracy = 0.61, Loss = 1.170\n",
      "[2024-06-28 08:59] Train Step 0990/10000, Batch Size = 128, Examples/Sec = 14249.30, Accuracy = 0.58, Loss = 1.269\n",
      "[2024-06-28 08:59] Train Step 1000/10000, Batch Size = 128, Examples/Sec = 12799.71, Accuracy = 0.57, Loss = 1.214\n",
      "[2024-06-28 08:59] Train Step 1010/10000, Batch Size = 128, Examples/Sec = 14395.25, Accuracy = 0.65, Loss = 0.873\n",
      "[2024-06-28 08:59] Train Step 1020/10000, Batch Size = 128, Examples/Sec = 13753.23, Accuracy = 0.58, Loss = 1.210\n",
      "[2024-06-28 08:59] Train Step 1030/10000, Batch Size = 128, Examples/Sec = 14162.10, Accuracy = 0.71, Loss = 0.758\n",
      "[2024-06-28 08:59] Train Step 1040/10000, Batch Size = 128, Examples/Sec = 14739.48, Accuracy = 0.62, Loss = 1.172\n",
      "[2024-06-28 08:59] Train Step 1050/10000, Batch Size = 128, Examples/Sec = 13881.60, Accuracy = 0.63, Loss = 1.137\n",
      "[2024-06-28 08:59] Train Step 1060/10000, Batch Size = 128, Examples/Sec = 14126.32, Accuracy = 0.77, Loss = 0.838\n",
      "[2024-06-28 08:59] Train Step 1070/10000, Batch Size = 128, Examples/Sec = 13236.79, Accuracy = 0.64, Loss = 0.817\n",
      "[2024-06-28 08:59] Train Step 1080/10000, Batch Size = 128, Examples/Sec = 13373.63, Accuracy = 0.77, Loss = 0.704\n",
      "[2024-06-28 08:59] Train Step 1090/10000, Batch Size = 128, Examples/Sec = 13094.73, Accuracy = 0.70, Loss = 0.967\n",
      "[2024-06-28 08:59] Train Step 1100/10000, Batch Size = 128, Examples/Sec = 14450.27, Accuracy = 0.69, Loss = 0.882\n",
      "[2024-06-28 08:59] Train Step 1110/10000, Batch Size = 128, Examples/Sec = 12168.70, Accuracy = 0.69, Loss = 0.874\n",
      "[2024-06-28 08:59] Train Step 1120/10000, Batch Size = 128, Examples/Sec = 12945.07, Accuracy = 0.78, Loss = 0.549\n",
      "[2024-06-28 08:59] Train Step 1130/10000, Batch Size = 128, Examples/Sec = 12614.45, Accuracy = 0.66, Loss = 1.095\n",
      "[2024-06-28 08:59] Train Step 1140/10000, Batch Size = 128, Examples/Sec = 13145.71, Accuracy = 0.73, Loss = 0.804\n",
      "[2024-06-28 08:59] Train Step 1150/10000, Batch Size = 128, Examples/Sec = 13128.03, Accuracy = 0.80, Loss = 0.594\n",
      "[2024-06-28 08:59] Train Step 1160/10000, Batch Size = 128, Examples/Sec = 12098.23, Accuracy = 0.66, Loss = 0.993\n",
      "[2024-06-28 08:59] Train Step 1170/10000, Batch Size = 128, Examples/Sec = 11562.52, Accuracy = 0.73, Loss = 0.904\n",
      "[2024-06-28 08:59] Train Step 1180/10000, Batch Size = 128, Examples/Sec = 13636.20, Accuracy = 0.73, Loss = 0.802\n",
      "[2024-06-28 08:59] Train Step 1190/10000, Batch Size = 128, Examples/Sec = 13242.34, Accuracy = 0.74, Loss = 0.807\n",
      "[2024-06-28 08:59] Train Step 1200/10000, Batch Size = 128, Examples/Sec = 14017.88, Accuracy = 0.77, Loss = 0.667\n",
      "[2024-06-28 08:59] Train Step 1210/10000, Batch Size = 128, Examples/Sec = 12961.95, Accuracy = 0.75, Loss = 0.681\n",
      "[2024-06-28 08:59] Train Step 1220/10000, Batch Size = 128, Examples/Sec = 13134.78, Accuracy = 0.63, Loss = 1.120\n",
      "[2024-06-28 08:59] Train Step 1230/10000, Batch Size = 128, Examples/Sec = 13565.23, Accuracy = 0.71, Loss = 0.753\n",
      "[2024-06-28 08:59] Train Step 1240/10000, Batch Size = 128, Examples/Sec = 13612.69, Accuracy = 0.75, Loss = 0.710\n",
      "[2024-06-28 08:59] Train Step 1250/10000, Batch Size = 128, Examples/Sec = 13644.87, Accuracy = 0.79, Loss = 0.661\n",
      "[2024-06-28 08:59] Train Step 1260/10000, Batch Size = 128, Examples/Sec = 13873.71, Accuracy = 0.71, Loss = 0.814\n",
      "[2024-06-28 08:59] Train Step 1270/10000, Batch Size = 128, Examples/Sec = 13380.96, Accuracy = 0.65, Loss = 1.025\n",
      "[2024-06-28 08:59] Train Step 1280/10000, Batch Size = 128, Examples/Sec = 13520.47, Accuracy = 0.69, Loss = 0.787\n",
      "[2024-06-28 08:59] Train Step 1290/10000, Batch Size = 128, Examples/Sec = 13921.92, Accuracy = 0.67, Loss = 1.000\n",
      "[2024-06-28 08:59] Train Step 1300/10000, Batch Size = 128, Examples/Sec = 13386.63, Accuracy = 0.73, Loss = 0.848\n",
      "[2024-06-28 08:59] Train Step 1310/10000, Batch Size = 128, Examples/Sec = 14140.09, Accuracy = 0.70, Loss = 0.806\n",
      "[2024-06-28 08:59] Train Step 1320/10000, Batch Size = 128, Examples/Sec = 14625.05, Accuracy = 0.80, Loss = 0.558\n",
      "[2024-06-28 08:59] Train Step 1330/10000, Batch Size = 128, Examples/Sec = 14712.42, Accuracy = 0.75, Loss = 0.664\n",
      "[2024-06-28 08:59] Train Step 1340/10000, Batch Size = 128, Examples/Sec = 14169.95, Accuracy = 0.69, Loss = 0.940\n",
      "[2024-06-28 08:59] Train Step 1350/10000, Batch Size = 128, Examples/Sec = 14849.15, Accuracy = 0.69, Loss = 0.887\n",
      "[2024-06-28 08:59] Train Step 1360/10000, Batch Size = 128, Examples/Sec = 14811.46, Accuracy = 0.72, Loss = 0.732\n",
      "[2024-06-28 08:59] Train Step 1370/10000, Batch Size = 128, Examples/Sec = 14743.13, Accuracy = 0.84, Loss = 0.553\n",
      "[2024-06-28 08:59] Train Step 1380/10000, Batch Size = 128, Examples/Sec = 10773.40, Accuracy = 0.77, Loss = 0.688\n",
      "[2024-06-28 08:59] Train Step 1390/10000, Batch Size = 128, Examples/Sec = 14149.78, Accuracy = 0.72, Loss = 0.840\n",
      "[2024-06-28 08:59] Train Step 1400/10000, Batch Size = 128, Examples/Sec = 14340.27, Accuracy = 0.77, Loss = 0.648\n",
      "[2024-06-28 08:59] Train Step 1410/10000, Batch Size = 128, Examples/Sec = 14813.09, Accuracy = 0.73, Loss = 0.746\n",
      "[2024-06-28 08:59] Train Step 1420/10000, Batch Size = 128, Examples/Sec = 14542.65, Accuracy = 0.72, Loss = 0.657\n",
      "[2024-06-28 08:59] Train Step 1430/10000, Batch Size = 128, Examples/Sec = 14522.19, Accuracy = 0.76, Loss = 0.633\n",
      "[2024-06-28 08:59] Train Step 1440/10000, Batch Size = 128, Examples/Sec = 14911.01, Accuracy = 0.73, Loss = 0.753\n",
      "[2024-06-28 08:59] Train Step 1450/10000, Batch Size = 128, Examples/Sec = 14295.59, Accuracy = 0.77, Loss = 0.755\n",
      "[2024-06-28 08:59] Train Step 1460/10000, Batch Size = 128, Examples/Sec = 13996.32, Accuracy = 0.76, Loss = 0.563\n",
      "[2024-06-28 08:59] Train Step 1470/10000, Batch Size = 128, Examples/Sec = 14753.66, Accuracy = 0.89, Loss = 0.382\n",
      "[2024-06-28 08:59] Train Step 1480/10000, Batch Size = 128, Examples/Sec = 14295.21, Accuracy = 0.73, Loss = 0.870\n",
      "[2024-06-28 08:59] Train Step 1490/10000, Batch Size = 128, Examples/Sec = 14437.06, Accuracy = 0.80, Loss = 0.675\n",
      "[2024-06-28 08:59] Train Step 1500/10000, Batch Size = 128, Examples/Sec = 12092.50, Accuracy = 0.80, Loss = 0.542\n",
      "[2024-06-28 08:59] Train Step 1510/10000, Batch Size = 128, Examples/Sec = 13135.10, Accuracy = 0.71, Loss = 0.812\n",
      "[2024-06-28 08:59] Train Step 1520/10000, Batch Size = 128, Examples/Sec = 13401.67, Accuracy = 0.73, Loss = 0.646\n",
      "[2024-06-28 08:59] Train Step 1530/10000, Batch Size = 128, Examples/Sec = 14058.26, Accuracy = 0.74, Loss = 0.629\n",
      "[2024-06-28 08:59] Train Step 1540/10000, Batch Size = 128, Examples/Sec = 13590.98, Accuracy = 0.79, Loss = 0.607\n",
      "[2024-06-28 08:59] Train Step 1550/10000, Batch Size = 128, Examples/Sec = 12532.00, Accuracy = 0.79, Loss = 0.620\n",
      "[2024-06-28 08:59] Train Step 1560/10000, Batch Size = 128, Examples/Sec = 10966.40, Accuracy = 0.64, Loss = 0.864\n",
      "[2024-06-28 08:59] Train Step 1570/10000, Batch Size = 128, Examples/Sec = 13256.07, Accuracy = 0.74, Loss = 0.734\n",
      "[2024-06-28 08:59] Train Step 1580/10000, Batch Size = 128, Examples/Sec = 13873.71, Accuracy = 0.77, Loss = 0.590\n",
      "[2024-06-28 08:59] Train Step 1590/10000, Batch Size = 128, Examples/Sec = 13890.22, Accuracy = 0.69, Loss = 0.876\n",
      "[2024-06-28 08:59] Train Step 1600/10000, Batch Size = 128, Examples/Sec = 14456.89, Accuracy = 0.73, Loss = 0.878\n",
      "[2024-06-28 08:59] Train Step 1610/10000, Batch Size = 128, Examples/Sec = 13995.59, Accuracy = 0.90, Loss = 0.322\n",
      "[2024-06-28 08:59] Train Step 1620/10000, Batch Size = 128, Examples/Sec = 12651.90, Accuracy = 0.65, Loss = 1.083\n",
      "[2024-06-28 08:59] Train Step 1630/10000, Batch Size = 128, Examples/Sec = 10363.50, Accuracy = 0.77, Loss = 0.650\n",
      "[2024-06-28 08:59] Train Step 1640/10000, Batch Size = 128, Examples/Sec = 12308.75, Accuracy = 0.70, Loss = 0.794\n",
      "[2024-06-28 08:59] Train Step 1650/10000, Batch Size = 128, Examples/Sec = 12464.79, Accuracy = 0.84, Loss = 0.449\n",
      "[2024-06-28 08:59] Train Step 1660/10000, Batch Size = 128, Examples/Sec = 12077.54, Accuracy = 0.74, Loss = 0.653\n",
      "[2024-06-28 08:59] Train Step 1670/10000, Batch Size = 128, Examples/Sec = 12740.17, Accuracy = 0.75, Loss = 0.681\n",
      "[2024-06-28 08:59] Train Step 1680/10000, Batch Size = 128, Examples/Sec = 11604.76, Accuracy = 0.77, Loss = 0.556\n",
      "[2024-06-28 08:59] Train Step 1690/10000, Batch Size = 128, Examples/Sec = 12440.24, Accuracy = 0.80, Loss = 0.582\n",
      "[2024-06-28 08:59] Train Step 1700/10000, Batch Size = 128, Examples/Sec = 10309.37, Accuracy = 0.78, Loss = 0.570\n",
      "[2024-06-28 08:59] Train Step 1710/10000, Batch Size = 128, Examples/Sec = 12506.02, Accuracy = 0.72, Loss = 0.826\n",
      "[2024-06-28 08:59] Train Step 1720/10000, Batch Size = 128, Examples/Sec = 11205.35, Accuracy = 0.80, Loss = 0.623\n",
      "[2024-06-28 08:59] Train Step 1730/10000, Batch Size = 128, Examples/Sec = 13490.57, Accuracy = 0.68, Loss = 0.830\n",
      "[2024-06-28 08:59] Train Step 1740/10000, Batch Size = 128, Examples/Sec = 12346.97, Accuracy = 0.83, Loss = 0.416\n",
      "[2024-06-28 08:59] Train Step 1750/10000, Batch Size = 128, Examples/Sec = 12255.93, Accuracy = 0.85, Loss = 0.355\n",
      "[2024-06-28 08:59] Train Step 1760/10000, Batch Size = 128, Examples/Sec = 12698.59, Accuracy = 0.74, Loss = 0.706\n",
      "[2024-06-28 08:59] Train Step 1770/10000, Batch Size = 128, Examples/Sec = 11950.38, Accuracy = 0.77, Loss = 0.582\n",
      "[2024-06-28 08:59] Train Step 1780/10000, Batch Size = 128, Examples/Sec = 13151.19, Accuracy = 0.81, Loss = 0.491\n",
      "[2024-06-28 08:59] Train Step 1790/10000, Batch Size = 128, Examples/Sec = 12968.52, Accuracy = 0.71, Loss = 0.870\n",
      "[2024-06-28 08:59] Train Step 1800/10000, Batch Size = 128, Examples/Sec = 13967.56, Accuracy = 0.79, Loss = 0.593\n",
      "[2024-06-28 08:59] Train Step 1810/10000, Batch Size = 128, Examples/Sec = 14224.01, Accuracy = 0.80, Loss = 0.638\n",
      "[2024-06-28 08:59] Train Step 1820/10000, Batch Size = 128, Examples/Sec = 12430.73, Accuracy = 0.79, Loss = 0.614\n",
      "[2024-06-28 08:59] Train Step 1830/10000, Batch Size = 128, Examples/Sec = 13250.18, Accuracy = 0.86, Loss = 0.358\n",
      "[2024-06-28 08:59] Train Step 1840/10000, Batch Size = 128, Examples/Sec = 12788.73, Accuracy = 0.88, Loss = 0.321\n",
      "[2024-06-28 08:59] Train Step 1850/10000, Batch Size = 128, Examples/Sec = 13788.55, Accuracy = 0.81, Loss = 0.523\n",
      "[2024-06-28 08:59] Train Step 1860/10000, Batch Size = 128, Examples/Sec = 10630.48, Accuracy = 0.82, Loss = 0.536\n",
      "[2024-06-28 08:59] Train Step 1870/10000, Batch Size = 128, Examples/Sec = 12253.41, Accuracy = 0.81, Loss = 0.553\n",
      "[2024-06-28 08:59] Train Step 1880/10000, Batch Size = 128, Examples/Sec = 12833.06, Accuracy = 0.80, Loss = 0.611\n",
      "[2024-06-28 08:59] Train Step 1890/10000, Batch Size = 128, Examples/Sec = 11797.29, Accuracy = 0.88, Loss = 0.445\n",
      "[2024-06-28 08:59] Train Step 1900/10000, Batch Size = 128, Examples/Sec = 10135.95, Accuracy = 0.88, Loss = 0.437\n",
      "[2024-06-28 08:59] Train Step 1910/10000, Batch Size = 128, Examples/Sec = 12207.99, Accuracy = 0.88, Loss = 0.375\n",
      "[2024-06-28 08:59] Train Step 1920/10000, Batch Size = 128, Examples/Sec = 13851.16, Accuracy = 0.84, Loss = 0.414\n",
      "[2024-06-28 08:59] Train Step 1930/10000, Batch Size = 128, Examples/Sec = 12897.80, Accuracy = 0.85, Loss = 0.461\n",
      "[2024-06-28 08:59] Train Step 1940/10000, Batch Size = 128, Examples/Sec = 11372.70, Accuracy = 0.79, Loss = 0.719\n",
      "[2024-06-28 08:59] Train Step 1950/10000, Batch Size = 128, Examples/Sec = 12884.80, Accuracy = 0.81, Loss = 0.461\n",
      "[2024-06-28 08:59] Train Step 1960/10000, Batch Size = 128, Examples/Sec = 14582.15, Accuracy = 0.84, Loss = 0.424\n",
      "[2024-06-28 08:59] Train Step 1970/10000, Batch Size = 128, Examples/Sec = 14228.53, Accuracy = 0.84, Loss = 0.408\n",
      "[2024-06-28 08:59] Train Step 1980/10000, Batch Size = 128, Examples/Sec = 12050.43, Accuracy = 0.90, Loss = 0.336\n",
      "[2024-06-28 08:59] Train Step 1990/10000, Batch Size = 128, Examples/Sec = 10915.78, Accuracy = 0.83, Loss = 0.521\n",
      "[2024-06-28 08:59] Train Step 2000/10000, Batch Size = 128, Examples/Sec = 11118.79, Accuracy = 0.77, Loss = 0.675\n",
      "[2024-06-28 08:59] Train Step 2010/10000, Batch Size = 128, Examples/Sec = 11133.32, Accuracy = 0.81, Loss = 0.667\n",
      "[2024-06-28 08:59] Train Step 2020/10000, Batch Size = 128, Examples/Sec = 13651.81, Accuracy = 0.85, Loss = 0.372\n",
      "[2024-06-28 08:59] Train Step 2030/10000, Batch Size = 128, Examples/Sec = 9949.42, Accuracy = 0.84, Loss = 0.433\n",
      "[2024-06-28 08:59] Train Step 2040/10000, Batch Size = 128, Examples/Sec = 11170.15, Accuracy = 0.86, Loss = 0.467\n",
      "[2024-06-28 08:59] Train Step 2050/10000, Batch Size = 128, Examples/Sec = 13160.86, Accuracy = 0.76, Loss = 0.494\n",
      "[2024-06-28 08:59] Train Step 2060/10000, Batch Size = 128, Examples/Sec = 12760.46, Accuracy = 0.85, Loss = 0.413\n",
      "[2024-06-28 08:59] Train Step 2070/10000, Batch Size = 128, Examples/Sec = 13717.73, Accuracy = 0.73, Loss = 0.636\n",
      "[2024-06-28 08:59] Train Step 2080/10000, Batch Size = 128, Examples/Sec = 14108.88, Accuracy = 0.84, Loss = 0.405\n",
      "[2024-06-28 08:59] Train Step 2090/10000, Batch Size = 128, Examples/Sec = 13774.04, Accuracy = 0.80, Loss = 0.476\n",
      "[2024-06-28 08:59] Train Step 2100/10000, Batch Size = 128, Examples/Sec = 14149.78, Accuracy = 0.88, Loss = 0.385\n",
      "[2024-06-28 08:59] Train Step 2110/10000, Batch Size = 128, Examples/Sec = 14303.59, Accuracy = 0.88, Loss = 0.278\n",
      "[2024-06-28 08:59] Train Step 2120/10000, Batch Size = 128, Examples/Sec = 12937.27, Accuracy = 0.78, Loss = 0.508\n",
      "[2024-06-28 08:59] Train Step 2130/10000, Batch Size = 128, Examples/Sec = 14137.48, Accuracy = 0.90, Loss = 0.324\n",
      "[2024-06-28 08:59] Train Step 2140/10000, Batch Size = 128, Examples/Sec = 12550.16, Accuracy = 0.82, Loss = 0.583\n",
      "[2024-06-28 08:59] Train Step 2150/10000, Batch Size = 128, Examples/Sec = 13982.83, Accuracy = 0.80, Loss = 0.519\n",
      "[2024-06-28 08:59] Train Step 2160/10000, Batch Size = 128, Examples/Sec = 14233.43, Accuracy = 0.80, Loss = 0.488\n",
      "[2024-06-28 08:59] Train Step 2170/10000, Batch Size = 128, Examples/Sec = 13541.96, Accuracy = 0.83, Loss = 0.498\n",
      "[2024-06-28 08:59] Train Step 2180/10000, Batch Size = 128, Examples/Sec = 14247.41, Accuracy = 0.86, Loss = 0.346\n",
      "[2024-06-28 08:59] Train Step 2190/10000, Batch Size = 128, Examples/Sec = 13685.21, Accuracy = 0.71, Loss = 0.733\n",
      "[2024-06-28 08:59] Train Step 2200/10000, Batch Size = 128, Examples/Sec = 12683.29, Accuracy = 0.81, Loss = 0.595\n",
      "[2024-06-28 08:59] Train Step 2210/10000, Batch Size = 128, Examples/Sec = 12319.49, Accuracy = 0.91, Loss = 0.259\n",
      "[2024-06-28 08:59] Train Step 2220/10000, Batch Size = 128, Examples/Sec = 10302.45, Accuracy = 0.88, Loss = 0.375\n",
      "[2024-06-28 08:59] Train Step 2230/10000, Batch Size = 128, Examples/Sec = 12272.46, Accuracy = 0.75, Loss = 0.624\n",
      "[2024-06-28 08:59] Train Step 2240/10000, Batch Size = 128, Examples/Sec = 14563.56, Accuracy = 0.81, Loss = 0.517\n",
      "[2024-06-28 08:59] Train Step 2250/10000, Batch Size = 128, Examples/Sec = 10278.78, Accuracy = 0.85, Loss = 0.404\n",
      "[2024-06-28 08:59] Train Step 2260/10000, Batch Size = 128, Examples/Sec = 13452.38, Accuracy = 0.88, Loss = 0.364\n",
      "[2024-06-28 08:59] Train Step 2270/10000, Batch Size = 128, Examples/Sec = 13304.36, Accuracy = 0.80, Loss = 0.475\n",
      "[2024-06-28 08:59] Train Step 2280/10000, Batch Size = 128, Examples/Sec = 13075.60, Accuracy = 0.90, Loss = 0.312\n",
      "[2024-06-28 08:59] Train Step 2290/10000, Batch Size = 128, Examples/Sec = 14082.97, Accuracy = 0.78, Loss = 0.456\n",
      "[2024-06-28 08:59] Train Step 2300/10000, Batch Size = 128, Examples/Sec = 13037.18, Accuracy = 0.90, Loss = 0.286\n",
      "[2024-06-28 08:59] Train Step 2310/10000, Batch Size = 128, Examples/Sec = 13191.90, Accuracy = 0.90, Loss = 0.282\n",
      "[2024-06-28 08:59] Train Step 2320/10000, Batch Size = 128, Examples/Sec = 12652.20, Accuracy = 0.86, Loss = 0.327\n",
      "[2024-06-28 08:59] Train Step 2330/10000, Batch Size = 128, Examples/Sec = 13135.10, Accuracy = 0.93, Loss = 0.257\n",
      "[2024-06-28 08:59] Train Step 2340/10000, Batch Size = 128, Examples/Sec = 12433.32, Accuracy = 0.92, Loss = 0.215\n",
      "[2024-06-28 08:59] Train Step 2350/10000, Batch Size = 128, Examples/Sec = 10337.56, Accuracy = 0.93, Loss = 0.241\n",
      "[2024-06-28 08:59] Train Step 2360/10000, Batch Size = 128, Examples/Sec = 13965.74, Accuracy = 0.69, Loss = 1.105\n",
      "[2024-06-28 08:59] Train Step 2370/10000, Batch Size = 128, Examples/Sec = 14555.26, Accuracy = 0.72, Loss = 0.828\n",
      "[2024-06-28 08:59] Train Step 2380/10000, Batch Size = 128, Examples/Sec = 13417.41, Accuracy = 0.71, Loss = 1.019\n",
      "[2024-06-28 08:59] Train Step 2390/10000, Batch Size = 128, Examples/Sec = 13883.04, Accuracy = 0.73, Loss = 0.849\n",
      "[2024-06-28 08:59] Train Step 2400/10000, Batch Size = 128, Examples/Sec = 14324.20, Accuracy = 0.71, Loss = 0.701\n",
      "[2024-06-28 08:59] Train Step 2410/10000, Batch Size = 128, Examples/Sec = 13476.35, Accuracy = 0.82, Loss = 0.556\n",
      "[2024-06-28 08:59] Train Step 2420/10000, Batch Size = 128, Examples/Sec = 12197.45, Accuracy = 0.88, Loss = 0.365\n",
      "[2024-06-28 08:59] Train Step 2430/10000, Batch Size = 128, Examples/Sec = 14167.33, Accuracy = 0.86, Loss = 0.457\n",
      "[2024-06-28 08:59] Train Step 2440/10000, Batch Size = 128, Examples/Sec = 13744.07, Accuracy = 0.85, Loss = 0.443\n",
      "[2024-06-28 08:59] Train Step 2450/10000, Batch Size = 128, Examples/Sec = 11683.04, Accuracy = 0.84, Loss = 0.421\n",
      "[2024-06-28 08:59] Train Step 2460/10000, Batch Size = 128, Examples/Sec = 12900.59, Accuracy = 0.92, Loss = 0.266\n",
      "[2024-06-28 08:59] Train Step 2470/10000, Batch Size = 128, Examples/Sec = 12496.41, Accuracy = 0.85, Loss = 0.413\n",
      "[2024-06-28 08:59] Train Step 2480/10000, Batch Size = 128, Examples/Sec = 13960.29, Accuracy = 0.84, Loss = 0.305\n",
      "[2024-06-28 08:59] Train Step 2490/10000, Batch Size = 128, Examples/Sec = 14523.76, Accuracy = 0.89, Loss = 0.357\n",
      "[2024-06-28 08:59] Train Step 2500/10000, Batch Size = 128, Examples/Sec = 13414.73, Accuracy = 0.80, Loss = 0.633\n",
      "[2024-06-28 08:59] Train Step 2510/10000, Batch Size = 128, Examples/Sec = 12254.53, Accuracy = 0.87, Loss = 0.402\n",
      "[2024-06-28 08:59] Train Step 2520/10000, Batch Size = 128, Examples/Sec = 12816.82, Accuracy = 0.72, Loss = 1.071\n",
      "[2024-06-28 08:59] Train Step 2530/10000, Batch Size = 128, Examples/Sec = 12335.05, Accuracy = 0.93, Loss = 0.243\n",
      "[2024-06-28 08:59] Train Step 2540/10000, Batch Size = 128, Examples/Sec = 13489.56, Accuracy = 0.93, Loss = 0.297\n",
      "[2024-06-28 08:59] Train Step 2550/10000, Batch Size = 128, Examples/Sec = 12675.80, Accuracy = 0.80, Loss = 0.510\n",
      "[2024-06-28 08:59] Train Step 2560/10000, Batch Size = 128, Examples/Sec = 13829.04, Accuracy = 0.88, Loss = 0.460\n",
      "[2024-06-28 08:59] Train Step 2570/10000, Batch Size = 128, Examples/Sec = 12351.80, Accuracy = 0.83, Loss = 0.527\n",
      "[2024-06-28 08:59] Train Step 2580/10000, Batch Size = 128, Examples/Sec = 14979.66, Accuracy = 0.93, Loss = 0.247\n",
      "[2024-06-28 08:59] Train Step 2590/10000, Batch Size = 128, Examples/Sec = 14414.58, Accuracy = 0.88, Loss = 0.298\n",
      "[2024-06-28 08:59] Train Step 2600/10000, Batch Size = 128, Examples/Sec = 14828.23, Accuracy = 0.94, Loss = 0.225\n",
      "[2024-06-28 08:59] Train Step 2610/10000, Batch Size = 128, Examples/Sec = 14050.53, Accuracy = 0.94, Loss = 0.234\n",
      "[2024-06-28 08:59] Train Step 2620/10000, Batch Size = 128, Examples/Sec = 14343.33, Accuracy = 0.88, Loss = 0.384\n",
      "[2024-06-28 08:59] Train Step 2630/10000, Batch Size = 128, Examples/Sec = 14052.37, Accuracy = 0.84, Loss = 0.572\n",
      "[2024-06-28 08:59] Train Step 2640/10000, Batch Size = 128, Examples/Sec = 15016.11, Accuracy = 0.84, Loss = 0.455\n",
      "[2024-06-28 08:59] Train Step 2650/10000, Batch Size = 128, Examples/Sec = 15049.78, Accuracy = 0.83, Loss = 0.420\n",
      "[2024-06-28 08:59] Train Step 2660/10000, Batch Size = 128, Examples/Sec = 14417.29, Accuracy = 0.91, Loss = 0.270\n",
      "[2024-06-28 08:59] Train Step 2670/10000, Batch Size = 128, Examples/Sec = 12745.01, Accuracy = 0.94, Loss = 0.215\n",
      "[2024-06-28 08:59] Train Step 2680/10000, Batch Size = 128, Examples/Sec = 14414.96, Accuracy = 0.90, Loss = 0.303\n",
      "[2024-06-28 08:59] Train Step 2690/10000, Batch Size = 128, Examples/Sec = 14066.00, Accuracy = 0.84, Loss = 0.452\n",
      "[2024-06-28 08:59] Train Step 2700/10000, Batch Size = 128, Examples/Sec = 14988.44, Accuracy = 0.78, Loss = 0.836\n",
      "[2024-06-28 08:59] Train Step 2710/10000, Batch Size = 128, Examples/Sec = 14269.75, Accuracy = 0.70, Loss = 0.834\n",
      "[2024-06-28 08:59] Train Step 2720/10000, Batch Size = 128, Examples/Sec = 14091.10, Accuracy = 0.87, Loss = 0.245\n",
      "[2024-06-28 08:59] Train Step 2730/10000, Batch Size = 128, Examples/Sec = 14233.43, Accuracy = 0.92, Loss = 0.220\n",
      "[2024-06-28 08:59] Train Step 2740/10000, Batch Size = 128, Examples/Sec = 14600.39, Accuracy = 0.91, Loss = 0.279\n",
      "[2024-06-28 08:59] Train Step 2750/10000, Batch Size = 128, Examples/Sec = 13302.71, Accuracy = 0.95, Loss = 0.183\n",
      "[2024-06-28 08:59] Train Step 2760/10000, Batch Size = 128, Examples/Sec = 14332.23, Accuracy = 0.93, Loss = 0.216\n",
      "[2024-06-28 08:59] Train Step 2770/10000, Batch Size = 128, Examples/Sec = 14319.23, Accuracy = 0.95, Loss = 0.185\n",
      "[2024-06-28 08:59] Train Step 2780/10000, Batch Size = 128, Examples/Sec = 11903.48, Accuracy = 0.95, Loss = 0.182\n",
      "[2024-06-28 08:59] Train Step 2790/10000, Batch Size = 128, Examples/Sec = 14432.01, Accuracy = 0.82, Loss = 0.439\n",
      "[2024-06-28 08:59] Train Step 2800/10000, Batch Size = 128, Examples/Sec = 14284.18, Accuracy = 0.83, Loss = 0.457\n",
      "[2024-06-28 08:59] Train Step 2810/10000, Batch Size = 128, Examples/Sec = 13155.05, Accuracy = 0.82, Loss = 0.552\n",
      "[2024-06-28 08:59] Train Step 2820/10000, Batch Size = 128, Examples/Sec = 14873.42, Accuracy = 0.85, Loss = 0.455\n",
      "[2024-06-28 08:59] Train Step 2830/10000, Batch Size = 128, Examples/Sec = 14325.73, Accuracy = 0.96, Loss = 0.161\n",
      "[2024-06-28 08:59] Train Step 2840/10000, Batch Size = 128, Examples/Sec = 14613.50, Accuracy = 0.90, Loss = 0.278\n",
      "[2024-06-28 08:59] Train Step 2850/10000, Batch Size = 128, Examples/Sec = 14613.11, Accuracy = 0.84, Loss = 0.588\n",
      "[2024-06-28 08:59] Train Step 2860/10000, Batch Size = 128, Examples/Sec = 13815.51, Accuracy = 0.83, Loss = 0.394\n",
      "[2024-06-28 08:59] Train Step 2870/10000, Batch Size = 128, Examples/Sec = 14084.45, Accuracy = 0.82, Loss = 0.401\n",
      "[2024-06-28 08:59] Train Step 2880/10000, Batch Size = 128, Examples/Sec = 13002.76, Accuracy = 0.95, Loss = 0.236\n",
      "[2024-06-28 08:59] Train Step 2890/10000, Batch Size = 128, Examples/Sec = 14105.91, Accuracy = 0.95, Loss = 0.187\n",
      "[2024-06-28 08:59] Train Step 2900/10000, Batch Size = 128, Examples/Sec = 13847.94, Accuracy = 0.88, Loss = 0.371\n",
      "[2024-06-28 08:59] Train Step 2910/10000, Batch Size = 128, Examples/Sec = 13234.18, Accuracy = 0.91, Loss = 0.254\n",
      "[2024-06-28 08:59] Train Step 2920/10000, Batch Size = 128, Examples/Sec = 14773.96, Accuracy = 0.98, Loss = 0.135\n",
      "[2024-06-28 08:59] Train Step 2930/10000, Batch Size = 128, Examples/Sec = 13852.95, Accuracy = 0.92, Loss = 0.266\n",
      "[2024-06-28 08:59] Train Step 2940/10000, Batch Size = 128, Examples/Sec = 14429.30, Accuracy = 0.95, Loss = 0.217\n",
      "[2024-06-28 08:59] Train Step 2950/10000, Batch Size = 128, Examples/Sec = 14092.21, Accuracy = 0.92, Loss = 0.240\n",
      "[2024-06-28 08:59] Train Step 2960/10000, Batch Size = 128, Examples/Sec = 14442.11, Accuracy = 0.93, Loss = 0.212\n",
      "[2024-06-28 08:59] Train Step 2970/10000, Batch Size = 128, Examples/Sec = 13062.55, Accuracy = 0.95, Loss = 0.162\n",
      "[2024-06-28 08:59] Train Step 2980/10000, Batch Size = 128, Examples/Sec = 13958.48, Accuracy = 0.89, Loss = 0.333\n",
      "[2024-06-28 08:59] Train Step 2990/10000, Batch Size = 128, Examples/Sec = 13147.00, Accuracy = 0.70, Loss = 1.033\n",
      "[2024-06-28 08:59] Train Step 3000/10000, Batch Size = 128, Examples/Sec = 13762.04, Accuracy = 0.77, Loss = 0.780\n",
      "[2024-06-28 08:59] Train Step 3010/10000, Batch Size = 128, Examples/Sec = 12971.34, Accuracy = 0.77, Loss = 0.488\n",
      "[2024-06-28 08:59] Train Step 3020/10000, Batch Size = 128, Examples/Sec = 13783.95, Accuracy = 0.80, Loss = 0.457\n",
      "[2024-06-28 08:59] Train Step 3030/10000, Batch Size = 128, Examples/Sec = 14118.89, Accuracy = 0.95, Loss = 0.208\n",
      "[2024-06-28 08:59] Train Step 3040/10000, Batch Size = 128, Examples/Sec = 12546.35, Accuracy = 0.98, Loss = 0.152\n",
      "[2024-06-28 08:59] Train Step 3050/10000, Batch Size = 128, Examples/Sec = 14944.63, Accuracy = 0.99, Loss = 0.103\n",
      "[2024-06-28 08:59] Train Step 3060/10000, Batch Size = 128, Examples/Sec = 14109.25, Accuracy = 0.95, Loss = 0.176\n",
      "[2024-06-28 08:59] Train Step 3070/10000, Batch Size = 128, Examples/Sec = 13747.24, Accuracy = 0.97, Loss = 0.159\n",
      "[2024-06-28 08:59] Train Step 3080/10000, Batch Size = 128, Examples/Sec = 11862.45, Accuracy = 0.92, Loss = 0.260\n",
      "[2024-06-28 08:59] Train Step 3090/10000, Batch Size = 128, Examples/Sec = 13319.55, Accuracy = 0.87, Loss = 0.374\n",
      "[2024-06-28 08:59] Train Step 3100/10000, Batch Size = 128, Examples/Sec = 14408.00, Accuracy = 0.88, Loss = 0.335\n",
      "[2024-06-28 08:59] Train Step 3110/10000, Batch Size = 128, Examples/Sec = 14148.66, Accuracy = 0.88, Loss = 0.279\n",
      "[2024-06-28 08:59] Train Step 3120/10000, Batch Size = 128, Examples/Sec = 13727.91, Accuracy = 0.94, Loss = 0.269\n",
      "[2024-06-28 08:59] Train Step 3130/10000, Batch Size = 128, Examples/Sec = 13422.78, Accuracy = 0.95, Loss = 0.220\n",
      "[2024-06-28 08:59] Train Step 3140/10000, Batch Size = 128, Examples/Sec = 12257.05, Accuracy = 0.90, Loss = 0.432\n",
      "[2024-06-28 08:59] Train Step 3150/10000, Batch Size = 128, Examples/Sec = 13275.08, Accuracy = 0.91, Loss = 0.312\n",
      "[2024-06-28 08:59] Train Step 3160/10000, Batch Size = 128, Examples/Sec = 13175.39, Accuracy = 0.92, Loss = 0.271\n",
      "[2024-06-28 08:59] Train Step 3170/10000, Batch Size = 128, Examples/Sec = 13350.02, Accuracy = 0.99, Loss = 0.152\n",
      "[2024-06-28 08:59] Train Step 3180/10000, Batch Size = 128, Examples/Sec = 13610.97, Accuracy = 0.89, Loss = 0.291\n",
      "[2024-06-28 08:59] Train Step 3190/10000, Batch Size = 128, Examples/Sec = 12199.67, Accuracy = 0.87, Loss = 0.481\n",
      "[2024-06-28 08:59] Train Step 3200/10000, Batch Size = 128, Examples/Sec = 12096.05, Accuracy = 0.81, Loss = 0.565\n",
      "[2024-06-28 08:59] Train Step 3210/10000, Batch Size = 128, Examples/Sec = 13941.80, Accuracy = 0.80, Loss = 0.540\n",
      "[2024-06-28 08:59] Train Step 3220/10000, Batch Size = 128, Examples/Sec = 12684.79, Accuracy = 0.96, Loss = 0.187\n",
      "[2024-06-28 08:59] Train Step 3230/10000, Batch Size = 128, Examples/Sec = 13372.30, Accuracy = 0.85, Loss = 0.382\n",
      "[2024-06-28 08:59] Train Step 3240/10000, Batch Size = 128, Examples/Sec = 13901.01, Accuracy = 0.73, Loss = 1.168\n",
      "[2024-06-28 08:59] Train Step 3250/10000, Batch Size = 128, Examples/Sec = 13556.66, Accuracy = 0.89, Loss = 0.246\n",
      "[2024-06-28 08:59] Train Step 3260/10000, Batch Size = 128, Examples/Sec = 12246.14, Accuracy = 0.97, Loss = 0.152\n",
      "[2024-06-28 08:59] Train Step 3270/10000, Batch Size = 128, Examples/Sec = 13566.60, Accuracy = 0.94, Loss = 0.161\n",
      "[2024-06-28 08:59] Train Step 3280/10000, Batch Size = 128, Examples/Sec = 12966.33, Accuracy = 0.94, Loss = 0.197\n",
      "[2024-06-28 08:59] Train Step 3290/10000, Batch Size = 128, Examples/Sec = 12920.15, Accuracy = 0.91, Loss = 0.366\n",
      "[2024-06-28 08:59] Train Step 3300/10000, Batch Size = 128, Examples/Sec = 14320.76, Accuracy = 0.89, Loss = 0.302\n",
      "[2024-06-28 08:59] Train Step 3310/10000, Batch Size = 128, Examples/Sec = 14231.55, Accuracy = 0.88, Loss = 0.433\n",
      "[2024-06-28 08:59] Train Step 3320/10000, Batch Size = 128, Examples/Sec = 13155.38, Accuracy = 0.95, Loss = 0.183\n",
      "[2024-06-28 08:59] Train Step 3330/10000, Batch Size = 128, Examples/Sec = 14249.30, Accuracy = 0.98, Loss = 0.150\n",
      "[2024-06-28 08:59] Train Step 3340/10000, Batch Size = 128, Examples/Sec = 12719.65, Accuracy = 0.99, Loss = 0.090\n",
      "[2024-06-28 08:59] Train Step 3350/10000, Batch Size = 128, Examples/Sec = 14187.55, Accuracy = 0.96, Loss = 0.138\n",
      "[2024-06-28 08:59] Train Step 3360/10000, Batch Size = 128, Examples/Sec = 14182.67, Accuracy = 0.98, Loss = 0.148\n",
      "[2024-06-28 08:59] Train Step 3370/10000, Batch Size = 128, Examples/Sec = 13686.96, Accuracy = 0.86, Loss = 0.371\n",
      "[2024-06-28 08:59] Train Step 3380/10000, Batch Size = 128, Examples/Sec = 13969.37, Accuracy = 0.81, Loss = 0.570\n",
      "[2024-06-28 08:59] Train Step 3390/10000, Batch Size = 128, Examples/Sec = 7494.53, Accuracy = 0.82, Loss = 0.446\n",
      "[2024-06-28 08:59] Train Step 3400/10000, Batch Size = 128, Examples/Sec = 13953.76, Accuracy = 0.96, Loss = 0.139\n",
      "[2024-06-28 08:59] Train Step 3410/10000, Batch Size = 128, Examples/Sec = 14027.04, Accuracy = 0.91, Loss = 0.274\n",
      "[2024-06-28 08:59] Train Step 3420/10000, Batch Size = 128, Examples/Sec = 14422.32, Accuracy = 0.91, Loss = 0.301\n",
      "[2024-06-28 08:59] Train Step 3430/10000, Batch Size = 128, Examples/Sec = 12947.57, Accuracy = 0.93, Loss = 0.186\n",
      "[2024-06-28 08:59] Train Step 3440/10000, Batch Size = 128, Examples/Sec = 14248.92, Accuracy = 0.95, Loss = 0.190\n",
      "[2024-06-28 08:59] Train Step 3450/10000, Batch Size = 128, Examples/Sec = 14377.52, Accuracy = 0.81, Loss = 0.874\n",
      "[2024-06-28 08:59] Train Step 3460/10000, Batch Size = 128, Examples/Sec = 12698.29, Accuracy = 0.59, Loss = 1.492\n",
      "[2024-06-28 08:59] Train Step 3470/10000, Batch Size = 128, Examples/Sec = 14126.32, Accuracy = 0.79, Loss = 0.633\n",
      "[2024-06-28 08:59] Train Step 3480/10000, Batch Size = 128, Examples/Sec = 13413.05, Accuracy = 0.78, Loss = 0.783\n",
      "[2024-06-28 08:59] Train Step 3490/10000, Batch Size = 128, Examples/Sec = 13415.40, Accuracy = 0.90, Loss = 0.341\n",
      "[2024-06-28 08:59] Train Step 3500/10000, Batch Size = 128, Examples/Sec = 14437.45, Accuracy = 0.91, Loss = 0.285\n",
      "[2024-06-28 08:59] Train Step 3510/10000, Batch Size = 128, Examples/Sec = 13204.23, Accuracy = 0.96, Loss = 0.180\n",
      "[2024-06-28 08:59] Train Step 3520/10000, Batch Size = 128, Examples/Sec = 13813.74, Accuracy = 0.88, Loss = 0.315\n",
      "[2024-06-28 08:59] Train Step 3530/10000, Batch Size = 128, Examples/Sec = 14535.95, Accuracy = 1.00, Loss = 0.097\n",
      "[2024-06-28 08:59] Train Step 3540/10000, Batch Size = 128, Examples/Sec = 14766.64, Accuracy = 0.95, Loss = 0.170\n",
      "[2024-06-28 08:59] Train Step 3550/10000, Batch Size = 128, Examples/Sec = 14282.66, Accuracy = 0.98, Loss = 0.123\n",
      "[2024-06-28 08:59] Train Step 3560/10000, Batch Size = 128, Examples/Sec = 12273.58, Accuracy = 0.98, Loss = 0.140\n",
      "[2024-06-28 08:59] Train Step 3570/10000, Batch Size = 128, Examples/Sec = 13482.44, Accuracy = 0.96, Loss = 0.121\n",
      "[2024-06-28 08:59] Train Step 3580/10000, Batch Size = 128, Examples/Sec = 13541.96, Accuracy = 0.98, Loss = 0.109\n",
      "[2024-06-28 08:59] Train Step 3590/10000, Batch Size = 128, Examples/Sec = 14611.91, Accuracy = 0.98, Loss = 0.094\n",
      "[2024-06-28 08:59] Train Step 3600/10000, Batch Size = 128, Examples/Sec = 13372.30, Accuracy = 0.98, Loss = 0.094\n",
      "[2024-06-28 08:59] Train Step 3610/10000, Batch Size = 128, Examples/Sec = 13640.01, Accuracy = 0.91, Loss = 0.245\n",
      "[2024-06-28 08:59] Train Step 3620/10000, Batch Size = 128, Examples/Sec = 13611.31, Accuracy = 0.67, Loss = 1.170\n",
      "[2024-06-28 08:59] Train Step 3630/10000, Batch Size = 128, Examples/Sec = 11156.69, Accuracy = 0.82, Loss = 0.600\n",
      "[2024-06-28 08:59] Train Step 3640/10000, Batch Size = 128, Examples/Sec = 10806.36, Accuracy = 0.86, Loss = 0.608\n",
      "[2024-06-28 08:59] Train Step 3650/10000, Batch Size = 128, Examples/Sec = 14101.46, Accuracy = 0.85, Loss = 0.440\n",
      "[2024-06-28 08:59] Train Step 3660/10000, Batch Size = 128, Examples/Sec = 13542.30, Accuracy = 0.89, Loss = 0.318\n",
      "[2024-06-28 08:59] Train Step 3670/10000, Batch Size = 128, Examples/Sec = 12191.64, Accuracy = 0.93, Loss = 0.211\n",
      "[2024-06-28 08:59] Train Step 3680/10000, Batch Size = 128, Examples/Sec = 13908.57, Accuracy = 0.98, Loss = 0.138\n",
      "[2024-06-28 08:59] Train Step 3690/10000, Batch Size = 128, Examples/Sec = 14001.07, Accuracy = 0.98, Loss = 0.104\n",
      "[2024-06-28 08:59] Train Step 3700/10000, Batch Size = 128, Examples/Sec = 13848.30, Accuracy = 0.97, Loss = 0.134\n",
      "[2024-06-28 08:59] Train Step 3710/10000, Batch Size = 128, Examples/Sec = 14039.51, Accuracy = 0.98, Loss = 0.116\n",
      "[2024-06-28 08:59] Train Step 3720/10000, Batch Size = 128, Examples/Sec = 13763.45, Accuracy = 0.98, Loss = 0.161\n",
      "[2024-06-28 08:59] Train Step 3730/10000, Batch Size = 128, Examples/Sec = 14047.23, Accuracy = 0.98, Loss = 0.150\n",
      "[2024-06-28 08:59] Train Step 3740/10000, Batch Size = 128, Examples/Sec = 12269.93, Accuracy = 0.95, Loss = 0.149\n",
      "[2024-06-28 08:59] Train Step 3750/10000, Batch Size = 128, Examples/Sec = 13641.75, Accuracy = 0.99, Loss = 0.096\n",
      "[2024-06-28 08:59] Train Step 3760/10000, Batch Size = 128, Examples/Sec = 13752.87, Accuracy = 0.99, Loss = 0.103\n",
      "[2024-06-28 08:59] Train Step 3770/10000, Batch Size = 128, Examples/Sec = 10973.79, Accuracy = 0.98, Loss = 0.143\n",
      "[2024-06-28 08:59] Train Step 3780/10000, Batch Size = 128, Examples/Sec = 11698.06, Accuracy = 0.70, Loss = 0.964\n",
      "[2024-06-28 08:59] Train Step 3790/10000, Batch Size = 128, Examples/Sec = 12509.81, Accuracy = 0.72, Loss = 0.681\n",
      "[2024-06-28 08:59] Train Step 3800/10000, Batch Size = 128, Examples/Sec = 11644.02, Accuracy = 0.90, Loss = 0.295\n",
      "[2024-06-28 08:59] Train Step 3810/10000, Batch Size = 128, Examples/Sec = 14066.00, Accuracy = 0.90, Loss = 0.275\n",
      "[2024-06-28 08:59] Train Step 3820/10000, Batch Size = 128, Examples/Sec = 12211.33, Accuracy = 0.98, Loss = 0.121\n",
      "[2024-06-28 08:59] Train Step 3830/10000, Batch Size = 128, Examples/Sec = 14364.05, Accuracy = 0.98, Loss = 0.108\n",
      "[2024-06-28 08:59] Train Step 3840/10000, Batch Size = 128, Examples/Sec = 13878.37, Accuracy = 1.00, Loss = 0.083\n",
      "[2024-06-28 08:59] Train Step 3850/10000, Batch Size = 128, Examples/Sec = 14680.24, Accuracy = 1.00, Loss = 0.090\n",
      "[2024-06-28 08:59] Train Step 3860/10000, Batch Size = 128, Examples/Sec = 14743.13, Accuracy = 1.00, Loss = 0.083\n",
      "[2024-06-28 08:59] Train Step 3870/10000, Batch Size = 128, Examples/Sec = 14234.94, Accuracy = 0.98, Loss = 0.123\n",
      "[2024-06-28 08:59] Train Step 3880/10000, Batch Size = 128, Examples/Sec = 14192.05, Accuracy = 0.98, Loss = 0.110\n",
      "[2024-06-28 08:59] Train Step 3890/10000, Batch Size = 128, Examples/Sec = 13948.32, Accuracy = 0.77, Loss = 0.602\n",
      "[2024-06-28 08:59] Train Step 3900/10000, Batch Size = 128, Examples/Sec = 14685.86, Accuracy = 0.91, Loss = 0.314\n",
      "[2024-06-28 08:59] Train Step 3910/10000, Batch Size = 128, Examples/Sec = 13814.09, Accuracy = 0.73, Loss = 0.863\n",
      "[2024-06-28 08:59] Train Step 3920/10000, Batch Size = 128, Examples/Sec = 12583.70, Accuracy = 0.91, Loss = 0.219\n",
      "[2024-06-28 08:59] Train Step 3930/10000, Batch Size = 128, Examples/Sec = 14279.62, Accuracy = 0.77, Loss = 0.792\n",
      "[2024-06-28 08:59] Train Step 3940/10000, Batch Size = 128, Examples/Sec = 13387.97, Accuracy = 0.84, Loss = 0.395\n",
      "[2024-06-28 08:59] Train Step 3950/10000, Batch Size = 128, Examples/Sec = 12926.68, Accuracy = 0.84, Loss = 0.552\n",
      "[2024-06-28 08:59] Train Step 3960/10000, Batch Size = 128, Examples/Sec = 13136.06, Accuracy = 0.93, Loss = 0.281\n",
      "[2024-06-28 08:59] Train Step 3970/10000, Batch Size = 128, Examples/Sec = 12253.41, Accuracy = 0.98, Loss = 0.117\n",
      "[2024-06-28 08:59] Train Step 3980/10000, Batch Size = 128, Examples/Sec = 12195.24, Accuracy = 0.98, Loss = 0.085\n",
      "[2024-06-28 08:59] Train Step 3990/10000, Batch Size = 128, Examples/Sec = 12881.09, Accuracy = 0.98, Loss = 0.094\n",
      "[2024-06-28 08:59] Train Step 4000/10000, Batch Size = 128, Examples/Sec = 13054.61, Accuracy = 0.99, Loss = 0.084\n",
      "[2024-06-28 08:59] Train Step 4010/10000, Batch Size = 128, Examples/Sec = 11839.95, Accuracy = 1.00, Loss = 0.080\n",
      "[2024-06-28 08:59] Train Step 4020/10000, Batch Size = 128, Examples/Sec = 9952.56, Accuracy = 0.98, Loss = 0.116\n",
      "[2024-06-28 08:59] Train Step 4030/10000, Batch Size = 128, Examples/Sec = 13046.36, Accuracy = 0.84, Loss = 0.508\n",
      "[2024-06-28 08:59] Train Step 4040/10000, Batch Size = 128, Examples/Sec = 12364.88, Accuracy = 0.79, Loss = 0.659\n",
      "[2024-06-28 08:59] Train Step 4050/10000, Batch Size = 128, Examples/Sec = 6841.21, Accuracy = 0.71, Loss = 0.861\n",
      "[2024-06-28 08:59] Train Step 4060/10000, Batch Size = 128, Examples/Sec = 6765.35, Accuracy = 0.95, Loss = 0.193\n",
      "[2024-06-28 08:59] Train Step 4070/10000, Batch Size = 128, Examples/Sec = 12043.68, Accuracy = 0.98, Loss = 0.150\n",
      "[2024-06-28 08:59] Train Step 4080/10000, Batch Size = 128, Examples/Sec = 13025.47, Accuracy = 0.97, Loss = 0.123\n",
      "[2024-06-28 08:59] Train Step 4090/10000, Batch Size = 128, Examples/Sec = 12993.63, Accuracy = 0.98, Loss = 0.146\n",
      "[2024-06-28 08:59] Train Step 4100/10000, Batch Size = 128, Examples/Sec = 12484.21, Accuracy = 0.95, Loss = 0.133\n",
      "[2024-06-28 08:59] Train Step 4110/10000, Batch Size = 128, Examples/Sec = 13859.03, Accuracy = 0.98, Loss = 0.102\n",
      "[2024-06-28 08:59] Train Step 4120/10000, Batch Size = 128, Examples/Sec = 13669.53, Accuracy = 0.98, Loss = 0.091\n",
      "[2024-06-28 08:59] Train Step 4130/10000, Batch Size = 128, Examples/Sec = 13376.96, Accuracy = 0.99, Loss = 0.075\n",
      "[2024-06-28 08:59] Train Step 4140/10000, Batch Size = 128, Examples/Sec = 13502.11, Accuracy = 0.98, Loss = 0.088\n",
      "[2024-06-28 08:59] Train Step 4150/10000, Batch Size = 128, Examples/Sec = 14187.17, Accuracy = 0.98, Loss = 0.092\n",
      "[2024-06-28 08:59] Train Step 4160/10000, Batch Size = 128, Examples/Sec = 14263.31, Accuracy = 0.75, Loss = 0.814\n",
      "[2024-06-28 08:59] Train Step 4170/10000, Batch Size = 128, Examples/Sec = 13022.63, Accuracy = 0.76, Loss = 0.714\n",
      "[2024-06-28 08:59] Train Step 4180/10000, Batch Size = 128, Examples/Sec = 12794.83, Accuracy = 0.73, Loss = 0.713\n",
      "[2024-06-28 08:59] Train Step 4190/10000, Batch Size = 128, Examples/Sec = 4037.08, Accuracy = 0.86, Loss = 0.472\n",
      "[2024-06-28 08:59] Train Step 4200/10000, Batch Size = 128, Examples/Sec = 13448.33, Accuracy = 0.91, Loss = 0.211\n",
      "[2024-06-28 08:59] Train Step 4210/10000, Batch Size = 128, Examples/Sec = 13436.89, Accuracy = 0.95, Loss = 0.207\n",
      "[2024-06-28 08:59] Train Step 4220/10000, Batch Size = 128, Examples/Sec = 12765.32, Accuracy = 0.98, Loss = 0.116\n",
      "[2024-06-28 08:59] Train Step 4230/10000, Batch Size = 128, Examples/Sec = 13267.21, Accuracy = 0.98, Loss = 0.130\n",
      "[2024-06-28 08:59] Train Step 4240/10000, Batch Size = 128, Examples/Sec = 13562.14, Accuracy = 0.99, Loss = 0.103\n",
      "[2024-06-28 08:59] Train Step 4250/10000, Batch Size = 128, Examples/Sec = 14552.11, Accuracy = 0.97, Loss = 0.133\n",
      "[2024-06-28 08:59] Train Step 4260/10000, Batch Size = 128, Examples/Sec = 13376.63, Accuracy = 0.99, Loss = 0.073\n",
      "[2024-06-28 08:59] Train Step 4270/10000, Batch Size = 128, Examples/Sec = 12514.77, Accuracy = 1.00, Loss = 0.081\n",
      "[2024-06-28 08:59] Train Step 4280/10000, Batch Size = 128, Examples/Sec = 12397.15, Accuracy = 1.00, Loss = 0.089\n",
      "[2024-06-28 08:59] Train Step 4290/10000, Batch Size = 128, Examples/Sec = 13024.21, Accuracy = 0.99, Loss = 0.072\n",
      "[2024-06-28 08:59] Train Step 4300/10000, Batch Size = 128, Examples/Sec = 14125.95, Accuracy = 0.95, Loss = 0.202\n",
      "[2024-06-28 08:59] Train Step 4310/10000, Batch Size = 128, Examples/Sec = 13903.89, Accuracy = 0.80, Loss = 0.553\n",
      "[2024-06-28 08:59] Train Step 4320/10000, Batch Size = 128, Examples/Sec = 13651.81, Accuracy = 0.69, Loss = 1.004\n",
      "[2024-06-28 08:59] Train Step 4330/10000, Batch Size = 128, Examples/Sec = 13587.88, Accuracy = 0.89, Loss = 0.320\n",
      "[2024-06-28 08:59] Train Step 4340/10000, Batch Size = 128, Examples/Sec = 11514.90, Accuracy = 0.94, Loss = 0.196\n",
      "[2024-06-28 08:59] Train Step 4350/10000, Batch Size = 128, Examples/Sec = 12979.18, Accuracy = 0.98, Loss = 0.102\n",
      "[2024-06-28 08:59] Train Step 4360/10000, Batch Size = 128, Examples/Sec = 14063.05, Accuracy = 1.00, Loss = 0.086\n",
      "[2024-06-28 08:59] Train Step 4370/10000, Batch Size = 128, Examples/Sec = 13190.61, Accuracy = 1.00, Loss = 0.079\n",
      "[2024-06-28 08:59] Train Step 4380/10000, Batch Size = 128, Examples/Sec = 13592.36, Accuracy = 0.99, Loss = 0.077\n",
      "[2024-06-28 08:59] Train Step 4390/10000, Batch Size = 128, Examples/Sec = 12653.40, Accuracy = 1.00, Loss = 0.087\n",
      "[2024-06-28 08:59] Train Step 4400/10000, Batch Size = 128, Examples/Sec = 14399.88, Accuracy = 0.99, Loss = 0.069\n",
      "[2024-06-28 08:59] Train Step 4410/10000, Batch Size = 128, Examples/Sec = 14519.05, Accuracy = 0.75, Loss = 0.727\n",
      "[2024-06-28 08:59] Train Step 4420/10000, Batch Size = 128, Examples/Sec = 14058.26, Accuracy = 0.73, Loss = 1.283\n",
      "[2024-06-28 08:59] Train Step 4430/10000, Batch Size = 128, Examples/Sec = 14527.30, Accuracy = 0.81, Loss = 0.488\n",
      "[2024-06-28 08:59] Train Step 4440/10000, Batch Size = 128, Examples/Sec = 14592.45, Accuracy = 0.95, Loss = 0.229\n",
      "[2024-06-28 08:59] Train Step 4450/10000, Batch Size = 128, Examples/Sec = 13152.80, Accuracy = 0.97, Loss = 0.139\n",
      "[2024-06-28 08:59] Train Step 4460/10000, Batch Size = 128, Examples/Sec = 12101.50, Accuracy = 0.96, Loss = 0.153\n",
      "[2024-06-28 08:59] Train Step 4470/10000, Batch Size = 128, Examples/Sec = 13125.47, Accuracy = 0.97, Loss = 0.130\n",
      "[2024-06-28 08:59] Train Step 4480/10000, Batch Size = 128, Examples/Sec = 10924.22, Accuracy = 0.98, Loss = 0.138\n",
      "[2024-06-28 08:59] Train Step 4490/10000, Batch Size = 128, Examples/Sec = 11047.64, Accuracy = 0.98, Loss = 0.090\n",
      "[2024-06-28 08:59] Train Step 4500/10000, Batch Size = 128, Examples/Sec = 11399.99, Accuracy = 1.00, Loss = 0.067\n",
      "[2024-06-28 08:59] Train Step 4510/10000, Batch Size = 128, Examples/Sec = 11202.55, Accuracy = 1.00, Loss = 0.056\n",
      "[2024-06-28 08:59] Train Step 4520/10000, Batch Size = 128, Examples/Sec = 13415.74, Accuracy = 1.00, Loss = 0.041\n",
      "[2024-06-28 08:59] Train Step 4530/10000, Batch Size = 128, Examples/Sec = 12755.61, Accuracy = 1.00, Loss = 0.058\n",
      "[2024-06-28 08:59] Train Step 4540/10000, Batch Size = 128, Examples/Sec = 12869.66, Accuracy = 0.96, Loss = 0.129\n",
      "[2024-06-28 08:59] Train Step 4550/10000, Batch Size = 128, Examples/Sec = 13366.97, Accuracy = 0.58, Loss = 1.371\n",
      "[2024-06-28 08:59] Train Step 4560/10000, Batch Size = 128, Examples/Sec = 13034.64, Accuracy = 0.63, Loss = 1.209\n",
      "[2024-06-28 08:59] Train Step 4570/10000, Batch Size = 128, Examples/Sec = 12530.54, Accuracy = 0.77, Loss = 0.665\n",
      "[2024-06-28 08:59] Train Step 4580/10000, Batch Size = 128, Examples/Sec = 11080.24, Accuracy = 0.87, Loss = 0.463\n",
      "[2024-06-28 08:59] Train Step 4590/10000, Batch Size = 128, Examples/Sec = 11313.26, Accuracy = 0.81, Loss = 0.608\n",
      "[2024-06-28 08:59] Train Step 4600/10000, Batch Size = 128, Examples/Sec = 11961.56, Accuracy = 0.91, Loss = 0.314\n",
      "[2024-06-28 08:59] Train Step 4610/10000, Batch Size = 128, Examples/Sec = 10845.44, Accuracy = 0.96, Loss = 0.165\n",
      "[2024-06-28 08:59] Train Step 4620/10000, Batch Size = 128, Examples/Sec = 12891.61, Accuracy = 0.89, Loss = 0.331\n",
      "[2024-06-28 08:59] Train Step 4630/10000, Batch Size = 128, Examples/Sec = 12338.17, Accuracy = 0.95, Loss = 0.176\n",
      "[2024-06-28 08:59] Train Step 4640/10000, Batch Size = 128, Examples/Sec = 13110.40, Accuracy = 0.98, Loss = 0.099\n",
      "[2024-06-28 08:59] Train Step 4650/10000, Batch Size = 128, Examples/Sec = 13986.11, Accuracy = 0.99, Loss = 0.079\n",
      "[2024-06-28 08:59] Train Step 4660/10000, Batch Size = 128, Examples/Sec = 14090.36, Accuracy = 0.99, Loss = 0.079\n",
      "[2024-06-28 08:59] Train Step 4670/10000, Batch Size = 128, Examples/Sec = 13598.55, Accuracy = 0.97, Loss = 0.117\n",
      "[2024-06-28 08:59] Train Step 4680/10000, Batch Size = 128, Examples/Sec = 13698.48, Accuracy = 1.00, Loss = 0.058\n",
      "[2024-06-28 08:59] Train Step 4690/10000, Batch Size = 128, Examples/Sec = 12946.32, Accuracy = 0.99, Loss = 0.078\n",
      "[2024-06-28 08:59] Train Step 4700/10000, Batch Size = 128, Examples/Sec = 10504.64, Accuracy = 1.00, Loss = 0.088\n",
      "[2024-06-28 08:59] Train Step 4710/10000, Batch Size = 128, Examples/Sec = 11222.22, Accuracy = 1.00, Loss = 0.070\n",
      "[2024-06-28 08:59] Train Step 4720/10000, Batch Size = 128, Examples/Sec = 12014.03, Accuracy = 0.99, Loss = 0.074\n",
      "[2024-06-28 08:59] Train Step 4730/10000, Batch Size = 128, Examples/Sec = 10545.49, Accuracy = 0.98, Loss = 0.082\n",
      "[2024-06-28 08:59] Train Step 4740/10000, Batch Size = 128, Examples/Sec = 10883.47, Accuracy = 1.00, Loss = 0.066\n",
      "[2024-06-28 08:59] Train Step 4750/10000, Batch Size = 128, Examples/Sec = 11595.23, Accuracy = 1.00, Loss = 0.059\n",
      "[2024-06-28 08:59] Train Step 4760/10000, Batch Size = 128, Examples/Sec = 12499.90, Accuracy = 0.97, Loss = 0.104\n",
      "[2024-06-28 08:59] Train Step 4770/10000, Batch Size = 128, Examples/Sec = 11086.88, Accuracy = 1.00, Loss = 0.064\n",
      "[2024-06-28 08:59] Train Step 4780/10000, Batch Size = 128, Examples/Sec = 10903.81, Accuracy = 0.66, Loss = 1.469\n",
      "[2024-06-28 08:59] Train Step 4790/10000, Batch Size = 128, Examples/Sec = 12306.50, Accuracy = 0.59, Loss = 1.396\n",
      "[2024-06-28 08:59] Train Step 4800/10000, Batch Size = 128, Examples/Sec = 12269.93, Accuracy = 0.70, Loss = 0.992\n",
      "[2024-06-28 08:59] Train Step 4810/10000, Batch Size = 128, Examples/Sec = 10426.10, Accuracy = 0.84, Loss = 0.493\n",
      "[2024-06-28 08:59] Train Step 4820/10000, Batch Size = 128, Examples/Sec = 12870.90, Accuracy = 0.91, Loss = 0.259\n",
      "[2024-06-28 08:59] Train Step 4830/10000, Batch Size = 128, Examples/Sec = 12299.45, Accuracy = 0.98, Loss = 0.117\n",
      "[2024-06-28 08:59] Train Step 4840/10000, Batch Size = 128, Examples/Sec = 14515.91, Accuracy = 0.98, Loss = 0.098\n",
      "[2024-06-28 08:59] Train Step 4850/10000, Batch Size = 128, Examples/Sec = 14504.14, Accuracy = 0.98, Loss = 0.081\n",
      "[2024-06-28 08:59] Train Step 4860/10000, Batch Size = 128, Examples/Sec = 13041.29, Accuracy = 1.00, Loss = 0.058\n",
      "[2024-06-28 08:59] Train Step 4870/10000, Batch Size = 128, Examples/Sec = 14327.64, Accuracy = 1.00, Loss = 0.048\n",
      "[2024-06-28 08:59] Train Step 4880/10000, Batch Size = 128, Examples/Sec = 13078.78, Accuracy = 0.98, Loss = 0.066\n",
      "[2024-06-28 08:59] Train Step 4890/10000, Batch Size = 128, Examples/Sec = 13889.14, Accuracy = 1.00, Loss = 0.060\n",
      "[2024-06-28 08:59] Train Step 4900/10000, Batch Size = 128, Examples/Sec = 12834.59, Accuracy = 0.95, Loss = 0.184\n",
      "[2024-06-28 08:59] Train Step 4910/10000, Batch Size = 128, Examples/Sec = 12383.71, Accuracy = 1.00, Loss = 0.052\n",
      "[2024-06-28 08:59] Train Step 4920/10000, Batch Size = 128, Examples/Sec = 10959.90, Accuracy = 1.00, Loss = 0.061\n",
      "[2024-06-28 08:59] Train Step 4930/10000, Batch Size = 128, Examples/Sec = 13102.40, Accuracy = 1.00, Loss = 0.042\n",
      "[2024-06-28 08:59] Train Step 4940/10000, Batch Size = 128, Examples/Sec = 10721.12, Accuracy = 0.80, Loss = 0.557\n",
      "[2024-06-28 08:59] Train Step 4950/10000, Batch Size = 128, Examples/Sec = 12118.98, Accuracy = 0.64, Loss = 1.193\n",
      "[2024-06-28 08:59] Train Step 4960/10000, Batch Size = 128, Examples/Sec = 12581.93, Accuracy = 0.88, Loss = 0.413\n",
      "[2024-06-28 08:59] Train Step 4970/10000, Batch Size = 128, Examples/Sec = 12183.34, Accuracy = 0.81, Loss = 0.454\n",
      "[2024-06-28 08:59] Train Step 4980/10000, Batch Size = 128, Examples/Sec = 12624.83, Accuracy = 0.95, Loss = 0.177\n",
      "[2024-06-28 08:59] Train Step 4990/10000, Batch Size = 128, Examples/Sec = 12585.17, Accuracy = 0.95, Loss = 0.134\n",
      "[2024-06-28 08:59] Train Step 5000/10000, Batch Size = 128, Examples/Sec = 10573.32, Accuracy = 1.00, Loss = 0.067\n",
      "[2024-06-28 08:59] Train Step 5010/10000, Batch Size = 128, Examples/Sec = 13022.63, Accuracy = 1.00, Loss = 0.047\n",
      "[2024-06-28 08:59] Train Step 5020/10000, Batch Size = 128, Examples/Sec = 10385.15, Accuracy = 0.98, Loss = 0.087\n",
      "[2024-06-28 08:59] Train Step 5030/10000, Batch Size = 128, Examples/Sec = 13074.64, Accuracy = 0.99, Loss = 0.068\n",
      "[2024-06-28 08:59] Train Step 5040/10000, Batch Size = 128, Examples/Sec = 12741.69, Accuracy = 0.77, Loss = 0.654\n",
      "[2024-06-28 08:59] Train Step 5050/10000, Batch Size = 128, Examples/Sec = 13308.32, Accuracy = 0.90, Loss = 0.278\n",
      "[2024-06-28 08:59] Train Step 5060/10000, Batch Size = 128, Examples/Sec = 13400.33, Accuracy = 0.96, Loss = 0.137\n",
      "[2024-06-28 08:59] Train Step 5070/10000, Batch Size = 128, Examples/Sec = 13382.30, Accuracy = 0.99, Loss = 0.102\n",
      "[2024-06-28 08:59] Train Step 5080/10000, Batch Size = 128, Examples/Sec = 13797.41, Accuracy = 0.99, Loss = 0.063\n",
      "[2024-06-28 08:59] Train Step 5090/10000, Batch Size = 128, Examples/Sec = 12873.37, Accuracy = 1.00, Loss = 0.061\n",
      "[2024-06-28 08:59] Train Step 5100/10000, Batch Size = 128, Examples/Sec = 13922.28, Accuracy = 0.99, Loss = 0.069\n",
      "[2024-06-28 08:59] Train Step 5110/10000, Batch Size = 128, Examples/Sec = 14166.95, Accuracy = 0.98, Loss = 0.086\n",
      "[2024-06-28 08:59] Train Step 5120/10000, Batch Size = 128, Examples/Sec = 14847.09, Accuracy = 0.99, Loss = 0.071\n",
      "[2024-06-28 08:59] Train Step 5130/10000, Batch Size = 128, Examples/Sec = 14132.64, Accuracy = 1.00, Loss = 0.052\n",
      "[2024-06-28 08:59] Train Step 5140/10000, Batch Size = 128, Examples/Sec = 13979.56, Accuracy = 1.00, Loss = 0.064\n",
      "[2024-06-28 08:59] Train Step 5150/10000, Batch Size = 128, Examples/Sec = 13682.77, Accuracy = 0.95, Loss = 0.139\n",
      "[2024-06-28 08:59] Train Step 5160/10000, Batch Size = 128, Examples/Sec = 12878.31, Accuracy = 0.69, Loss = 1.201\n",
      "[2024-06-28 08:59] Train Step 5170/10000, Batch Size = 128, Examples/Sec = 12450.91, Accuracy = 0.77, Loss = 0.842\n",
      "[2024-06-28 08:59] Train Step 5180/10000, Batch Size = 128, Examples/Sec = 9982.91, Accuracy = 0.83, Loss = 0.614\n",
      "[2024-06-28 08:59] Train Step 5190/10000, Batch Size = 128, Examples/Sec = 12878.62, Accuracy = 0.86, Loss = 0.342\n",
      "[2024-06-28 08:59] Train Step 5200/10000, Batch Size = 128, Examples/Sec = 11333.56, Accuracy = 0.84, Loss = 0.506\n",
      "[2024-06-28 08:59] Train Step 5210/10000, Batch Size = 128, Examples/Sec = 10792.68, Accuracy = 0.95, Loss = 0.120\n",
      "[2024-06-28 08:59] Train Step 5220/10000, Batch Size = 128, Examples/Sec = 11182.02, Accuracy = 0.99, Loss = 0.088\n",
      "[2024-06-28 08:59] Train Step 5230/10000, Batch Size = 128, Examples/Sec = 12900.59, Accuracy = 0.98, Loss = 0.086\n",
      "[2024-06-28 08:59] Train Step 5240/10000, Batch Size = 128, Examples/Sec = 11941.61, Accuracy = 0.99, Loss = 0.059\n",
      "[2024-06-28 08:59] Train Step 5250/10000, Batch Size = 128, Examples/Sec = 11121.79, Accuracy = 0.99, Loss = 0.076\n",
      "[2024-06-28 08:59] Train Step 5260/10000, Batch Size = 128, Examples/Sec = 13133.81, Accuracy = 0.99, Loss = 0.063\n",
      "[2024-06-28 08:59] Train Step 5270/10000, Batch Size = 128, Examples/Sec = 13018.52, Accuracy = 1.00, Loss = 0.059\n",
      "[2024-06-28 08:59] Train Step 5280/10000, Batch Size = 128, Examples/Sec = 14070.79, Accuracy = 1.00, Loss = 0.059\n",
      "[2024-06-28 08:59] Train Step 5290/10000, Batch Size = 128, Examples/Sec = 11196.71, Accuracy = 1.00, Loss = 0.036\n",
      "[2024-06-28 08:59] Train Step 5300/10000, Batch Size = 128, Examples/Sec = 11248.79, Accuracy = 1.00, Loss = 0.059\n",
      "[2024-06-28 08:59] Train Step 5310/10000, Batch Size = 128, Examples/Sec = 12529.37, Accuracy = 0.98, Loss = 0.086\n",
      "[2024-06-28 08:59] Train Step 5320/10000, Batch Size = 128, Examples/Sec = 12456.11, Accuracy = 0.95, Loss = 0.147\n",
      "[2024-06-28 08:59] Train Step 5330/10000, Batch Size = 128, Examples/Sec = 12924.19, Accuracy = 0.73, Loss = 0.688\n",
      "[2024-06-28 08:59] Train Step 5340/10000, Batch Size = 128, Examples/Sec = 9904.64, Accuracy = 0.55, Loss = 2.062\n",
      "[2024-06-28 08:59] Train Step 5350/10000, Batch Size = 128, Examples/Sec = 11808.44, Accuracy = 0.62, Loss = 1.285\n",
      "[2024-06-28 08:59] Train Step 5360/10000, Batch Size = 128, Examples/Sec = 12609.71, Accuracy = 0.91, Loss = 0.254\n",
      "[2024-06-28 08:59] Train Step 5370/10000, Batch Size = 128, Examples/Sec = 12740.17, Accuracy = 0.97, Loss = 0.146\n",
      "[2024-06-28 08:59] Train Step 5380/10000, Batch Size = 128, Examples/Sec = 12793.61, Accuracy = 1.00, Loss = 0.063\n",
      "[2024-06-28 08:59] Train Step 5390/10000, Batch Size = 128, Examples/Sec = 12613.26, Accuracy = 1.00, Loss = 0.070\n",
      "[2024-06-28 08:59] Train Step 5400/10000, Batch Size = 128, Examples/Sec = 12300.86, Accuracy = 1.00, Loss = 0.041\n",
      "[2024-06-28 08:59] Train Step 5410/10000, Batch Size = 128, Examples/Sec = 11044.00, Accuracy = 1.00, Loss = 0.055\n",
      "[2024-06-28 08:59] Train Step 5420/10000, Batch Size = 128, Examples/Sec = 11980.78, Accuracy = 1.00, Loss = 0.048\n",
      "[2024-06-28 08:59] Train Step 5430/10000, Batch Size = 128, Examples/Sec = 12793.61, Accuracy = 1.00, Loss = 0.050\n",
      "[2024-06-28 08:59] Train Step 5440/10000, Batch Size = 128, Examples/Sec = 12777.16, Accuracy = 0.98, Loss = 0.059\n",
      "[2024-06-28 08:59] Train Step 5450/10000, Batch Size = 128, Examples/Sec = 12586.06, Accuracy = 0.99, Loss = 0.053\n",
      "[2024-06-28 08:59] Train Step 5460/10000, Batch Size = 128, Examples/Sec = 12746.22, Accuracy = 0.99, Loss = 0.066\n",
      "[2024-06-28 08:59] Train Step 5470/10000, Batch Size = 128, Examples/Sec = 12132.68, Accuracy = 1.00, Loss = 0.061\n",
      "[2024-06-28 08:59] Train Step 5480/10000, Batch Size = 128, Examples/Sec = 10902.04, Accuracy = 1.00, Loss = 0.037\n",
      "[2024-06-28 08:59] Train Step 5490/10000, Batch Size = 128, Examples/Sec = 12376.86, Accuracy = 0.72, Loss = 0.900\n",
      "[2024-06-28 08:59] Train Step 5500/10000, Batch Size = 128, Examples/Sec = 14198.80, Accuracy = 0.80, Loss = 0.558\n",
      "[2024-06-28 08:59] Train Step 5510/10000, Batch Size = 128, Examples/Sec = 12832.14, Accuracy = 0.79, Loss = 0.517\n",
      "[2024-06-28 08:59] Train Step 5520/10000, Batch Size = 128, Examples/Sec = 12500.20, Accuracy = 0.91, Loss = 0.340\n",
      "[2024-06-28 08:59] Train Step 5530/10000, Batch Size = 128, Examples/Sec = 12272.46, Accuracy = 0.98, Loss = 0.113\n",
      "[2024-06-28 08:59] Train Step 5540/10000, Batch Size = 128, Examples/Sec = 14151.27, Accuracy = 0.95, Loss = 0.248\n",
      "[2024-06-28 08:59] Train Step 5550/10000, Batch Size = 128, Examples/Sec = 12800.01, Accuracy = 0.98, Loss = 0.113\n",
      "[2024-06-28 08:59] Train Step 5560/10000, Batch Size = 128, Examples/Sec = 13625.82, Accuracy = 0.98, Loss = 0.069\n",
      "[2024-06-28 08:59] Train Step 5570/10000, Batch Size = 128, Examples/Sec = 14055.32, Accuracy = 0.99, Loss = 0.069\n",
      "[2024-06-28 08:59] Train Step 5580/10000, Batch Size = 128, Examples/Sec = 14140.83, Accuracy = 1.00, Loss = 0.051\n",
      "[2024-06-28 08:59] Train Step 5590/10000, Batch Size = 128, Examples/Sec = 14036.57, Accuracy = 0.99, Loss = 0.057\n",
      "[2024-06-28 08:59] Train Step 5600/10000, Batch Size = 128, Examples/Sec = 12214.94, Accuracy = 0.99, Loss = 0.053\n",
      "[2024-06-28 08:59] Train Step 5610/10000, Batch Size = 128, Examples/Sec = 12934.47, Accuracy = 1.00, Loss = 0.048\n",
      "[2024-06-28 08:59] Train Step 5620/10000, Batch Size = 128, Examples/Sec = 12320.62, Accuracy = 1.00, Loss = 0.058\n",
      "[2024-06-28 08:59] Train Step 5630/10000, Batch Size = 128, Examples/Sec = 13380.63, Accuracy = 1.00, Loss = 0.041\n",
      "[2024-06-28 08:59] Train Step 5640/10000, Batch Size = 128, Examples/Sec = 14087.40, Accuracy = 0.98, Loss = 0.085\n",
      "[2024-06-28 08:59] Train Step 5650/10000, Batch Size = 128, Examples/Sec = 14784.13, Accuracy = 0.77, Loss = 0.754\n",
      "[2024-06-28 08:59] Train Step 5660/10000, Batch Size = 128, Examples/Sec = 14179.68, Accuracy = 0.80, Loss = 0.595\n",
      "[2024-06-28 08:59] Train Step 5670/10000, Batch Size = 128, Examples/Sec = 14385.61, Accuracy = 0.83, Loss = 0.518\n",
      "[2024-06-28 08:59] Train Step 5680/10000, Batch Size = 128, Examples/Sec = 13157.63, Accuracy = 0.80, Loss = 0.524\n",
      "[2024-06-28 08:59] Train Step 5690/10000, Batch Size = 128, Examples/Sec = 13699.88, Accuracy = 0.91, Loss = 0.206\n",
      "[2024-06-28 08:59] Train Step 5700/10000, Batch Size = 128, Examples/Sec = 13169.90, Accuracy = 0.96, Loss = 0.127\n",
      "[2024-06-28 08:59] Train Step 5710/10000, Batch Size = 128, Examples/Sec = 13004.33, Accuracy = 0.95, Loss = 0.160\n",
      "[2024-06-28 08:59] Train Step 5720/10000, Batch Size = 128, Examples/Sec = 12162.91, Accuracy = 0.95, Loss = 0.126\n",
      "[2024-06-28 08:59] Train Step 5730/10000, Batch Size = 128, Examples/Sec = 13211.06, Accuracy = 0.99, Loss = 0.067\n",
      "[2024-06-28 08:59] Train Step 5740/10000, Batch Size = 128, Examples/Sec = 11688.39, Accuracy = 1.00, Loss = 0.049\n",
      "[2024-06-28 08:59] Train Step 5750/10000, Batch Size = 128, Examples/Sec = 12016.72, Accuracy = 0.99, Loss = 0.060\n",
      "[2024-06-28 08:59] Train Step 5760/10000, Batch Size = 128, Examples/Sec = 12303.96, Accuracy = 0.95, Loss = 0.164\n",
      "[2024-06-28 08:59] Train Step 5770/10000, Batch Size = 128, Examples/Sec = 14343.33, Accuracy = 0.91, Loss = 0.290\n",
      "[2024-06-28 08:59] Train Step 5780/10000, Batch Size = 128, Examples/Sec = 14181.17, Accuracy = 0.99, Loss = 0.098\n",
      "[2024-06-28 08:59] Train Step 5790/10000, Batch Size = 128, Examples/Sec = 10240.16, Accuracy = 0.73, Loss = 0.683\n",
      "[2024-06-28 08:59] Train Step 5800/10000, Batch Size = 128, Examples/Sec = 12528.20, Accuracy = 0.74, Loss = 0.615\n",
      "[2024-06-28 08:59] Train Step 5810/10000, Batch Size = 128, Examples/Sec = 12523.52, Accuracy = 0.94, Loss = 0.207\n",
      "[2024-06-28 08:59] Train Step 5820/10000, Batch Size = 128, Examples/Sec = 13212.36, Accuracy = 0.98, Loss = 0.073\n",
      "[2024-06-28 08:59] Train Step 5830/10000, Batch Size = 128, Examples/Sec = 12729.60, Accuracy = 0.99, Loss = 0.047\n",
      "[2024-06-28 08:59] Train Step 5840/10000, Batch Size = 128, Examples/Sec = 10978.51, Accuracy = 1.00, Loss = 0.045\n",
      "[2024-06-28 08:59] Train Step 5850/10000, Batch Size = 128, Examples/Sec = 12550.16, Accuracy = 1.00, Loss = 0.048\n",
      "[2024-06-28 08:59] Train Step 5860/10000, Batch Size = 128, Examples/Sec = 12994.89, Accuracy = 1.00, Loss = 0.042\n",
      "[2024-06-28 08:59] Train Step 5870/10000, Batch Size = 128, Examples/Sec = 13235.48, Accuracy = 0.91, Loss = 0.223\n",
      "[2024-06-28 08:59] Train Step 5880/10000, Batch Size = 128, Examples/Sec = 14417.67, Accuracy = 0.99, Loss = 0.082\n",
      "[2024-06-28 08:59] Train Step 5890/10000, Batch Size = 128, Examples/Sec = 11195.77, Accuracy = 0.66, Loss = 1.099\n",
      "[2024-06-28 08:59] Train Step 5900/10000, Batch Size = 128, Examples/Sec = 13337.75, Accuracy = 0.91, Loss = 0.273\n",
      "[2024-06-28 08:59] Train Step 5910/10000, Batch Size = 128, Examples/Sec = 11031.52, Accuracy = 0.93, Loss = 0.246\n",
      "[2024-06-28 08:59] Train Step 5920/10000, Batch Size = 128, Examples/Sec = 12904.62, Accuracy = 0.96, Loss = 0.165\n",
      "[2024-06-28 08:59] Train Step 5930/10000, Batch Size = 128, Examples/Sec = 10800.71, Accuracy = 0.98, Loss = 0.088\n",
      "[2024-06-28 08:59] Train Step 5940/10000, Batch Size = 128, Examples/Sec = 10537.42, Accuracy = 1.00, Loss = 0.050\n",
      "[2024-06-28 08:59] Train Step 5950/10000, Batch Size = 128, Examples/Sec = 12447.74, Accuracy = 1.00, Loss = 0.055\n",
      "[2024-06-28 08:59] Train Step 5960/10000, Batch Size = 128, Examples/Sec = 12245.31, Accuracy = 1.00, Loss = 0.047\n",
      "[2024-06-28 08:59] Train Step 5970/10000, Batch Size = 128, Examples/Sec = 13045.10, Accuracy = 1.00, Loss = 0.040\n",
      "[2024-06-28 08:59] Train Step 5980/10000, Batch Size = 128, Examples/Sec = 12455.25, Accuracy = 0.98, Loss = 0.060\n",
      "[2024-06-28 08:59] Train Step 5990/10000, Batch Size = 128, Examples/Sec = 10027.47, Accuracy = 1.00, Loss = 0.038\n",
      "[2024-06-28 08:59] Train Step 6000/10000, Batch Size = 128, Examples/Sec = 13605.45, Accuracy = 1.00, Loss = 0.033\n",
      "[2024-06-28 08:59] Train Step 6010/10000, Batch Size = 128, Examples/Sec = 14304.73, Accuracy = 1.00, Loss = 0.035\n",
      "[2024-06-28 08:59] Train Step 6020/10000, Batch Size = 128, Examples/Sec = 12228.85, Accuracy = 0.98, Loss = 0.072\n",
      "[2024-06-28 08:59] Train Step 6030/10000, Batch Size = 128, Examples/Sec = 13925.17, Accuracy = 0.99, Loss = 0.069\n",
      "[2024-06-28 08:59] Train Step 6040/10000, Batch Size = 128, Examples/Sec = 13997.05, Accuracy = 0.88, Loss = 0.351\n",
      "[2024-06-28 08:59] Train Step 6050/10000, Batch Size = 128, Examples/Sec = 11720.54, Accuracy = 0.63, Loss = 1.131\n",
      "[2024-06-28 08:59] Train Step 6060/10000, Batch Size = 128, Examples/Sec = 14386.77, Accuracy = 0.71, Loss = 1.127\n",
      "[2024-06-28 08:59] Train Step 6070/10000, Batch Size = 128, Examples/Sec = 13688.70, Accuracy = 0.64, Loss = 1.343\n",
      "[2024-06-28 08:59] Train Step 6080/10000, Batch Size = 128, Examples/Sec = 13516.39, Accuracy = 0.87, Loss = 0.396\n",
      "[2024-06-28 08:59] Train Step 6090/10000, Batch Size = 128, Examples/Sec = 13580.67, Accuracy = 0.84, Loss = 0.452\n",
      "[2024-06-28 08:59] Train Step 6100/10000, Batch Size = 128, Examples/Sec = 10829.91, Accuracy = 0.89, Loss = 0.288\n",
      "[2024-06-28 08:59] Train Step 6110/10000, Batch Size = 128, Examples/Sec = 14238.34, Accuracy = 0.94, Loss = 0.174\n",
      "[2024-06-28 08:59] Train Step 6120/10000, Batch Size = 128, Examples/Sec = 13847.94, Accuracy = 0.93, Loss = 0.215\n",
      "[2024-06-28 08:59] Train Step 6130/10000, Batch Size = 128, Examples/Sec = 13262.62, Accuracy = 0.96, Loss = 0.124\n",
      "[2024-06-28 08:59] Train Step 6140/10000, Batch Size = 128, Examples/Sec = 13829.04, Accuracy = 0.98, Loss = 0.104\n",
      "[2024-06-28 08:59] Train Step 6150/10000, Batch Size = 128, Examples/Sec = 14109.62, Accuracy = 0.94, Loss = 0.261\n",
      "[2024-06-28 08:59] Train Step 6160/10000, Batch Size = 128, Examples/Sec = 14409.16, Accuracy = 0.84, Loss = 0.382\n",
      "[2024-06-28 08:59] Train Step 6170/10000, Batch Size = 128, Examples/Sec = 14239.47, Accuracy = 0.95, Loss = 0.139\n",
      "[2024-06-28 08:59] Train Step 6180/10000, Batch Size = 128, Examples/Sec = 13160.86, Accuracy = 0.95, Loss = 0.172\n",
      "[2024-06-28 08:59] Train Step 6190/10000, Batch Size = 128, Examples/Sec = 14351.77, Accuracy = 0.96, Loss = 0.106\n",
      "[2024-06-28 08:59] Train Step 6200/10000, Batch Size = 128, Examples/Sec = 13532.06, Accuracy = 0.98, Loss = 0.104\n",
      "[2024-06-28 08:59] Train Step 6210/10000, Batch Size = 128, Examples/Sec = 14370.98, Accuracy = 0.98, Loss = 0.106\n",
      "[2024-06-28 08:59] Train Step 6220/10000, Batch Size = 128, Examples/Sec = 14001.43, Accuracy = 0.99, Loss = 0.084\n",
      "[2024-06-28 08:59] Train Step 6230/10000, Batch Size = 128, Examples/Sec = 14027.41, Accuracy = 0.98, Loss = 0.077\n",
      "[2024-06-28 08:59] Train Step 6240/10000, Batch Size = 128, Examples/Sec = 14550.53, Accuracy = 0.93, Loss = 0.205\n",
      "[2024-06-28 08:59] Train Step 6250/10000, Batch Size = 128, Examples/Sec = 12745.32, Accuracy = 0.98, Loss = 0.092\n",
      "[2024-06-28 09:00] Train Step 6260/10000, Batch Size = 128, Examples/Sec = 14084.45, Accuracy = 0.99, Loss = 0.080\n",
      "[2024-06-28 09:00] Train Step 6270/10000, Batch Size = 128, Examples/Sec = 13439.58, Accuracy = 0.84, Loss = 0.568\n",
      "[2024-06-28 09:00] Train Step 6280/10000, Batch Size = 128, Examples/Sec = 13846.87, Accuracy = 0.88, Loss = 0.308\n",
      "[2024-06-28 09:00] Train Step 6290/10000, Batch Size = 128, Examples/Sec = 13236.46, Accuracy = 0.95, Loss = 0.194\n",
      "[2024-06-28 09:00] Train Step 6300/10000, Batch Size = 128, Examples/Sec = 14386.77, Accuracy = 0.88, Loss = 0.302\n",
      "[2024-06-28 09:00] Train Step 6310/10000, Batch Size = 128, Examples/Sec = 12650.71, Accuracy = 0.87, Loss = 0.516\n",
      "[2024-06-28 09:00] Train Step 6320/10000, Batch Size = 128, Examples/Sec = 12156.85, Accuracy = 0.90, Loss = 0.286\n",
      "[2024-06-28 09:00] Train Step 6330/10000, Batch Size = 128, Examples/Sec = 9564.44, Accuracy = 0.96, Loss = 0.181\n",
      "[2024-06-28 09:00] Train Step 6340/10000, Batch Size = 128, Examples/Sec = 12633.15, Accuracy = 0.98, Loss = 0.104\n",
      "[2024-06-28 09:00] Train Step 6350/10000, Batch Size = 128, Examples/Sec = 12973.85, Accuracy = 0.99, Loss = 0.092\n",
      "[2024-06-28 09:00] Train Step 6360/10000, Batch Size = 128, Examples/Sec = 13009.38, Accuracy = 0.99, Loss = 0.055\n",
      "[2024-06-28 09:00] Train Step 6370/10000, Batch Size = 128, Examples/Sec = 13931.31, Accuracy = 1.00, Loss = 0.066\n",
      "[2024-06-28 09:00] Train Step 6380/10000, Batch Size = 128, Examples/Sec = 13065.10, Accuracy = 0.98, Loss = 0.076\n",
      "[2024-06-28 09:00] Train Step 6390/10000, Batch Size = 128, Examples/Sec = 13394.65, Accuracy = 0.98, Loss = 0.084\n",
      "[2024-06-28 09:00] Train Step 6400/10000, Batch Size = 128, Examples/Sec = 10357.70, Accuracy = 0.89, Loss = 0.304\n",
      "[2024-06-28 09:00] Train Step 6410/10000, Batch Size = 128, Examples/Sec = 13490.57, Accuracy = 0.92, Loss = 0.213\n",
      "[2024-06-28 09:00] Train Step 6420/10000, Batch Size = 128, Examples/Sec = 11138.17, Accuracy = 0.92, Loss = 0.219\n",
      "[2024-06-28 09:00] Train Step 6430/10000, Batch Size = 128, Examples/Sec = 12818.96, Accuracy = 0.88, Loss = 0.258\n",
      "[2024-06-28 09:00] Train Step 6440/10000, Batch Size = 128, Examples/Sec = 12303.96, Accuracy = 0.96, Loss = 0.136\n",
      "[2024-06-28 09:00] Train Step 6450/10000, Batch Size = 128, Examples/Sec = 10787.26, Accuracy = 0.96, Loss = 0.128\n",
      "[2024-06-28 09:00] Train Step 6460/10000, Batch Size = 128, Examples/Sec = 10079.43, Accuracy = 0.98, Loss = 0.125\n",
      "[2024-06-28 09:00] Train Step 6470/10000, Batch Size = 128, Examples/Sec = 12355.21, Accuracy = 0.99, Loss = 0.056\n",
      "[2024-06-28 09:00] Train Step 6480/10000, Batch Size = 128, Examples/Sec = 12795.13, Accuracy = 0.98, Loss = 0.068\n",
      "[2024-06-28 09:00] Train Step 6490/10000, Batch Size = 128, Examples/Sec = 12344.70, Accuracy = 0.98, Loss = 0.089\n",
      "[2024-06-28 09:00] Train Step 6500/10000, Batch Size = 128, Examples/Sec = 13164.73, Accuracy = 0.99, Loss = 0.052\n",
      "[2024-06-28 09:00] Train Step 6510/10000, Batch Size = 128, Examples/Sec = 13688.00, Accuracy = 1.00, Loss = 0.081\n",
      "[2024-06-28 09:00] Train Step 6520/10000, Batch Size = 128, Examples/Sec = 13650.42, Accuracy = 1.00, Loss = 0.043\n",
      "[2024-06-28 09:00] Train Step 6530/10000, Batch Size = 128, Examples/Sec = 12897.80, Accuracy = 0.97, Loss = 0.133\n",
      "[2024-06-28 09:00] Train Step 6540/10000, Batch Size = 128, Examples/Sec = 13060.96, Accuracy = 0.60, Loss = 1.457\n",
      "[2024-06-28 09:00] Train Step 6550/10000, Batch Size = 128, Examples/Sec = 13166.99, Accuracy = 0.73, Loss = 0.868\n",
      "[2024-06-28 09:00] Train Step 6560/10000, Batch Size = 128, Examples/Sec = 12972.60, Accuracy = 0.94, Loss = 0.234\n",
      "[2024-06-28 09:00] Train Step 6570/10000, Batch Size = 128, Examples/Sec = 12954.44, Accuracy = 0.86, Loss = 0.311\n",
      "[2024-06-28 09:00] Train Step 6580/10000, Batch Size = 128, Examples/Sec = 13408.70, Accuracy = 0.97, Loss = 0.126\n",
      "[2024-06-28 09:00] Train Step 6590/10000, Batch Size = 128, Examples/Sec = 14686.26, Accuracy = 0.94, Loss = 0.192\n",
      "[2024-06-28 09:00] Train Step 6600/10000, Batch Size = 128, Examples/Sec = 14809.82, Accuracy = 0.96, Loss = 0.127\n",
      "[2024-06-28 09:00] Train Step 6610/10000, Batch Size = 128, Examples/Sec = 12581.04, Accuracy = 1.00, Loss = 0.062\n",
      "[2024-06-28 09:00] Train Step 6620/10000, Batch Size = 128, Examples/Sec = 14013.49, Accuracy = 1.00, Loss = 0.046\n",
      "[2024-06-28 09:00] Train Step 6630/10000, Batch Size = 128, Examples/Sec = 13514.35, Accuracy = 1.00, Loss = 0.046\n",
      "[2024-06-28 09:00] Train Step 6640/10000, Batch Size = 128, Examples/Sec = 12970.09, Accuracy = 1.00, Loss = 0.040\n",
      "[2024-06-28 09:00] Train Step 6650/10000, Batch Size = 128, Examples/Sec = 13616.83, Accuracy = 0.98, Loss = 0.056\n",
      "[2024-06-28 09:00] Train Step 6660/10000, Batch Size = 128, Examples/Sec = 12298.32, Accuracy = 0.98, Loss = 0.070\n",
      "[2024-06-28 09:00] Train Step 6670/10000, Batch Size = 128, Examples/Sec = 14148.29, Accuracy = 1.00, Loss = 0.037\n",
      "[2024-06-28 09:00] Train Step 6680/10000, Batch Size = 128, Examples/Sec = 14138.97, Accuracy = 1.00, Loss = 0.042\n",
      "[2024-06-28 09:00] Train Step 6690/10000, Batch Size = 128, Examples/Sec = 13452.38, Accuracy = 1.00, Loss = 0.034\n",
      "[2024-06-28 09:00] Train Step 6700/10000, Batch Size = 128, Examples/Sec = 10808.76, Accuracy = 1.00, Loss = 0.047\n",
      "[2024-06-28 09:00] Train Step 6710/10000, Batch Size = 128, Examples/Sec = 12778.08, Accuracy = 0.99, Loss = 0.054\n",
      "[2024-06-28 09:00] Train Step 6720/10000, Batch Size = 128, Examples/Sec = 13023.89, Accuracy = 0.95, Loss = 0.152\n",
      "[2024-06-28 09:00] Train Step 6730/10000, Batch Size = 128, Examples/Sec = 13872.27, Accuracy = 0.60, Loss = 1.336\n",
      "[2024-06-28 09:00] Train Step 6740/10000, Batch Size = 128, Examples/Sec = 11630.15, Accuracy = 0.92, Loss = 0.305\n",
      "[2024-06-28 09:00] Train Step 6750/10000, Batch Size = 128, Examples/Sec = 12708.51, Accuracy = 0.91, Loss = 0.224\n",
      "[2024-06-28 09:00] Train Step 6760/10000, Batch Size = 128, Examples/Sec = 11471.60, Accuracy = 0.95, Loss = 0.186\n",
      "[2024-06-28 09:00] Train Step 6770/10000, Batch Size = 128, Examples/Sec = 13241.36, Accuracy = 0.98, Loss = 0.094\n",
      "[2024-06-28 09:00] Train Step 6780/10000, Batch Size = 128, Examples/Sec = 14219.11, Accuracy = 0.98, Loss = 0.096\n",
      "[2024-06-28 09:00] Train Step 6790/10000, Batch Size = 128, Examples/Sec = 14601.58, Accuracy = 0.95, Loss = 0.087\n",
      "[2024-06-28 09:00] Train Step 6800/10000, Batch Size = 128, Examples/Sec = 12828.46, Accuracy = 1.00, Loss = 0.037\n",
      "[2024-06-28 09:00] Train Step 6810/10000, Batch Size = 128, Examples/Sec = 14018.25, Accuracy = 1.00, Loss = 0.046\n",
      "[2024-06-28 09:00] Train Step 6820/10000, Batch Size = 128, Examples/Sec = 14125.21, Accuracy = 0.99, Loss = 0.110\n",
      "[2024-06-28 09:00] Train Step 6830/10000, Batch Size = 128, Examples/Sec = 14328.78, Accuracy = 0.73, Loss = 0.846\n",
      "[2024-06-28 09:00] Train Step 6840/10000, Batch Size = 128, Examples/Sec = 14042.45, Accuracy = 0.87, Loss = 0.358\n",
      "[2024-06-28 09:00] Train Step 6850/10000, Batch Size = 128, Examples/Sec = 13444.29, Accuracy = 0.95, Loss = 0.174\n",
      "[2024-06-28 09:00] Train Step 6860/10000, Batch Size = 128, Examples/Sec = 14131.53, Accuracy = 0.98, Loss = 0.112\n",
      "[2024-06-28 09:00] Train Step 6870/10000, Batch Size = 128, Examples/Sec = 14124.46, Accuracy = 1.00, Loss = 0.060\n",
      "[2024-06-28 09:00] Train Step 6880/10000, Batch Size = 128, Examples/Sec = 14033.64, Accuracy = 1.00, Loss = 0.043\n",
      "[2024-06-28 09:00] Train Step 6890/10000, Batch Size = 128, Examples/Sec = 13821.21, Accuracy = 1.00, Loss = 0.041\n",
      "[2024-06-28 09:00] Train Step 6900/10000, Batch Size = 128, Examples/Sec = 13541.96, Accuracy = 1.00, Loss = 0.036\n",
      "[2024-06-28 09:00] Train Step 6910/10000, Batch Size = 128, Examples/Sec = 14160.98, Accuracy = 1.00, Loss = 0.039\n",
      "[2024-06-28 09:00] Train Step 6920/10000, Batch Size = 128, Examples/Sec = 14685.86, Accuracy = 1.00, Loss = 0.052\n",
      "[2024-06-28 09:00] Train Step 6930/10000, Batch Size = 128, Examples/Sec = 13614.07, Accuracy = 1.00, Loss = 0.036\n",
      "[2024-06-28 09:00] Train Step 6940/10000, Batch Size = 128, Examples/Sec = 15087.42, Accuracy = 1.00, Loss = 0.036\n",
      "[2024-06-28 09:00] Train Step 6950/10000, Batch Size = 128, Examples/Sec = 13473.65, Accuracy = 1.00, Loss = 0.027\n",
      "[2024-06-28 09:00] Train Step 6960/10000, Batch Size = 128, Examples/Sec = 14838.89, Accuracy = 1.00, Loss = 0.028\n",
      "[2024-06-28 09:00] Train Step 6970/10000, Batch Size = 128, Examples/Sec = 14417.29, Accuracy = 1.00, Loss = 0.038\n",
      "[2024-06-28 09:00] Train Step 6980/10000, Batch Size = 128, Examples/Sec = 13917.59, Accuracy = 1.00, Loss = 0.033\n",
      "[2024-06-28 09:00] Train Step 6990/10000, Batch Size = 128, Examples/Sec = 14660.59, Accuracy = 1.00, Loss = 0.034\n",
      "[2024-06-28 09:00] Train Step 7000/10000, Batch Size = 128, Examples/Sec = 14685.86, Accuracy = 1.00, Loss = 0.027\n",
      "[2024-06-28 09:00] Train Step 7010/10000, Batch Size = 128, Examples/Sec = 14078.17, Accuracy = 1.00, Loss = 0.036\n",
      "[2024-06-28 09:00] Train Step 7020/10000, Batch Size = 128, Examples/Sec = 12802.45, Accuracy = 0.93, Loss = 0.156\n",
      "[2024-06-28 09:00] Train Step 7030/10000, Batch Size = 128, Examples/Sec = 14239.47, Accuracy = 0.64, Loss = 1.726\n",
      "[2024-06-28 09:00] Train Step 7040/10000, Batch Size = 128, Examples/Sec = 14144.93, Accuracy = 0.66, Loss = 1.416\n",
      "[2024-06-28 09:00] Train Step 7050/10000, Batch Size = 128, Examples/Sec = 13138.96, Accuracy = 0.61, Loss = 1.540\n",
      "[2024-06-28 09:00] Train Step 7060/10000, Batch Size = 128, Examples/Sec = 13220.49, Accuracy = 0.71, Loss = 0.659\n",
      "[2024-06-28 09:00] Train Step 7070/10000, Batch Size = 128, Examples/Sec = 14427.36, Accuracy = 0.72, Loss = 0.778\n",
      "[2024-06-28 09:00] Train Step 7080/10000, Batch Size = 128, Examples/Sec = 13694.29, Accuracy = 0.73, Loss = 0.729\n",
      "[2024-06-28 09:00] Train Step 7090/10000, Batch Size = 128, Examples/Sec = 14939.64, Accuracy = 0.80, Loss = 0.476\n",
      "[2024-06-28 09:00] Train Step 7100/10000, Batch Size = 128, Examples/Sec = 14738.27, Accuracy = 0.83, Loss = 0.453\n",
      "[2024-06-28 09:00] Train Step 7110/10000, Batch Size = 128, Examples/Sec = 14442.11, Accuracy = 0.82, Loss = 0.476\n",
      "[2024-06-28 09:00] Train Step 7120/10000, Batch Size = 128, Examples/Sec = 12884.18, Accuracy = 0.81, Loss = 0.588\n",
      "[2024-06-28 09:00] Train Step 7130/10000, Batch Size = 128, Examples/Sec = 13351.34, Accuracy = 0.84, Loss = 0.404\n",
      "[2024-06-28 09:00] Train Step 7140/10000, Batch Size = 128, Examples/Sec = 14271.27, Accuracy = 0.88, Loss = 0.297\n",
      "[2024-06-28 09:00] Train Step 7150/10000, Batch Size = 128, Examples/Sec = 14317.70, Accuracy = 0.84, Loss = 0.494\n",
      "[2024-06-28 09:00] Train Step 7160/10000, Batch Size = 128, Examples/Sec = 13110.40, Accuracy = 0.78, Loss = 0.491\n",
      "[2024-06-28 09:00] Train Step 7170/10000, Batch Size = 128, Examples/Sec = 13551.87, Accuracy = 0.75, Loss = 0.588\n",
      "[2024-06-28 09:00] Train Step 7180/10000, Batch Size = 128, Examples/Sec = 13946.15, Accuracy = 0.84, Loss = 0.390\n",
      "[2024-06-28 09:00] Train Step 7190/10000, Batch Size = 128, Examples/Sec = 13313.93, Accuracy = 0.90, Loss = 0.340\n",
      "[2024-06-28 09:00] Train Step 7200/10000, Batch Size = 128, Examples/Sec = 13510.61, Accuracy = 0.89, Loss = 0.327\n",
      "[2024-06-28 09:00] Train Step 7210/10000, Batch Size = 128, Examples/Sec = 12685.99, Accuracy = 0.91, Loss = 0.232\n",
      "[2024-06-28 09:00] Train Step 7220/10000, Batch Size = 128, Examples/Sec = 13264.59, Accuracy = 0.83, Loss = 0.469\n",
      "[2024-06-28 09:00] Train Step 7230/10000, Batch Size = 128, Examples/Sec = 5558.42, Accuracy = 0.89, Loss = 0.340\n",
      "[2024-06-28 09:00] Train Step 7240/10000, Batch Size = 128, Examples/Sec = 12705.80, Accuracy = 0.86, Loss = 0.360\n",
      "[2024-06-28 09:00] Train Step 7250/10000, Batch Size = 128, Examples/Sec = 13800.95, Accuracy = 0.88, Loss = 0.312\n",
      "[2024-06-28 09:00] Train Step 7260/10000, Batch Size = 128, Examples/Sec = 14456.50, Accuracy = 0.83, Loss = 0.465\n",
      "[2024-06-28 09:00] Train Step 7270/10000, Batch Size = 128, Examples/Sec = 13771.22, Accuracy = 0.88, Loss = 0.259\n",
      "[2024-06-28 09:00] Train Step 7280/10000, Batch Size = 128, Examples/Sec = 13631.35, Accuracy = 0.88, Loss = 0.314\n",
      "[2024-06-28 09:00] Train Step 7290/10000, Batch Size = 128, Examples/Sec = 12898.11, Accuracy = 0.95, Loss = 0.203\n",
      "[2024-06-28 09:00] Train Step 7300/10000, Batch Size = 128, Examples/Sec = 10677.20, Accuracy = 0.88, Loss = 0.407\n",
      "[2024-06-28 09:00] Train Step 7310/10000, Batch Size = 128, Examples/Sec = 13049.22, Accuracy = 0.89, Loss = 0.266\n",
      "[2024-06-28 09:00] Train Step 7320/10000, Batch Size = 128, Examples/Sec = 13300.08, Accuracy = 0.92, Loss = 0.206\n",
      "[2024-06-28 09:00] Train Step 7330/10000, Batch Size = 128, Examples/Sec = 13744.07, Accuracy = 0.92, Loss = 0.245\n",
      "[2024-06-28 09:00] Train Step 7340/10000, Batch Size = 128, Examples/Sec = 12818.04, Accuracy = 0.95, Loss = 0.127\n",
      "[2024-06-28 09:00] Train Step 7350/10000, Batch Size = 128, Examples/Sec = 12220.78, Accuracy = 0.93, Loss = 0.221\n",
      "[2024-06-28 09:00] Train Step 7360/10000, Batch Size = 128, Examples/Sec = 14117.04, Accuracy = 0.96, Loss = 0.119\n",
      "[2024-06-28 09:00] Train Step 7370/10000, Batch Size = 128, Examples/Sec = 14126.69, Accuracy = 0.93, Loss = 0.180\n",
      "[2024-06-28 09:00] Train Step 7380/10000, Batch Size = 128, Examples/Sec = 13806.28, Accuracy = 0.70, Loss = 0.991\n",
      "[2024-06-28 09:00] Train Step 7390/10000, Batch Size = 128, Examples/Sec = 13316.90, Accuracy = 0.91, Loss = 0.273\n",
      "[2024-06-28 09:00] Train Step 7400/10000, Batch Size = 128, Examples/Sec = 12685.69, Accuracy = 0.94, Loss = 0.183\n",
      "[2024-06-28 09:00] Train Step 7410/10000, Batch Size = 128, Examples/Sec = 10894.52, Accuracy = 0.90, Loss = 0.251\n",
      "[2024-06-28 09:00] Train Step 7420/10000, Batch Size = 128, Examples/Sec = 9552.86, Accuracy = 0.94, Loss = 0.212\n",
      "[2024-06-28 09:00] Train Step 7430/10000, Batch Size = 128, Examples/Sec = 11531.72, Accuracy = 0.93, Loss = 0.138\n",
      "[2024-06-28 09:00] Train Step 7440/10000, Batch Size = 128, Examples/Sec = 12294.66, Accuracy = 0.86, Loss = 0.462\n",
      "[2024-06-28 09:00] Train Step 7450/10000, Batch Size = 128, Examples/Sec = 12862.88, Accuracy = 0.90, Loss = 0.349\n",
      "[2024-06-28 09:00] Train Step 7460/10000, Batch Size = 128, Examples/Sec = 13260.00, Accuracy = 0.84, Loss = 0.496\n",
      "[2024-06-28 09:00] Train Step 7470/10000, Batch Size = 128, Examples/Sec = 12408.04, Accuracy = 0.93, Loss = 0.193\n",
      "[2024-06-28 09:00] Train Step 7480/10000, Batch Size = 128, Examples/Sec = 12632.85, Accuracy = 0.95, Loss = 0.178\n",
      "[2024-06-28 09:00] Train Step 7490/10000, Batch Size = 128, Examples/Sec = 11855.38, Accuracy = 0.95, Loss = 0.144\n",
      "[2024-06-28 09:00] Train Step 7500/10000, Batch Size = 128, Examples/Sec = 13932.76, Accuracy = 0.98, Loss = 0.119\n",
      "[2024-06-28 09:00] Train Step 7510/10000, Batch Size = 128, Examples/Sec = 12704.60, Accuracy = 0.98, Loss = 0.110\n",
      "[2024-06-28 09:00] Train Step 7520/10000, Batch Size = 128, Examples/Sec = 12685.69, Accuracy = 0.98, Loss = 0.081\n",
      "[2024-06-28 09:00] Train Step 7530/10000, Batch Size = 128, Examples/Sec = 14341.80, Accuracy = 0.92, Loss = 0.210\n",
      "[2024-06-28 09:00] Train Step 7540/10000, Batch Size = 128, Examples/Sec = 13554.95, Accuracy = 0.95, Loss = 0.144\n",
      "[2024-06-28 09:00] Train Step 7550/10000, Batch Size = 128, Examples/Sec = 13380.63, Accuracy = 0.90, Loss = 0.291\n",
      "[2024-06-28 09:00] Train Step 7560/10000, Batch Size = 128, Examples/Sec = 13629.97, Accuracy = 0.92, Loss = 0.197\n",
      "[2024-06-28 09:00] Train Step 7570/10000, Batch Size = 128, Examples/Sec = 13547.77, Accuracy = 0.98, Loss = 0.092\n",
      "[2024-06-28 09:00] Train Step 7580/10000, Batch Size = 128, Examples/Sec = 12664.44, Accuracy = 0.97, Loss = 0.099\n",
      "[2024-06-28 09:00] Train Step 7590/10000, Batch Size = 128, Examples/Sec = 11733.60, Accuracy = 0.88, Loss = 0.463\n",
      "[2024-06-28 09:00] Train Step 7600/10000, Batch Size = 128, Examples/Sec = 13168.93, Accuracy = 0.86, Loss = 0.438\n",
      "[2024-06-28 09:00] Train Step 7610/10000, Batch Size = 128, Examples/Sec = 13518.77, Accuracy = 0.94, Loss = 0.185\n",
      "[2024-06-28 09:00] Train Step 7620/10000, Batch Size = 128, Examples/Sec = 13679.29, Accuracy = 0.95, Loss = 0.123\n",
      "[2024-06-28 09:00] Train Step 7630/10000, Batch Size = 128, Examples/Sec = 13638.63, Accuracy = 0.95, Loss = 0.162\n",
      "[2024-06-28 09:00] Train Step 7640/10000, Batch Size = 128, Examples/Sec = 10225.92, Accuracy = 0.99, Loss = 0.062\n",
      "[2024-06-28 09:00] Train Step 7650/10000, Batch Size = 128, Examples/Sec = 12535.51, Accuracy = 1.00, Loss = 0.069\n",
      "[2024-06-28 09:00] Train Step 7660/10000, Batch Size = 128, Examples/Sec = 13628.24, Accuracy = 1.00, Loss = 0.048\n",
      "[2024-06-28 09:00] Train Step 7670/10000, Batch Size = 128, Examples/Sec = 14391.78, Accuracy = 0.97, Loss = 0.104\n",
      "[2024-06-28 09:00] Train Step 7680/10000, Batch Size = 128, Examples/Sec = 13800.60, Accuracy = 0.84, Loss = 0.361\n",
      "[2024-06-28 09:00] Train Step 7690/10000, Batch Size = 128, Examples/Sec = 14274.31, Accuracy = 0.84, Loss = 0.419\n",
      "[2024-06-28 09:00] Train Step 7700/10000, Batch Size = 128, Examples/Sec = 14059.37, Accuracy = 0.92, Loss = 0.194\n",
      "[2024-06-28 09:00] Train Step 7710/10000, Batch Size = 128, Examples/Sec = 12241.68, Accuracy = 0.88, Loss = 0.387\n",
      "[2024-06-28 09:00] Train Step 7720/10000, Batch Size = 128, Examples/Sec = 12410.33, Accuracy = 1.00, Loss = 0.078\n",
      "[2024-06-28 09:00] Train Step 7730/10000, Batch Size = 128, Examples/Sec = 11912.20, Accuracy = 0.95, Loss = 0.131\n",
      "[2024-06-28 09:00] Train Step 7740/10000, Batch Size = 128, Examples/Sec = 7187.03, Accuracy = 1.00, Loss = 0.068\n",
      "[2024-06-28 09:00] Train Step 7750/10000, Batch Size = 128, Examples/Sec = 12213.83, Accuracy = 0.95, Loss = 0.126\n",
      "[2024-06-28 09:00] Train Step 7760/10000, Batch Size = 128, Examples/Sec = 10463.28, Accuracy = 0.96, Loss = 0.127\n",
      "[2024-06-28 09:00] Train Step 7770/10000, Batch Size = 128, Examples/Sec = 12407.75, Accuracy = 0.95, Loss = 0.160\n",
      "[2024-06-28 09:00] Train Step 7780/10000, Batch Size = 128, Examples/Sec = 12605.56, Accuracy = 0.99, Loss = 0.064\n",
      "[2024-06-28 09:00] Train Step 7790/10000, Batch Size = 128, Examples/Sec = 13266.88, Accuracy = 0.99, Loss = 0.082\n",
      "[2024-06-28 09:00] Train Step 7800/10000, Batch Size = 128, Examples/Sec = 12265.17, Accuracy = 0.96, Loss = 0.138\n",
      "[2024-06-28 09:00] Train Step 7810/10000, Batch Size = 128, Examples/Sec = 12722.36, Accuracy = 0.90, Loss = 0.350\n",
      "[2024-06-28 09:00] Train Step 7820/10000, Batch Size = 128, Examples/Sec = 7080.02, Accuracy = 0.87, Loss = 0.472\n",
      "[2024-06-28 09:00] Train Step 7830/10000, Batch Size = 128, Examples/Sec = 13575.17, Accuracy = 0.91, Loss = 0.209\n",
      "[2024-06-28 09:00] Train Step 7840/10000, Batch Size = 128, Examples/Sec = 10910.46, Accuracy = 0.92, Loss = 0.342\n",
      "[2024-06-28 09:00] Train Step 7850/10000, Batch Size = 128, Examples/Sec = 11618.32, Accuracy = 0.94, Loss = 0.134\n",
      "[2024-06-28 09:00] Train Step 7860/10000, Batch Size = 128, Examples/Sec = 11562.77, Accuracy = 0.95, Loss = 0.120\n",
      "[2024-06-28 09:00] Train Step 7870/10000, Batch Size = 128, Examples/Sec = 11510.71, Accuracy = 0.99, Loss = 0.075\n",
      "[2024-06-28 09:00] Train Step 7880/10000, Batch Size = 128, Examples/Sec = 13607.17, Accuracy = 0.99, Loss = 0.060\n",
      "[2024-06-28 09:00] Train Step 7890/10000, Batch Size = 128, Examples/Sec = 11605.76, Accuracy = 1.00, Loss = 0.048\n",
      "[2024-06-28 09:00] Train Step 7900/10000, Batch Size = 128, Examples/Sec = 12624.24, Accuracy = 1.00, Loss = 0.058\n",
      "[2024-06-28 09:00] Train Step 7910/10000, Batch Size = 128, Examples/Sec = 13305.68, Accuracy = 1.00, Loss = 0.052\n",
      "[2024-06-28 09:00] Train Step 7920/10000, Batch Size = 128, Examples/Sec = 13010.64, Accuracy = 0.97, Loss = 0.086\n",
      "[2024-06-28 09:00] Train Step 7930/10000, Batch Size = 128, Examples/Sec = 12541.66, Accuracy = 0.94, Loss = 0.236\n",
      "[2024-06-28 09:00] Train Step 7940/10000, Batch Size = 128, Examples/Sec = 12467.10, Accuracy = 0.72, Loss = 1.178\n",
      "[2024-06-28 09:00] Train Step 7950/10000, Batch Size = 128, Examples/Sec = 10565.41, Accuracy = 0.91, Loss = 0.254\n",
      "[2024-06-28 09:00] Train Step 7960/10000, Batch Size = 128, Examples/Sec = 13527.97, Accuracy = 0.94, Loss = 0.213\n",
      "[2024-06-28 09:00] Train Step 7970/10000, Batch Size = 128, Examples/Sec = 12463.34, Accuracy = 0.90, Loss = 0.371\n",
      "[2024-06-28 09:00] Train Step 7980/10000, Batch Size = 128, Examples/Sec = 11421.57, Accuracy = 0.96, Loss = 0.150\n",
      "[2024-06-28 09:00] Train Step 7990/10000, Batch Size = 128, Examples/Sec = 12548.99, Accuracy = 0.99, Loss = 0.057\n",
      "[2024-06-28 09:00] Train Step 8000/10000, Batch Size = 128, Examples/Sec = 13035.59, Accuracy = 0.99, Loss = 0.059\n",
      "[2024-06-28 09:00] Train Step 8010/10000, Batch Size = 128, Examples/Sec = 14370.98, Accuracy = 1.00, Loss = 0.057\n",
      "[2024-06-28 09:00] Train Step 8020/10000, Batch Size = 128, Examples/Sec = 14370.59, Accuracy = 0.99, Loss = 0.047\n",
      "[2024-06-28 09:00] Train Step 8030/10000, Batch Size = 128, Examples/Sec = 14214.59, Accuracy = 1.00, Loss = 0.044\n",
      "[2024-06-28 09:00] Train Step 8040/10000, Batch Size = 128, Examples/Sec = 14517.48, Accuracy = 0.89, Loss = 0.248\n",
      "[2024-06-28 09:00] Train Step 8050/10000, Batch Size = 128, Examples/Sec = 14239.85, Accuracy = 0.84, Loss = 0.514\n",
      "[2024-06-28 09:00] Train Step 8060/10000, Batch Size = 128, Examples/Sec = 14279.24, Accuracy = 0.97, Loss = 0.115\n",
      "[2024-06-28 09:00] Train Step 8070/10000, Batch Size = 128, Examples/Sec = 14129.30, Accuracy = 0.92, Loss = 0.210\n",
      "[2024-06-28 09:00] Train Step 8080/10000, Batch Size = 128, Examples/Sec = 13845.44, Accuracy = 0.96, Loss = 0.142\n",
      "[2024-06-28 09:00] Train Step 8090/10000, Batch Size = 128, Examples/Sec = 13911.10, Accuracy = 1.00, Loss = 0.046\n",
      "[2024-06-28 09:00] Train Step 8100/10000, Batch Size = 128, Examples/Sec = 14356.37, Accuracy = 0.99, Loss = 0.067\n",
      "[2024-06-28 09:00] Train Step 8110/10000, Batch Size = 128, Examples/Sec = 14593.25, Accuracy = 0.99, Loss = 0.059\n",
      "[2024-06-28 09:00] Train Step 8120/10000, Batch Size = 128, Examples/Sec = 13926.61, Accuracy = 1.00, Loss = 0.037\n",
      "[2024-06-28 09:00] Train Step 8130/10000, Batch Size = 128, Examples/Sec = 14369.05, Accuracy = 0.89, Loss = 0.391\n",
      "[2024-06-28 09:00] Train Step 8140/10000, Batch Size = 128, Examples/Sec = 14242.50, Accuracy = 0.94, Loss = 0.194\n",
      "[2024-06-28 09:00] Train Step 8150/10000, Batch Size = 128, Examples/Sec = 14395.25, Accuracy = 0.78, Loss = 0.657\n",
      "[2024-06-28 09:00] Train Step 8160/10000, Batch Size = 128, Examples/Sec = 13156.34, Accuracy = 0.85, Loss = 0.355\n",
      "[2024-06-28 09:00] Train Step 8170/10000, Batch Size = 128, Examples/Sec = 14107.76, Accuracy = 0.95, Loss = 0.139\n",
      "[2024-06-28 09:00] Train Step 8180/10000, Batch Size = 128, Examples/Sec = 14271.65, Accuracy = 0.89, Loss = 0.289\n",
      "[2024-06-28 09:00] Train Step 8190/10000, Batch Size = 128, Examples/Sec = 14650.19, Accuracy = 0.97, Loss = 0.105\n",
      "[2024-06-28 09:00] Train Step 8200/10000, Batch Size = 128, Examples/Sec = 13599.59, Accuracy = 1.00, Loss = 0.076\n",
      "[2024-06-28 09:00] Train Step 8210/10000, Batch Size = 128, Examples/Sec = 13287.90, Accuracy = 0.99, Loss = 0.069\n",
      "[2024-06-28 09:00] Train Step 8220/10000, Batch Size = 128, Examples/Sec = 14237.96, Accuracy = 1.00, Loss = 0.036\n",
      "[2024-06-28 09:00] Train Step 8230/10000, Batch Size = 128, Examples/Sec = 12573.38, Accuracy = 1.00, Loss = 0.042\n",
      "[2024-06-28 09:00] Train Step 8240/10000, Batch Size = 128, Examples/Sec = 14179.30, Accuracy = 1.00, Loss = 0.050\n",
      "[2024-06-28 09:00] Train Step 8250/10000, Batch Size = 128, Examples/Sec = 13595.45, Accuracy = 0.99, Loss = 0.061\n",
      "[2024-06-28 09:00] Train Step 8260/10000, Batch Size = 128, Examples/Sec = 14369.05, Accuracy = 0.99, Loss = 0.051\n",
      "[2024-06-28 09:00] Train Step 8270/10000, Batch Size = 128, Examples/Sec = 14050.53, Accuracy = 1.00, Loss = 0.040\n",
      "[2024-06-28 09:00] Train Step 8280/10000, Batch Size = 128, Examples/Sec = 12807.65, Accuracy = 1.00, Loss = 0.035\n",
      "[2024-06-28 09:00] Train Step 8290/10000, Batch Size = 128, Examples/Sec = 14203.31, Accuracy = 1.00, Loss = 0.036\n",
      "[2024-06-28 09:00] Train Step 8300/10000, Batch Size = 128, Examples/Sec = 14178.18, Accuracy = 1.00, Loss = 0.029\n",
      "[2024-06-28 09:00] Train Step 8310/10000, Batch Size = 128, Examples/Sec = 14035.11, Accuracy = 0.84, Loss = 0.484\n",
      "[2024-06-28 09:00] Train Step 8320/10000, Batch Size = 128, Examples/Sec = 12369.44, Accuracy = 0.83, Loss = 0.506\n",
      "[2024-06-28 09:00] Train Step 8330/10000, Batch Size = 128, Examples/Sec = 11259.88, Accuracy = 0.93, Loss = 0.212\n",
      "[2024-06-28 09:00] Train Step 8340/10000, Batch Size = 128, Examples/Sec = 10559.59, Accuracy = 0.80, Loss = 0.542\n",
      "[2024-06-28 09:00] Train Step 8350/10000, Batch Size = 128, Examples/Sec = 12754.10, Accuracy = 0.94, Loss = 0.165\n",
      "[2024-06-28 09:00] Train Step 8360/10000, Batch Size = 128, Examples/Sec = 11285.44, Accuracy = 0.94, Loss = 0.169\n",
      "[2024-06-28 09:00] Train Step 8370/10000, Batch Size = 128, Examples/Sec = 12861.65, Accuracy = 0.98, Loss = 0.114\n",
      "[2024-06-28 09:00] Train Step 8380/10000, Batch Size = 128, Examples/Sec = 13109.76, Accuracy = 0.99, Loss = 0.071\n",
      "[2024-06-28 09:00] Train Step 8390/10000, Batch Size = 128, Examples/Sec = 12947.88, Accuracy = 1.00, Loss = 0.041\n",
      "[2024-06-28 09:00] Train Step 8400/10000, Batch Size = 128, Examples/Sec = 13018.84, Accuracy = 1.00, Loss = 0.047\n",
      "[2024-06-28 09:00] Train Step 8410/10000, Batch Size = 128, Examples/Sec = 11829.00, Accuracy = 1.00, Loss = 0.039\n",
      "[2024-06-28 09:00] Train Step 8420/10000, Batch Size = 128, Examples/Sec = 12596.10, Accuracy = 0.99, Loss = 0.069\n",
      "[2024-06-28 09:00] Train Step 8430/10000, Batch Size = 128, Examples/Sec = 11830.82, Accuracy = 1.00, Loss = 0.056\n",
      "[2024-06-28 09:00] Train Step 8440/10000, Batch Size = 128, Examples/Sec = 13172.81, Accuracy = 1.00, Loss = 0.041\n",
      "[2024-06-28 09:00] Train Step 8450/10000, Batch Size = 128, Examples/Sec = 10679.11, Accuracy = 1.00, Loss = 0.026\n",
      "[2024-06-28 09:00] Train Step 8460/10000, Batch Size = 128, Examples/Sec = 12886.35, Accuracy = 1.00, Loss = 0.029\n",
      "[2024-06-28 09:00] Train Step 8470/10000, Batch Size = 128, Examples/Sec = 13974.10, Accuracy = 0.84, Loss = 0.576\n",
      "[2024-06-28 09:00] Train Step 8480/10000, Batch Size = 128, Examples/Sec = 12847.49, Accuracy = 0.90, Loss = 0.223\n",
      "[2024-06-28 09:00] Train Step 8490/10000, Batch Size = 128, Examples/Sec = 11677.71, Accuracy = 0.95, Loss = 0.175\n",
      "[2024-06-28 09:00] Train Step 8500/10000, Batch Size = 128, Examples/Sec = 12527.03, Accuracy = 0.99, Loss = 0.048\n",
      "[2024-06-28 09:00] Train Step 8510/10000, Batch Size = 128, Examples/Sec = 10740.86, Accuracy = 1.00, Loss = 0.031\n",
      "[2024-06-28 09:00] Train Step 8520/10000, Batch Size = 128, Examples/Sec = 12381.71, Accuracy = 0.99, Loss = 0.105\n",
      "[2024-06-28 09:00] Train Step 8530/10000, Batch Size = 128, Examples/Sec = 10341.74, Accuracy = 0.99, Loss = 0.074\n",
      "[2024-06-28 09:00] Train Step 8540/10000, Batch Size = 128, Examples/Sec = 12857.95, Accuracy = 0.84, Loss = 0.454\n",
      "[2024-06-28 09:00] Train Step 8550/10000, Batch Size = 128, Examples/Sec = 12530.54, Accuracy = 0.98, Loss = 0.085\n",
      "[2024-06-28 09:00] Train Step 8560/10000, Batch Size = 128, Examples/Sec = 12876.15, Accuracy = 0.99, Loss = 0.064\n",
      "[2024-06-28 09:00] Train Step 8570/10000, Batch Size = 128, Examples/Sec = 12907.10, Accuracy = 1.00, Loss = 0.031\n",
      "[2024-06-28 09:00] Train Step 8580/10000, Batch Size = 128, Examples/Sec = 12341.86, Accuracy = 0.99, Loss = 0.050\n",
      "[2024-06-28 09:00] Train Step 8590/10000, Batch Size = 128, Examples/Sec = 12165.39, Accuracy = 0.98, Loss = 0.060\n",
      "[2024-06-28 09:00] Train Step 8600/10000, Batch Size = 128, Examples/Sec = 12426.99, Accuracy = 1.00, Loss = 0.039\n",
      "[2024-06-28 09:00] Train Step 8610/10000, Batch Size = 128, Examples/Sec = 12055.85, Accuracy = 1.00, Loss = 0.040\n",
      "[2024-06-28 09:00] Train Step 8620/10000, Batch Size = 128, Examples/Sec = 13992.31, Accuracy = 0.99, Loss = 0.046\n",
      "[2024-06-28 09:00] Train Step 8630/10000, Batch Size = 128, Examples/Sec = 13265.57, Accuracy = 0.71, Loss = 0.927\n",
      "[2024-06-28 09:00] Train Step 8640/10000, Batch Size = 128, Examples/Sec = 14231.93, Accuracy = 0.72, Loss = 0.780\n",
      "[2024-06-28 09:00] Train Step 8650/10000, Batch Size = 128, Examples/Sec = 10906.47, Accuracy = 0.77, Loss = 0.633\n",
      "[2024-06-28 09:00] Train Step 8660/10000, Batch Size = 128, Examples/Sec = 13011.90, Accuracy = 0.83, Loss = 0.525\n",
      "[2024-06-28 09:00] Train Step 8670/10000, Batch Size = 128, Examples/Sec = 13477.71, Accuracy = 0.88, Loss = 0.394\n",
      "[2024-06-28 09:00] Train Step 8680/10000, Batch Size = 128, Examples/Sec = 12074.28, Accuracy = 0.91, Loss = 0.278\n",
      "[2024-06-28 09:00] Train Step 8690/10000, Batch Size = 128, Examples/Sec = 13159.25, Accuracy = 0.96, Loss = 0.100\n",
      "[2024-06-28 09:00] Train Step 8700/10000, Batch Size = 128, Examples/Sec = 13117.45, Accuracy = 0.98, Loss = 0.065\n",
      "[2024-06-28 09:00] Train Step 8710/10000, Batch Size = 128, Examples/Sec = 12308.75, Accuracy = 1.00, Loss = 0.039\n",
      "[2024-06-28 09:00] Train Step 8720/10000, Batch Size = 128, Examples/Sec = 12213.55, Accuracy = 1.00, Loss = 0.037\n",
      "[2024-06-28 09:00] Train Step 8730/10000, Batch Size = 128, Examples/Sec = 13553.24, Accuracy = 1.00, Loss = 0.025\n",
      "[2024-06-28 09:00] Train Step 8740/10000, Batch Size = 128, Examples/Sec = 13699.88, Accuracy = 1.00, Loss = 0.031\n",
      "[2024-06-28 09:00] Train Step 8750/10000, Batch Size = 128, Examples/Sec = 13890.22, Accuracy = 1.00, Loss = 0.027\n",
      "[2024-06-28 09:00] Train Step 8760/10000, Batch Size = 128, Examples/Sec = 12702.49, Accuracy = 1.00, Loss = 0.041\n",
      "[2024-06-28 09:00] Train Step 8770/10000, Batch Size = 128, Examples/Sec = 12279.47, Accuracy = 1.00, Loss = 0.032\n",
      "[2024-06-28 09:00] Train Step 8780/10000, Batch Size = 128, Examples/Sec = 13251.82, Accuracy = 0.99, Loss = 0.052\n",
      "[2024-06-28 09:00] Train Step 8790/10000, Batch Size = 128, Examples/Sec = 13440.93, Accuracy = 1.00, Loss = 0.051\n",
      "[2024-06-28 09:00] Train Step 8800/10000, Batch Size = 128, Examples/Sec = 13123.22, Accuracy = 1.00, Loss = 0.035\n",
      "[2024-06-28 09:00] Train Step 8810/10000, Batch Size = 128, Examples/Sec = 10829.25, Accuracy = 1.00, Loss = 0.022\n",
      "[2024-06-28 09:00] Train Step 8820/10000, Batch Size = 128, Examples/Sec = 10971.10, Accuracy = 0.99, Loss = 0.035\n",
      "[2024-06-28 09:00] Train Step 8830/10000, Batch Size = 128, Examples/Sec = 12925.12, Accuracy = 0.99, Loss = 0.064\n",
      "[2024-06-28 09:00] Train Step 8840/10000, Batch Size = 128, Examples/Sec = 13548.79, Accuracy = 1.00, Loss = 0.036\n",
      "[2024-06-28 09:00] Train Step 8850/10000, Batch Size = 128, Examples/Sec = 14063.05, Accuracy = 1.00, Loss = 0.027\n",
      "[2024-06-28 09:00] Train Step 8860/10000, Batch Size = 128, Examples/Sec = 13805.21, Accuracy = 0.99, Loss = 0.051\n",
      "[2024-06-28 09:00] Train Step 8870/10000, Batch Size = 128, Examples/Sec = 13946.51, Accuracy = 0.75, Loss = 1.017\n",
      "[2024-06-28 09:00] Train Step 8880/10000, Batch Size = 128, Examples/Sec = 14061.57, Accuracy = 0.85, Loss = 0.452\n",
      "[2024-06-28 09:00] Train Step 8890/10000, Batch Size = 128, Examples/Sec = 13865.11, Accuracy = 0.88, Loss = 0.399\n",
      "[2024-06-28 09:00] Train Step 8900/10000, Batch Size = 128, Examples/Sec = 14341.42, Accuracy = 0.85, Loss = 0.475\n",
      "[2024-06-28 09:00] Train Step 8910/10000, Batch Size = 128, Examples/Sec = 12616.82, Accuracy = 0.93, Loss = 0.207\n",
      "[2024-06-28 09:00] Train Step 8920/10000, Batch Size = 128, Examples/Sec = 10922.44, Accuracy = 0.99, Loss = 0.050\n",
      "[2024-06-28 09:00] Train Step 8930/10000, Batch Size = 128, Examples/Sec = 12962.26, Accuracy = 0.98, Loss = 0.054\n",
      "[2024-06-28 09:00] Train Step 8940/10000, Batch Size = 128, Examples/Sec = 12969.78, Accuracy = 0.99, Loss = 0.045\n",
      "[2024-06-28 09:00] Train Step 8950/10000, Batch Size = 128, Examples/Sec = 10539.28, Accuracy = 1.00, Loss = 0.026\n",
      "[2024-06-28 09:00] Train Step 8960/10000, Batch Size = 128, Examples/Sec = 12420.38, Accuracy = 1.00, Loss = 0.028\n",
      "[2024-06-28 09:00] Train Step 8970/10000, Batch Size = 128, Examples/Sec = 12532.88, Accuracy = 1.00, Loss = 0.038\n",
      "[2024-06-28 09:00] Train Step 8980/10000, Batch Size = 128, Examples/Sec = 13057.47, Accuracy = 1.00, Loss = 0.033\n",
      "[2024-06-28 09:00] Train Step 8990/10000, Batch Size = 128, Examples/Sec = 13361.31, Accuracy = 0.99, Loss = 0.049\n",
      "[2024-06-28 09:00] Train Step 9000/10000, Batch Size = 128, Examples/Sec = 12541.66, Accuracy = 1.00, Loss = 0.023\n",
      "[2024-06-28 09:00] Train Step 9010/10000, Batch Size = 128, Examples/Sec = 14058.26, Accuracy = 1.00, Loss = 0.021\n",
      "[2024-06-28 09:00] Train Step 9020/10000, Batch Size = 128, Examples/Sec = 13137.35, Accuracy = 1.00, Loss = 0.022\n",
      "[2024-06-28 09:00] Train Step 9030/10000, Batch Size = 128, Examples/Sec = 14622.26, Accuracy = 1.00, Loss = 0.025\n",
      "[2024-06-28 09:00] Train Step 9040/10000, Batch Size = 128, Examples/Sec = 13379.29, Accuracy = 1.00, Loss = 0.019\n",
      "[2024-06-28 09:00] Train Step 9050/10000, Batch Size = 128, Examples/Sec = 12710.91, Accuracy = 1.00, Loss = 0.027\n",
      "[2024-06-28 09:00] Train Step 9060/10000, Batch Size = 128, Examples/Sec = 12173.39, Accuracy = 1.00, Loss = 0.018\n",
      "[2024-06-28 09:00] Train Step 9070/10000, Batch Size = 128, Examples/Sec = 12706.40, Accuracy = 1.00, Loss = 0.022\n",
      "[2024-06-28 09:00] Train Step 9080/10000, Batch Size = 128, Examples/Sec = 10841.93, Accuracy = 1.00, Loss = 0.022\n",
      "[2024-06-28 09:00] Train Step 9090/10000, Batch Size = 128, Examples/Sec = 12685.69, Accuracy = 0.98, Loss = 0.076\n",
      "[2024-06-28 09:00] Train Step 9100/10000, Batch Size = 128, Examples/Sec = 12448.89, Accuracy = 0.77, Loss = 0.889\n",
      "[2024-06-28 09:00] Train Step 9110/10000, Batch Size = 128, Examples/Sec = 13857.24, Accuracy = 0.73, Loss = 0.868\n",
      "[2024-06-28 09:00] Train Step 9120/10000, Batch Size = 128, Examples/Sec = 14188.67, Accuracy = 0.89, Loss = 0.262\n",
      "[2024-06-28 09:00] Train Step 9130/10000, Batch Size = 128, Examples/Sec = 13411.71, Accuracy = 1.00, Loss = 0.067\n",
      "[2024-06-28 09:00] Train Step 9140/10000, Batch Size = 128, Examples/Sec = 13217.89, Accuracy = 0.98, Loss = 0.110\n",
      "[2024-06-28 09:00] Train Step 9150/10000, Batch Size = 128, Examples/Sec = 12718.44, Accuracy = 0.98, Loss = 0.063\n",
      "[2024-06-28 09:00] Train Step 9160/10000, Batch Size = 128, Examples/Sec = 14288.36, Accuracy = 0.99, Loss = 0.071\n",
      "[2024-06-28 09:00] Train Step 9170/10000, Batch Size = 128, Examples/Sec = 12600.83, Accuracy = 1.00, Loss = 0.038\n",
      "[2024-06-28 09:00] Train Step 9180/10000, Batch Size = 128, Examples/Sec = 14297.11, Accuracy = 1.00, Loss = 0.034\n",
      "[2024-06-28 09:00] Train Step 9190/10000, Batch Size = 128, Examples/Sec = 14486.53, Accuracy = 1.00, Loss = 0.027\n",
      "[2024-06-28 09:00] Train Step 9200/10000, Batch Size = 128, Examples/Sec = 13661.88, Accuracy = 1.00, Loss = 0.030\n",
      "[2024-06-28 09:00] Train Step 9210/10000, Batch Size = 128, Examples/Sec = 14321.14, Accuracy = 1.00, Loss = 0.024\n",
      "[2024-06-28 09:00] Train Step 9220/10000, Batch Size = 128, Examples/Sec = 13654.93, Accuracy = 1.00, Loss = 0.030\n",
      "[2024-06-28 09:00] Train Step 9230/10000, Batch Size = 128, Examples/Sec = 13414.39, Accuracy = 1.00, Loss = 0.026\n",
      "[2024-06-28 09:00] Train Step 9240/10000, Batch Size = 128, Examples/Sec = 13854.38, Accuracy = 1.00, Loss = 0.026\n",
      "[2024-06-28 09:00] Train Step 9250/10000, Batch Size = 128, Examples/Sec = 14032.17, Accuracy = 1.00, Loss = 0.024\n",
      "[2024-06-28 09:00] Train Step 9260/10000, Batch Size = 128, Examples/Sec = 12678.50, Accuracy = 0.91, Loss = 0.354\n",
      "[2024-06-28 09:00] Train Step 9270/10000, Batch Size = 128, Examples/Sec = 11462.05, Accuracy = 0.64, Loss = 1.083\n",
      "[2024-06-28 09:00] Train Step 9280/10000, Batch Size = 128, Examples/Sec = 11688.39, Accuracy = 0.72, Loss = 1.038\n",
      "[2024-06-28 09:00] Train Step 9290/10000, Batch Size = 128, Examples/Sec = 12989.55, Accuracy = 0.86, Loss = 0.443\n",
      "[2024-06-28 09:00] Train Step 9300/10000, Batch Size = 128, Examples/Sec = 10695.07, Accuracy = 0.86, Loss = 0.321\n",
      "[2024-06-28 09:00] Train Step 9310/10000, Batch Size = 128, Examples/Sec = 7651.00, Accuracy = 0.93, Loss = 0.173\n",
      "[2024-06-28 09:00] Train Step 9320/10000, Batch Size = 128, Examples/Sec = 12448.89, Accuracy = 0.95, Loss = 0.173\n",
      "[2024-06-28 09:00] Train Step 9330/10000, Batch Size = 128, Examples/Sec = 11404.34, Accuracy = 0.98, Loss = 0.075\n",
      "[2024-06-28 09:00] Train Step 9340/10000, Batch Size = 128, Examples/Sec = 12450.05, Accuracy = 0.99, Loss = 0.065\n",
      "[2024-06-28 09:00] Train Step 9350/10000, Batch Size = 128, Examples/Sec = 12851.49, Accuracy = 0.98, Loss = 0.066\n",
      "[2024-06-28 09:00] Train Step 9360/10000, Batch Size = 128, Examples/Sec = 13594.08, Accuracy = 0.95, Loss = 0.220\n",
      "[2024-06-28 09:00] Train Step 9370/10000, Batch Size = 128, Examples/Sec = 12629.29, Accuracy = 0.98, Loss = 0.083\n",
      "[2024-06-28 09:00] Train Step 9380/10000, Batch Size = 128, Examples/Sec = 12801.54, Accuracy = 0.93, Loss = 0.176\n",
      "[2024-06-28 09:00] Train Step 9390/10000, Batch Size = 128, Examples/Sec = 12843.80, Accuracy = 0.95, Loss = 0.124\n",
      "[2024-06-28 09:00] Train Step 9400/10000, Batch Size = 128, Examples/Sec = 12009.73, Accuracy = 0.98, Loss = 0.112\n",
      "[2024-06-28 09:00] Train Step 9410/10000, Batch Size = 128, Examples/Sec = 13004.33, Accuracy = 0.91, Loss = 0.267\n",
      "[2024-06-28 09:00] Train Step 9420/10000, Batch Size = 128, Examples/Sec = 12683.29, Accuracy = 0.98, Loss = 0.078\n",
      "[2024-06-28 09:00] Train Step 9430/10000, Batch Size = 128, Examples/Sec = 12394.86, Accuracy = 0.98, Loss = 0.083\n",
      "[2024-06-28 09:00] Train Step 9440/10000, Batch Size = 128, Examples/Sec = 13188.99, Accuracy = 0.98, Loss = 0.120\n",
      "[2024-06-28 09:00] Train Step 9450/10000, Batch Size = 128, Examples/Sec = 11961.30, Accuracy = 0.99, Loss = 0.065\n",
      "[2024-06-28 09:00] Train Step 9460/10000, Batch Size = 128, Examples/Sec = 12084.61, Accuracy = 0.92, Loss = 0.229\n",
      "[2024-06-28 09:00] Train Step 9470/10000, Batch Size = 128, Examples/Sec = 12219.66, Accuracy = 0.94, Loss = 0.141\n",
      "[2024-06-28 09:00] Train Step 9480/10000, Batch Size = 128, Examples/Sec = 12046.92, Accuracy = 0.99, Loss = 0.066\n",
      "[2024-06-28 09:00] Train Step 9490/10000, Batch Size = 128, Examples/Sec = 12385.14, Accuracy = 0.98, Loss = 0.065\n",
      "[2024-06-28 09:00] Train Step 9500/10000, Batch Size = 128, Examples/Sec = 11088.25, Accuracy = 1.00, Loss = 0.041\n",
      "[2024-06-28 09:00] Train Step 9510/10000, Batch Size = 128, Examples/Sec = 11349.62, Accuracy = 1.00, Loss = 0.037\n",
      "[2024-06-28 09:00] Train Step 9520/10000, Batch Size = 128, Examples/Sec = 12002.75, Accuracy = 0.99, Loss = 0.043\n",
      "[2024-06-28 09:00] Train Step 9530/10000, Batch Size = 128, Examples/Sec = 11135.40, Accuracy = 1.00, Loss = 0.049\n",
      "[2024-06-28 09:00] Train Step 9540/10000, Batch Size = 128, Examples/Sec = 9653.69, Accuracy = 1.00, Loss = 0.041\n",
      "[2024-06-28 09:00] Train Step 9550/10000, Batch Size = 128, Examples/Sec = 12252.01, Accuracy = 1.00, Loss = 0.035\n",
      "[2024-06-28 09:00] Train Step 9560/10000, Batch Size = 128, Examples/Sec = 12571.32, Accuracy = 1.00, Loss = 0.040\n",
      "[2024-06-28 09:00] Train Step 9570/10000, Batch Size = 128, Examples/Sec = 10609.05, Accuracy = 1.00, Loss = 0.033\n",
      "[2024-06-28 09:00] Train Step 9580/10000, Batch Size = 128, Examples/Sec = 12351.51, Accuracy = 1.00, Loss = 0.022\n",
      "[2024-06-28 09:00] Train Step 9590/10000, Batch Size = 128, Examples/Sec = 11473.81, Accuracy = 1.00, Loss = 0.026\n",
      "[2024-06-28 09:00] Train Step 9600/10000, Batch Size = 128, Examples/Sec = 11333.56, Accuracy = 1.00, Loss = 0.030\n",
      "[2024-06-28 09:00] Train Step 9610/10000, Batch Size = 128, Examples/Sec = 13527.63, Accuracy = 1.00, Loss = 0.021\n",
      "[2024-06-28 09:00] Train Step 9620/10000, Batch Size = 128, Examples/Sec = 13240.71, Accuracy = 1.00, Loss = 0.030\n",
      "[2024-06-28 09:00] Train Step 9630/10000, Batch Size = 128, Examples/Sec = 10761.52, Accuracy = 1.00, Loss = 0.030\n",
      "[2024-06-28 09:00] Train Step 9640/10000, Batch Size = 128, Examples/Sec = 12489.15, Accuracy = 1.00, Loss = 0.026\n",
      "[2024-06-28 09:00] Train Step 9650/10000, Batch Size = 128, Examples/Sec = 13808.05, Accuracy = 0.66, Loss = 1.120\n",
      "[2024-06-28 09:00] Train Step 9660/10000, Batch Size = 128, Examples/Sec = 13363.97, Accuracy = 0.77, Loss = 0.718\n",
      "[2024-06-28 09:00] Train Step 9670/10000, Batch Size = 128, Examples/Sec = 14372.51, Accuracy = 0.77, Loss = 0.767\n",
      "[2024-06-28 09:00] Train Step 9680/10000, Batch Size = 128, Examples/Sec = 14637.01, Accuracy = 0.79, Loss = 0.598\n",
      "[2024-06-28 09:00] Train Step 9690/10000, Batch Size = 128, Examples/Sec = 14305.88, Accuracy = 0.79, Loss = 0.496\n",
      "[2024-06-28 09:00] Train Step 9700/10000, Batch Size = 128, Examples/Sec = 12726.28, Accuracy = 0.89, Loss = 0.221\n",
      "[2024-06-28 09:00] Train Step 9710/10000, Batch Size = 128, Examples/Sec = 13947.96, Accuracy = 0.97, Loss = 0.160\n",
      "[2024-06-28 09:00] Train Step 9720/10000, Batch Size = 128, Examples/Sec = 12541.37, Accuracy = 0.98, Loss = 0.154\n",
      "[2024-06-28 09:00] Train Step 9730/10000, Batch Size = 128, Examples/Sec = 12411.19, Accuracy = 0.95, Loss = 0.177\n",
      "[2024-06-28 09:00] Train Step 9740/10000, Batch Size = 128, Examples/Sec = 12062.08, Accuracy = 0.99, Loss = 0.058\n",
      "[2024-06-28 09:00] Train Step 9750/10000, Batch Size = 128, Examples/Sec = 11350.58, Accuracy = 0.97, Loss = 0.102\n",
      "[2024-06-28 09:00] Train Step 9760/10000, Batch Size = 128, Examples/Sec = 11038.32, Accuracy = 0.98, Loss = 0.051\n",
      "[2024-06-28 09:00] Train Step 9770/10000, Batch Size = 128, Examples/Sec = 12133.77, Accuracy = 0.99, Loss = 0.055\n",
      "[2024-06-28 09:00] Train Step 9780/10000, Batch Size = 128, Examples/Sec = 14126.32, Accuracy = 0.97, Loss = 0.083\n",
      "[2024-06-28 09:00] Train Step 9790/10000, Batch Size = 128, Examples/Sec = 14385.22, Accuracy = 1.00, Loss = 0.040\n",
      "[2024-06-28 09:00] Train Step 9800/10000, Batch Size = 128, Examples/Sec = 12992.06, Accuracy = 1.00, Loss = 0.037\n",
      "[2024-06-28 09:00] Train Step 9810/10000, Batch Size = 128, Examples/Sec = 11126.63, Accuracy = 0.89, Loss = 0.266\n",
      "[2024-06-28 09:00] Train Step 9820/10000, Batch Size = 128, Examples/Sec = 11643.77, Accuracy = 0.97, Loss = 0.109\n",
      "[2024-06-28 09:00] Train Step 9830/10000, Batch Size = 128, Examples/Sec = 12576.03, Accuracy = 1.00, Loss = 0.041\n",
      "[2024-06-28 09:00] Train Step 9840/10000, Batch Size = 128, Examples/Sec = 11473.81, Accuracy = 0.98, Loss = 0.055\n",
      "[2024-06-28 09:00] Train Step 9850/10000, Batch Size = 128, Examples/Sec = 11076.58, Accuracy = 1.00, Loss = 0.025\n",
      "[2024-06-28 09:00] Train Step 9860/10000, Batch Size = 128, Examples/Sec = 12661.75, Accuracy = 1.00, Loss = 0.031\n",
      "[2024-06-28 09:00] Train Step 9870/10000, Batch Size = 128, Examples/Sec = 12664.14, Accuracy = 0.99, Loss = 0.040\n",
      "[2024-06-28 09:00] Train Step 9880/10000, Batch Size = 128, Examples/Sec = 12932.91, Accuracy = 1.00, Loss = 0.034\n",
      "[2024-06-28 09:00] Train Step 9890/10000, Batch Size = 128, Examples/Sec = 13758.86, Accuracy = 1.00, Loss = 0.031\n",
      "[2024-06-28 09:00] Train Step 9900/10000, Batch Size = 128, Examples/Sec = 13517.75, Accuracy = 0.99, Loss = 0.034\n",
      "[2024-06-28 09:00] Train Step 9910/10000, Batch Size = 128, Examples/Sec = 14007.64, Accuracy = 0.99, Loss = 0.043\n",
      "[2024-06-28 09:00] Train Step 9920/10000, Batch Size = 128, Examples/Sec = 13984.29, Accuracy = 1.00, Loss = 0.016\n",
      "[2024-06-28 09:00] Train Step 9930/10000, Batch Size = 128, Examples/Sec = 14325.73, Accuracy = 1.00, Loss = 0.023\n",
      "[2024-06-28 09:00] Train Step 9940/10000, Batch Size = 128, Examples/Sec = 14145.31, Accuracy = 1.00, Loss = 0.020\n",
      "[2024-06-28 09:00] Train Step 9950/10000, Batch Size = 128, Examples/Sec = 14271.27, Accuracy = 1.00, Loss = 0.021\n",
      "[2024-06-28 09:00] Train Step 9960/10000, Batch Size = 128, Examples/Sec = 14530.45, Accuracy = 1.00, Loss = 0.015\n",
      "[2024-06-28 09:00] Train Step 9970/10000, Batch Size = 128, Examples/Sec = 14225.51, Accuracy = 1.00, Loss = 0.017\n",
      "[2024-06-28 09:00] Train Step 9980/10000, Batch Size = 128, Examples/Sec = 14454.94, Accuracy = 1.00, Loss = 0.020\n",
      "[2024-06-28 09:00] Train Step 9990/10000, Batch Size = 128, Examples/Sec = 13590.98, Accuracy = 1.00, Loss = 0.017\n",
      "[2024-06-28 09:00] Train Step 10000/10000, Batch Size = 128, Examples/Sec = 12626.91, Accuracy = 1.00, Loss = 0.030\n",
      "Done training.\n"
     ]
    }
   ],
   "source": [
    "model, _, _= train(config, verbosity=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's 128 examples to make sure it actually worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1, 0, 0, 1], prediction = 2, groud truth = 2\n",
      "[6, 4, 1, 1, 4], prediction = 6, groud truth = 6\n",
      "[4, 0, 5, 5, 0], prediction = 4, groud truth = 4\n",
      "[7, 0, 0, 0, 0], prediction = 7, groud truth = 7\n",
      "[8, 4, 0, 0, 4], prediction = 8, groud truth = 8\n",
      "[2, 2, 2, 2, 2], prediction = 2, groud truth = 2\n",
      "[7, 7, 3, 3, 7], prediction = 7, groud truth = 7\n",
      "[4, 9, 3, 3, 9], prediction = 4, groud truth = 4\n",
      "[9, 4, 0, 0, 4], prediction = 9, groud truth = 9\n",
      "[0, 7, 1, 1, 7], prediction = 0, groud truth = 0\n",
      "[7, 5, 7, 7, 5], prediction = 7, groud truth = 7\n",
      "[4, 4, 0, 0, 4], prediction = 4, groud truth = 4\n",
      "[9, 5, 4, 4, 5], prediction = 9, groud truth = 9\n",
      "[3, 1, 0, 0, 1], prediction = 3, groud truth = 3\n",
      "[9, 9, 2, 2, 9], prediction = 9, groud truth = 9\n",
      "[9, 4, 2, 2, 4], prediction = 9, groud truth = 9\n",
      "[0, 5, 3, 3, 5], prediction = 0, groud truth = 0\n",
      "[8, 8, 9, 9, 8], prediction = 8, groud truth = 8\n",
      "[7, 4, 8, 8, 4], prediction = 7, groud truth = 7\n",
      "[3, 6, 2, 2, 6], prediction = 3, groud truth = 3\n",
      "[6, 2, 6, 6, 2], prediction = 6, groud truth = 6\n",
      "[5, 1, 8, 8, 1], prediction = 5, groud truth = 5\n",
      "[9, 4, 8, 8, 4], prediction = 9, groud truth = 9\n",
      "[1, 2, 8, 8, 2], prediction = 1, groud truth = 1\n",
      "[0, 9, 8, 8, 9], prediction = 0, groud truth = 0\n",
      "[5, 3, 8, 8, 3], prediction = 5, groud truth = 5\n",
      "[3, 2, 6, 6, 2], prediction = 3, groud truth = 3\n",
      "[6, 7, 3, 3, 7], prediction = 6, groud truth = 6\n",
      "[5, 2, 4, 4, 2], prediction = 5, groud truth = 5\n",
      "[3, 5, 9, 9, 5], prediction = 3, groud truth = 3\n",
      "[4, 8, 9, 9, 8], prediction = 4, groud truth = 4\n",
      "[0, 1, 3, 3, 1], prediction = 0, groud truth = 0\n",
      "[5, 3, 8, 8, 3], prediction = 5, groud truth = 5\n",
      "[8, 8, 8, 8, 8], prediction = 8, groud truth = 8\n",
      "[4, 5, 6, 6, 5], prediction = 4, groud truth = 4\n",
      "[1, 7, 1, 1, 7], prediction = 1, groud truth = 1\n",
      "[1, 0, 5, 5, 0], prediction = 1, groud truth = 1\n",
      "[4, 7, 2, 2, 7], prediction = 4, groud truth = 4\n",
      "[8, 4, 6, 6, 4], prediction = 8, groud truth = 8\n",
      "[8, 1, 6, 6, 1], prediction = 8, groud truth = 8\n",
      "[0, 0, 7, 7, 0], prediction = 0, groud truth = 0\n",
      "[4, 2, 1, 1, 2], prediction = 4, groud truth = 4\n",
      "[0, 9, 6, 6, 9], prediction = 0, groud truth = 0\n",
      "[2, 0, 1, 1, 0], prediction = 2, groud truth = 2\n",
      "[5, 2, 3, 3, 2], prediction = 5, groud truth = 5\n",
      "[2, 8, 9, 9, 8], prediction = 2, groud truth = 2\n",
      "[7, 5, 1, 1, 5], prediction = 7, groud truth = 7\n",
      "[9, 9, 4, 4, 9], prediction = 9, groud truth = 9\n",
      "[3, 6, 4, 4, 6], prediction = 3, groud truth = 3\n",
      "[0, 7, 7, 7, 7], prediction = 0, groud truth = 0\n",
      "[0, 0, 9, 9, 0], prediction = 0, groud truth = 0\n",
      "[4, 5, 2, 2, 5], prediction = 4, groud truth = 4\n",
      "[1, 5, 8, 8, 5], prediction = 1, groud truth = 1\n",
      "[8, 5, 2, 2, 5], prediction = 8, groud truth = 8\n",
      "[7, 6, 1, 1, 6], prediction = 7, groud truth = 7\n",
      "[6, 1, 8, 8, 1], prediction = 6, groud truth = 6\n",
      "[7, 0, 2, 2, 0], prediction = 7, groud truth = 7\n",
      "[7, 5, 0, 0, 5], prediction = 7, groud truth = 7\n",
      "[6, 9, 8, 8, 9], prediction = 6, groud truth = 6\n",
      "[6, 5, 3, 3, 5], prediction = 6, groud truth = 6\n",
      "[6, 8, 6, 6, 8], prediction = 6, groud truth = 6\n",
      "[0, 5, 8, 8, 5], prediction = 0, groud truth = 0\n",
      "[7, 3, 6, 6, 3], prediction = 7, groud truth = 7\n",
      "[1, 7, 1, 1, 7], prediction = 1, groud truth = 1\n",
      "[0, 4, 8, 8, 4], prediction = 0, groud truth = 0\n",
      "[0, 4, 4, 4, 4], prediction = 0, groud truth = 0\n",
      "[9, 6, 2, 2, 6], prediction = 9, groud truth = 9\n",
      "[8, 9, 0, 0, 9], prediction = 8, groud truth = 8\n",
      "[0, 9, 3, 3, 9], prediction = 0, groud truth = 0\n",
      "[1, 8, 6, 6, 8], prediction = 1, groud truth = 1\n",
      "[1, 3, 9, 9, 3], prediction = 1, groud truth = 1\n",
      "[2, 1, 9, 9, 1], prediction = 2, groud truth = 2\n",
      "[2, 8, 7, 7, 8], prediction = 2, groud truth = 2\n",
      "[9, 1, 2, 2, 1], prediction = 9, groud truth = 9\n",
      "[6, 5, 9, 9, 5], prediction = 6, groud truth = 6\n",
      "[4, 0, 9, 9, 0], prediction = 4, groud truth = 4\n",
      "[3, 3, 2, 2, 3], prediction = 3, groud truth = 3\n",
      "[4, 1, 8, 8, 1], prediction = 4, groud truth = 4\n",
      "[6, 6, 2, 2, 6], prediction = 6, groud truth = 6\n",
      "[4, 9, 1, 1, 9], prediction = 4, groud truth = 4\n",
      "[5, 6, 1, 1, 6], prediction = 5, groud truth = 5\n",
      "[8, 4, 0, 0, 4], prediction = 8, groud truth = 8\n",
      "[7, 5, 4, 4, 5], prediction = 7, groud truth = 7\n",
      "[9, 9, 4, 4, 9], prediction = 9, groud truth = 9\n",
      "[8, 7, 4, 4, 7], prediction = 8, groud truth = 8\n",
      "[1, 6, 7, 7, 6], prediction = 1, groud truth = 1\n",
      "[0, 4, 8, 8, 4], prediction = 0, groud truth = 0\n",
      "[2, 1, 4, 4, 1], prediction = 2, groud truth = 2\n",
      "[4, 5, 5, 5, 5], prediction = 4, groud truth = 4\n",
      "[2, 2, 4, 4, 2], prediction = 2, groud truth = 2\n",
      "[2, 4, 7, 7, 4], prediction = 2, groud truth = 2\n",
      "[4, 6, 9, 9, 6], prediction = 4, groud truth = 4\n",
      "[5, 3, 7, 7, 3], prediction = 5, groud truth = 5\n",
      "[1, 6, 1, 1, 6], prediction = 1, groud truth = 1\n",
      "[2, 6, 0, 0, 6], prediction = 2, groud truth = 2\n",
      "[2, 5, 4, 4, 5], prediction = 2, groud truth = 2\n",
      "[8, 1, 5, 5, 1], prediction = 8, groud truth = 8\n",
      "[7, 7, 1, 1, 7], prediction = 7, groud truth = 7\n",
      "[2, 3, 3, 3, 3], prediction = 2, groud truth = 2\n",
      "[2, 2, 0, 0, 2], prediction = 2, groud truth = 2\n",
      "[7, 4, 7, 7, 4], prediction = 7, groud truth = 7\n",
      "[6, 4, 1, 1, 4], prediction = 6, groud truth = 6\n",
      "[8, 7, 2, 2, 7], prediction = 8, groud truth = 8\n",
      "[0, 9, 9, 9, 9], prediction = 0, groud truth = 0\n",
      "[3, 6, 1, 1, 6], prediction = 3, groud truth = 3\n",
      "[4, 8, 9, 9, 8], prediction = 4, groud truth = 4\n",
      "[6, 9, 5, 5, 9], prediction = 6, groud truth = 6\n",
      "[6, 8, 8, 8, 8], prediction = 6, groud truth = 6\n",
      "[9, 0, 5, 5, 0], prediction = 9, groud truth = 9\n",
      "[9, 0, 6, 6, 0], prediction = 9, groud truth = 9\n",
      "[3, 4, 3, 3, 4], prediction = 3, groud truth = 3\n",
      "[5, 1, 2, 2, 1], prediction = 5, groud truth = 5\n",
      "[7, 4, 5, 5, 4], prediction = 7, groud truth = 7\n",
      "[7, 2, 4, 4, 2], prediction = 7, groud truth = 7\n",
      "[0, 5, 9, 9, 5], prediction = 0, groud truth = 0\n",
      "[5, 8, 9, 9, 8], prediction = 5, groud truth = 5\n",
      "[5, 1, 7, 7, 1], prediction = 5, groud truth = 5\n",
      "[5, 1, 7, 7, 1], prediction = 5, groud truth = 5\n",
      "[8, 5, 6, 6, 5], prediction = 8, groud truth = 8\n",
      "[9, 4, 7, 7, 4], prediction = 9, groud truth = 9\n",
      "[4, 7, 4, 4, 7], prediction = 4, groud truth = 4\n",
      "[7, 3, 2, 2, 3], prediction = 7, groud truth = 7\n",
      "[9, 0, 5, 5, 0], prediction = 9, groud truth = 9\n",
      "[5, 5, 5, 5, 5], prediction = 5, groud truth = 5\n",
      "[3, 9, 3, 3, 9], prediction = 3, groud truth = 3\n",
      "[1, 4, 8, 8, 4], prediction = 1, groud truth = 1\n",
      "[3, 0, 5, 5, 0], prediction = 3, groud truth = 3\n",
      "[7, 3, 0, 0, 3], prediction = 7, groud truth = 7\n"
     ]
    }
   ],
   "source": [
    "dataset = PalindromeDataset(6)\n",
    "data_loader = DataLoader(dataset, 128)\n",
    "\n",
    "for x, y in data_loader:\n",
    "    x = x.unsqueeze(-1)\n",
    "    preds = model(x.to(\"mps\"))\n",
    "    results = tuple(zip(x, y, preds.argmax(-1)))\n",
    "    \n",
    "    break\n",
    "\n",
    "for x, y, pred in results:\n",
    "    print(f\"{[int(x) for x in x.flatten().tolist()]}, \"\n",
    "        + f\"prediction = {pred.item()}, \"\n",
    "        + f\"groud truth = {y.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is not making that many mistakes, let us now increase $T$.\n",
    "\n",
    "### Question 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.model_type = \"RNN\"\n",
    "        self.input_length = 5 # Sanity Check\n",
    "        self.input_dim = 1\n",
    "        self.num_classes = 10\n",
    "        self.num_hidden = 128\n",
    "        self.batch_size = 128\n",
    "        self.learning_rate = 0.001\n",
    "        self.train_steps = 10000\n",
    "        self.max_norm = 10.0\n",
    "        self.device = \"mps\"\n",
    "\n",
    "config = Config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.model_type = \"RNN\"\n",
    "\n",
    "range_length = range(5, 10)\n",
    "accuracies = []\n",
    "losses = []\n",
    "\n",
    "for t in range_length:\n",
    "    config.input_length = t\n",
    "    \n",
    "    _, accuracy, loss = train(config)\n",
    "    print(accuracy, loss)\n",
    "    accuracies.append(accuracy)\n",
    "    losses.append(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Plotting accuracies and losses\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range_length, accuracies, label='Accuracy')\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy per Training Step')\n",
    "plt.legend()\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range_length, losses, label='Loss', color='orange')\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss per Training Step')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.4\n",
    "\n",
    "#### Momentum\n",
    "With momentum, the update rule incorporates a term for the previous update:\n",
    "\n",
    "$$v_t=\\gamma v_{t-1}+\\eta\\nabla_\\theta J(\\theta)$$\n",
    "\n",
    "$$\\theta=\\theta-v_t$$\n",
    "\n",
    "Here, $v_{t-1}$ is the velocity, $\\gamma$  is the momentum term (typically between 0.8 and 0.9), and $\\eta$ is the learning rate.\n",
    "\n",
    "Thus, Momentum in optimization helps accelerate gradients vectors in the right directions, leading to faster converging.\n",
    "\n",
    "This cause:\n",
    "- *Faster Convergence*: By adding a **fraction of the previous update to the current update**, momentum helps the optimizer gain speed in directions where the gradient consistently points, leading to faster convergence.\n",
    "- *Smoother Updates*: It **reduces oscillations** and provides smoother updates, especially in areas with steep gradients or noise, by dampening the effects of small, inconsistent gradients\n",
    "\n",
    "#### Adaptive Learning Rates\n",
    "\n",
    "With **RMSProp**, we keep a moving average of the squared gradients and scales the learning rate by dividing by the root of this average:\n",
    "\n",
    "$$\\begin{aligned}E[g^2]_t&=\\gamma E[g^2]_{t-1}+(1-\\gamma)g_t^2\\\\theta&=\\theta-\\frac\\eta{\\sqrt{E[g^2]_t+\\epsilon}}g_t\\end{aligned}$$\n",
    "Here, $E[g^2]_t$ is the moving average of squared gradients, $\\gamma$ is the decay term, and $\\epsilon$ is a small constant to prevent division by zero.\n",
    "\n",
    "With **RMSProp**, we combine the benefits of both momentum and RMSProp by computing adaptive learning rates for each parameter:\n",
    "\n",
    "$$\\begin{gathered}\n",
    "\\text{r} n_t=\\beta_1m_{t-1}+(1-\\beta_1)g_t \\\\\n",
    "v_t=\\beta_2v_{t-1}+(1-\\beta_2)g_t^2 \\\\\n",
    "\\hat{m}_t=\\frac{m_t}{1-\\beta_1^t} \\\\\n",
    "\\hat{v}_t=\\frac{v_t}{1-\\beta_2^t} \\\\\n",
    "\\theta=\\theta-\\frac{\\eta\\hat{m}_t}{\\sqrt{\\hat{v}_t}+\\epsilon} \n",
    "\\end{gathered}$$\n",
    "\n",
    "Here, $m_t$ and $v_t$ are the estimates of the first and second moments, respectively, $\\beta_1$ and $\\beta_2$ are decay rates for these moments, and $\\hat{m}_t$ and $\\hat{v}_t$ are bias-corrected estimates.\n",
    "\n",
    "Thus, methods with Adaptive Learning Rates are more efficient and ensure a stable convergence, especially in problems with sparse data or varying gradients.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.5\n",
    "\n",
    "#### a ) Gates explained\n",
    "\n",
    "\n",
    "- **input modulation** gate $g^(t)$: Uses tanh to generate candidate values for updating the cell state, ensuring values are within a manageable range. Responsible for generating new candidate values that could be added to the cell state.\n",
    "\n",
    "Non-linearity due to **tanh**.\n",
    "\n",
    "Good choice because: The tanh function outputs values between -1 and 1, which helps in normalizing the candidate values and ensures that the updates to the cell state are kept within a manageable range. This helps prevent the cell state from growing too large or too small, which could lead to issues such as exploding or vanishing gradients. Thus we do not need to clip the gradients anymore.\n",
    "\n",
    "- **input** gate $i^(t)$: Uses sigmoid to control the extent to which new information updates the cell state. Decides which values we’ll update. What new information we learn.\n",
    "> what new information we’re going to store in the cell state.\n",
    "\n",
    "Non-linearity due to **sigmoid**.\n",
    "\n",
    "Good choice because: The sigmoid function outputs values between 0 and 1, which makes it suitable for gating purposes. This allows the model to determine the extent to which new information should be added to the cell state. By using the sigmoid function, the LSTM can scale the influence of the candidate values on the cell state, effectively controlling the flow of new information into the cell.\n",
    "\n",
    "\n",
    "- **forget** gate $f^(t)$: Uses sigmoid to decide how much of the previous cell state should be retained. Decide what information we’re going to throw away from the cell state.\n",
    "> It looks at $h_{t−1}$ and $x_t$, and outputs a number between 0 and 1 for each number in the cell state $C_{t−1}$. A 1 represents “completely keep this” while a 0 represents “completely get rid of this.”\n",
    "\n",
    "Non-linearity due to **sigmoid**.\n",
    "\n",
    "Good choice because: Same than for input gate but the other way around this time. The sigmoid function is used here because it outputs values between 0 and 1. This allows the model to scale the previous cell state, effectively \"forgetting\" parts of it by multiplying by values close to 0 and \"retaining\" parts of it by multiplying by values close to 1. This selective forgetting is crucial for managing the long-term dependencies and avoiding the issue of vanishing gradients.\n",
    "\n",
    "- and **output** gate $o^(t)$: Uses sigmoid to regulate the information passed to the hidden state, with tanh applied to the cell state for normalization. Decides which values we’ll update.\n",
    "> output will be based on our cell state, but will be a filtered version. [...]   we put the cell state through tanh (to push the values to be between −1 and 1) and multiply it by the output of the sigmoid gate, so that we only output the parts we decided to.\n",
    "\n",
    "Non-linearity due to  **sigmoid** and **tanh**.\n",
    "\n",
    "Good choice because: \n",
    "- **sigmoid** function in the output gate allows the model to decide how much of the cell state should influence the hidden state. The hidden state is the output of the LSTM cell at each time step, and by gating this output, the model can regulate the flow of information to the next layer or next time step.\n",
    "- **tanh** function is applied to the cell state before multiplying it by the output gate. This ensures that the output values are normalized between -1 and 1, which helps in maintaining the stability of the gradients and provides a bounded output range.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b ) Total number of parameters\n",
    "\n",
    "**Weights** for the Gates\n",
    "\n",
    "There is 2 types of gates:\n",
    "- connecting the hidden states of dimension $(n, n)$\n",
    "- connecting the inputs to the gates of dimension $(d, n)$\n",
    "\n",
    "For each we have dimension $n^2 + d\\times n$, thus for all: $4\\times (n^2 + d\\times n)$\n",
    "\n",
    "**Biases**\n",
    "\n",
    "Each gate has its own bias vector, which has dimensions $n$. Thus, $4*n$ biases for all.\n",
    "\n",
    "**Total**\n",
    "\n",
    "$$4 \\times (n^2 + d \\times n + n)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flyboy/Documents/LMU/SoSe 25/GenAI/Exercise9/part1/train.py:101: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), max_norm=config.max_norm)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-28 07:41] Train Step 0000/0050, Batch Size = 128, Examples/Sec = 1915.25, Accuracy = 0.08, Loss = 7.660\n",
      "[2024-06-28 07:41] Train Step 0010/0050, Batch Size = 128, Examples/Sec = 4583.00, Accuracy = 0.25, Loss = 2.851\n",
      "[2024-06-28 07:41] Train Step 0020/0050, Batch Size = 128, Examples/Sec = 4246.56, Accuracy = 0.35, Loss = 1.891\n",
      "[2024-06-28 07:41] Train Step 0030/0050, Batch Size = 128, Examples/Sec = 4168.19, Accuracy = 0.45, Loss = 1.666\n",
      "[2024-06-28 07:41] Train Step 0040/0050, Batch Size = 128, Examples/Sec = 4223.34, Accuracy = 0.52, Loss = 1.449\n",
      "[2024-06-28 07:41] Train Step 0050/0050, Batch Size = 128, Examples/Sec = 3239.69, Accuracy = 0.55, Loss = 1.195\n",
      "Done training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LSTM(), 0.546875, 1.1951243877410889)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.model_type = \"LSTM\"\n",
    "config.input_length = 5 # Sanity Check\n",
    "config.train_steps = 50\n",
    "\n",
    "train(config, verbosity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-28 07:42] Train Step 0000/0050, Batch Size = 128, Examples/Sec = 2349.36, Accuracy = 0.09, Loss = 6.751\n",
      "[2024-06-28 07:42] Train Step 0010/0050, Batch Size = 128, Examples/Sec = 4353.76, Accuracy = 0.26, Loss = 3.044\n",
      "[2024-06-28 07:42] Train Step 0020/0050, Batch Size = 128, Examples/Sec = 4537.10, Accuracy = 0.29, Loss = 2.108\n",
      "[2024-06-28 07:42] Train Step 0030/0050, Batch Size = 128, Examples/Sec = 4618.44, Accuracy = 0.40, Loss = 1.753\n",
      "[2024-06-28 07:42] Train Step 0040/0050, Batch Size = 128, Examples/Sec = 4134.26, Accuracy = 0.45, Loss = 1.571\n",
      "[2024-06-28 07:42] Train Step 0050/0050, Batch Size = 128, Examples/Sec = 4655.61, Accuracy = 0.45, Loss = 1.513\n",
      "Done training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LSTM(), 0.4453125, 1.5130856037139893)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.model_type = \"LSTM\"\n",
    "config.input_length = 5 # Sanity Check\n",
    "config.train_steps = 50\n",
    "\n",
    "train(config, verbosity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training.\n",
      "1.0 7.105978170329763e-07\n",
      "Done training.\n",
      "1.0 5.794614025944611e-06\n",
      "Done training.\n",
      "1.0 0.00011121592251583934\n",
      "Done training.\n",
      "1.0 0.0024377526715397835\n",
      "Done training.\n",
      "1.0 0.0003996348532382399\n"
     ]
    }
   ],
   "source": [
    "config.model_type = \"LSTM\"\n",
    "config.train_steps = 10000\n",
    "\n",
    "range_length = range(5, 10)\n",
    "accuracies = []\n",
    "losses = []\n",
    "\n",
    "for t in range_length:\n",
    "    config.input_length = t\n",
    "    \n",
    "    _, accuracy, loss = train(config)\n",
    "    print(accuracy, loss)\n",
    "    accuracies.append(accuracy)\n",
    "    losses.append(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Plotting accuracies and losses\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range_length, accuracies, label='Accuracy')\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy per Training Step')\n",
    "plt.legend()\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range_length, losses, label='Loss', color='orange')\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss per Training Step')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can attest by the graph above that the LSTM is performing much better in retaining long term dependencies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
