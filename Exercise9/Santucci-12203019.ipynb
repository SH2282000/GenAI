{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9\n",
    "\n",
    "## Task 1: Toy Problem: Palindrome Numbers\n",
    "\n",
    "- $W_{hx}$ denotes the **input-to-hidden** weight matrix,\n",
    "- $W_{hh}$ is the **hidden-to-hidden** (or recurrent) weight matrix,\n",
    "- $W_{ph}$ represents the **hidden-to-output** weight matrix and the $b_h$ and $b_p$ vectors denote the biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from part1.dataset import PalindromeDataset\n",
    "from part1.train import train\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flyboy/Documents/LMU/SoSe 25/GenAI/Exercise9/part1/train.py:100: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), max_norm=config.max_norm)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-26 14:52] Train Step 0000/1000, Batch Size = 128, Examples/Sec = 525.45, Accuracy = 0.06, Loss = 19.993\n",
      "[2024-06-26 14:52] Train Step 0010/1000, Batch Size = 128, Examples/Sec = 13550.84, Accuracy = 0.12, Loss = 11.047\n",
      "[2024-06-26 14:52] Train Step 0020/1000, Batch Size = 128, Examples/Sec = 11950.65, Accuracy = 0.20, Loss = 8.412\n",
      "[2024-06-26 14:52] Train Step 0030/1000, Batch Size = 128, Examples/Sec = 14120.38, Accuracy = 0.19, Loss = 7.071\n",
      "[2024-06-26 14:52] Train Step 0040/1000, Batch Size = 128, Examples/Sec = 14802.47, Accuracy = 0.22, Loss = 7.614\n",
      "[2024-06-26 14:52] Train Step 0050/1000, Batch Size = 128, Examples/Sec = 14578.19, Accuracy = 0.21, Loss = 6.062\n",
      "[2024-06-26 14:52] Train Step 0060/1000, Batch Size = 128, Examples/Sec = 14838.89, Accuracy = 0.26, Loss = 6.605\n",
      "[2024-06-26 14:52] Train Step 0070/1000, Batch Size = 128, Examples/Sec = 14800.84, Accuracy = 0.26, Loss = 5.809\n",
      "[2024-06-26 14:52] Train Step 0080/1000, Batch Size = 128, Examples/Sec = 14030.34, Accuracy = 0.36, Loss = 4.880\n",
      "[2024-06-26 14:52] Train Step 0090/1000, Batch Size = 128, Examples/Sec = 14741.51, Accuracy = 0.23, Loss = 4.483\n",
      "[2024-06-26 14:52] Train Step 0100/1000, Batch Size = 128, Examples/Sec = 14651.79, Accuracy = 0.27, Loss = 4.896\n",
      "[2024-06-26 14:52] Train Step 0110/1000, Batch Size = 128, Examples/Sec = 14386.77, Accuracy = 0.34, Loss = 4.390\n",
      "[2024-06-26 14:52] Train Step 0120/1000, Batch Size = 128, Examples/Sec = 13537.86, Accuracy = 0.35, Loss = 3.722\n",
      "[2024-06-26 14:52] Train Step 0130/1000, Batch Size = 128, Examples/Sec = 15467.77, Accuracy = 0.35, Loss = 3.982\n",
      "[2024-06-26 14:52] Train Step 0140/1000, Batch Size = 128, Examples/Sec = 15019.89, Accuracy = 0.38, Loss = 3.398\n",
      "[2024-06-26 14:52] Train Step 0150/1000, Batch Size = 128, Examples/Sec = 14483.02, Accuracy = 0.42, Loss = 3.220\n",
      "[2024-06-26 14:52] Train Step 0160/1000, Batch Size = 128, Examples/Sec = 13415.74, Accuracy = 0.48, Loss = 2.324\n",
      "[2024-06-26 14:52] Train Step 0170/1000, Batch Size = 128, Examples/Sec = 14556.84, Accuracy = 0.39, Loss = 3.305\n",
      "[2024-06-26 14:52] Train Step 0180/1000, Batch Size = 128, Examples/Sec = 14850.79, Accuracy = 0.59, Loss = 2.638\n",
      "[2024-06-26 14:52] Train Step 0190/1000, Batch Size = 128, Examples/Sec = 14670.61, Accuracy = 0.45, Loss = 2.931\n",
      "[2024-06-26 14:52] Train Step 0200/1000, Batch Size = 128, Examples/Sec = 13041.29, Accuracy = 0.46, Loss = 2.776\n",
      "[2024-06-26 14:52] Train Step 0210/1000, Batch Size = 128, Examples/Sec = 15126.53, Accuracy = 0.43, Loss = 3.135\n",
      "[2024-06-26 14:52] Train Step 0220/1000, Batch Size = 128, Examples/Sec = 13612.69, Accuracy = 0.45, Loss = 2.916\n",
      "[2024-06-26 14:52] Train Step 0230/1000, Batch Size = 128, Examples/Sec = 14787.39, Accuracy = 0.48, Loss = 2.358\n",
      "[2024-06-26 14:52] Train Step 0240/1000, Batch Size = 128, Examples/Sec = 14845.86, Accuracy = 0.42, Loss = 2.346\n",
      "[2024-06-26 14:52] Train Step 0250/1000, Batch Size = 128, Examples/Sec = 14601.98, Accuracy = 0.43, Loss = 2.993\n",
      "[2024-06-26 14:52] Train Step 0260/1000, Batch Size = 128, Examples/Sec = 13159.25, Accuracy = 0.42, Loss = 2.920\n",
      "[2024-06-26 14:52] Train Step 0270/1000, Batch Size = 128, Examples/Sec = 14067.47, Accuracy = 0.49, Loss = 2.462\n",
      "[2024-06-26 14:52] Train Step 0280/1000, Batch Size = 128, Examples/Sec = 11498.13, Accuracy = 0.44, Loss = 2.358\n",
      "[2024-06-26 14:52] Train Step 0290/1000, Batch Size = 128, Examples/Sec = 11218.23, Accuracy = 0.48, Loss = 2.245\n",
      "[2024-06-26 14:52] Train Step 0300/1000, Batch Size = 128, Examples/Sec = 10312.74, Accuracy = 0.47, Loss = 2.509\n",
      "[2024-06-26 14:52] Train Step 0310/1000, Batch Size = 128, Examples/Sec = 13362.98, Accuracy = 0.49, Loss = 2.201\n",
      "[2024-06-26 14:52] Train Step 0320/1000, Batch Size = 128, Examples/Sec = 13812.67, Accuracy = 0.52, Loss = 1.955\n",
      "[2024-06-26 14:52] Train Step 0330/1000, Batch Size = 128, Examples/Sec = 14081.12, Accuracy = 0.45, Loss = 2.136\n",
      "[2024-06-26 14:52] Train Step 0340/1000, Batch Size = 128, Examples/Sec = 14148.66, Accuracy = 0.52, Loss = 2.384\n",
      "[2024-06-26 14:52] Train Step 0350/1000, Batch Size = 128, Examples/Sec = 14313.12, Accuracy = 0.53, Loss = 2.058\n",
      "[2024-06-26 14:52] Train Step 0360/1000, Batch Size = 128, Examples/Sec = 14035.11, Accuracy = 0.52, Loss = 2.292\n",
      "[2024-06-26 14:52] Train Step 0370/1000, Batch Size = 128, Examples/Sec = 14623.85, Accuracy = 0.47, Loss = 2.282\n",
      "[2024-06-26 14:52] Train Step 0380/1000, Batch Size = 128, Examples/Sec = 14570.67, Accuracy = 0.56, Loss = 2.000\n",
      "[2024-06-26 14:52] Train Step 0390/1000, Batch Size = 128, Examples/Sec = 14022.28, Accuracy = 0.56, Loss = 2.121\n",
      "[2024-06-26 14:52] Train Step 0400/1000, Batch Size = 128, Examples/Sec = 14601.98, Accuracy = 0.52, Loss = 1.967\n",
      "[2024-06-26 14:52] Train Step 0410/1000, Batch Size = 128, Examples/Sec = 14615.10, Accuracy = 0.46, Loss = 2.119\n",
      "[2024-06-26 14:52] Train Step 0420/1000, Batch Size = 128, Examples/Sec = 14442.11, Accuracy = 0.58, Loss = 1.760\n",
      "[2024-06-26 14:52] Train Step 0430/1000, Batch Size = 128, Examples/Sec = 13965.01, Accuracy = 0.51, Loss = 2.042\n",
      "[2024-06-26 14:52] Train Step 0440/1000, Batch Size = 128, Examples/Sec = 14212.71, Accuracy = 0.52, Loss = 1.907\n",
      "[2024-06-26 14:52] Train Step 0450/1000, Batch Size = 128, Examples/Sec = 12922.64, Accuracy = 0.54, Loss = 1.603\n",
      "[2024-06-26 14:52] Train Step 0460/1000, Batch Size = 128, Examples/Sec = 13478.04, Accuracy = 0.56, Loss = 1.989\n",
      "[2024-06-26 14:52] Train Step 0470/1000, Batch Size = 128, Examples/Sec = 13047.95, Accuracy = 0.61, Loss = 1.485\n",
      "[2024-06-26 14:52] Train Step 0480/1000, Batch Size = 128, Examples/Sec = 14142.32, Accuracy = 0.54, Loss = 1.697\n",
      "[2024-06-26 14:52] Train Step 0490/1000, Batch Size = 128, Examples/Sec = 12988.60, Accuracy = 0.60, Loss = 1.636\n",
      "[2024-06-26 14:52] Train Step 0500/1000, Batch Size = 128, Examples/Sec = 14650.59, Accuracy = 0.54, Loss = 1.622\n",
      "[2024-06-26 14:52] Train Step 0510/1000, Batch Size = 128, Examples/Sec = 14469.74, Accuracy = 0.52, Loss = 1.988\n",
      "[2024-06-26 14:52] Train Step 0520/1000, Batch Size = 128, Examples/Sec = 12750.16, Accuracy = 0.53, Loss = 1.736\n",
      "[2024-06-26 14:52] Train Step 0530/1000, Batch Size = 128, Examples/Sec = 14333.76, Accuracy = 0.63, Loss = 1.393\n",
      "[2024-06-26 14:52] Train Step 0540/1000, Batch Size = 128, Examples/Sec = 13903.89, Accuracy = 0.64, Loss = 1.320\n",
      "[2024-06-26 14:52] Train Step 0550/1000, Batch Size = 128, Examples/Sec = 14476.38, Accuracy = 0.66, Loss = 1.336\n",
      "[2024-06-26 14:52] Train Step 0560/1000, Batch Size = 128, Examples/Sec = 13813.74, Accuracy = 0.59, Loss = 1.569\n",
      "[2024-06-26 14:52] Train Step 0570/1000, Batch Size = 128, Examples/Sec = 14567.11, Accuracy = 0.60, Loss = 1.443\n",
      "[2024-06-26 14:52] Train Step 0580/1000, Batch Size = 128, Examples/Sec = 14344.86, Accuracy = 0.66, Loss = 1.311\n",
      "[2024-06-26 14:52] Train Step 0590/1000, Batch Size = 128, Examples/Sec = 12998.67, Accuracy = 0.54, Loss = 2.201\n",
      "[2024-06-26 14:52] Train Step 0600/1000, Batch Size = 128, Examples/Sec = 13925.17, Accuracy = 0.58, Loss = 1.597\n",
      "[2024-06-26 14:52] Train Step 0610/1000, Batch Size = 128, Examples/Sec = 14482.63, Accuracy = 0.64, Loss = 1.265\n",
      "[2024-06-26 14:52] Train Step 0620/1000, Batch Size = 128, Examples/Sec = 13152.80, Accuracy = 0.52, Loss = 1.743\n",
      "[2024-06-26 14:52] Train Step 0630/1000, Batch Size = 128, Examples/Sec = 14918.47, Accuracy = 0.55, Loss = 1.617\n",
      "[2024-06-26 14:52] Train Step 0640/1000, Batch Size = 128, Examples/Sec = 15236.43, Accuracy = 0.62, Loss = 1.177\n",
      "[2024-06-26 14:52] Train Step 0650/1000, Batch Size = 128, Examples/Sec = 14580.17, Accuracy = 0.65, Loss = 1.195\n",
      "[2024-06-26 14:52] Train Step 0660/1000, Batch Size = 128, Examples/Sec = 13570.71, Accuracy = 0.61, Loss = 1.651\n",
      "[2024-06-26 14:52] Train Step 0670/1000, Batch Size = 128, Examples/Sec = 13986.11, Accuracy = 0.64, Loss = 1.263\n",
      "[2024-06-26 14:52] Train Step 0680/1000, Batch Size = 128, Examples/Sec = 13732.47, Accuracy = 0.59, Loss = 1.209\n",
      "[2024-06-26 14:52] Train Step 0690/1000, Batch Size = 128, Examples/Sec = 13816.94, Accuracy = 0.59, Loss = 1.484\n",
      "[2024-06-26 14:52] Train Step 0700/1000, Batch Size = 128, Examples/Sec = 14495.53, Accuracy = 0.67, Loss = 1.299\n",
      "[2024-06-26 14:52] Train Step 0710/1000, Batch Size = 128, Examples/Sec = 14889.09, Accuracy = 0.62, Loss = 1.432\n",
      "[2024-06-26 14:52] Train Step 0720/1000, Batch Size = 128, Examples/Sec = 13872.27, Accuracy = 0.61, Loss = 1.206\n",
      "[2024-06-26 14:52] Train Step 0730/1000, Batch Size = 128, Examples/Sec = 13505.17, Accuracy = 0.65, Loss = 1.239\n",
      "[2024-06-26 14:52] Train Step 0740/1000, Batch Size = 128, Examples/Sec = 14641.80, Accuracy = 0.63, Loss = 1.433\n",
      "[2024-06-26 14:52] Train Step 0750/1000, Batch Size = 128, Examples/Sec = 15401.21, Accuracy = 0.62, Loss = 1.038\n",
      "[2024-06-26 14:52] Train Step 0760/1000, Batch Size = 128, Examples/Sec = 12503.40, Accuracy = 0.68, Loss = 1.030\n",
      "[2024-06-26 14:52] Train Step 0770/1000, Batch Size = 128, Examples/Sec = 13118.73, Accuracy = 0.68, Loss = 1.021\n",
      "[2024-06-26 14:52] Train Step 0780/1000, Batch Size = 128, Examples/Sec = 12274.70, Accuracy = 0.70, Loss = 1.002\n",
      "[2024-06-26 14:52] Train Step 0790/1000, Batch Size = 128, Examples/Sec = 7419.55, Accuracy = 0.70, Loss = 0.897\n",
      "[2024-06-26 14:52] Train Step 0800/1000, Batch Size = 128, Examples/Sec = 12559.85, Accuracy = 0.66, Loss = 0.980\n",
      "[2024-06-26 14:52] Train Step 0810/1000, Batch Size = 128, Examples/Sec = 12331.37, Accuracy = 0.57, Loss = 1.562\n",
      "[2024-06-26 14:52] Train Step 0820/1000, Batch Size = 128, Examples/Sec = 10538.45, Accuracy = 0.63, Loss = 1.456\n",
      "[2024-06-26 14:52] Train Step 0830/1000, Batch Size = 128, Examples/Sec = 12264.33, Accuracy = 0.62, Loss = 1.145\n",
      "[2024-06-26 14:52] Train Step 0840/1000, Batch Size = 128, Examples/Sec = 12482.76, Accuracy = 0.70, Loss = 1.068\n",
      "[2024-06-26 14:52] Train Step 0850/1000, Batch Size = 128, Examples/Sec = 12009.73, Accuracy = 0.66, Loss = 1.185\n",
      "[2024-06-26 14:52] Train Step 0860/1000, Batch Size = 128, Examples/Sec = 13632.05, Accuracy = 0.67, Loss = 1.147\n",
      "[2024-06-26 14:52] Train Step 0870/1000, Batch Size = 128, Examples/Sec = 12599.94, Accuracy = 0.73, Loss = 0.820\n",
      "[2024-06-26 14:52] Train Step 0880/1000, Batch Size = 128, Examples/Sec = 11501.58, Accuracy = 0.60, Loss = 1.398\n",
      "[2024-06-26 14:52] Train Step 0890/1000, Batch Size = 128, Examples/Sec = 12772.00, Accuracy = 0.71, Loss = 1.026\n",
      "[2024-06-26 14:52] Train Step 0900/1000, Batch Size = 128, Examples/Sec = 12733.83, Accuracy = 0.67, Loss = 0.895\n",
      "[2024-06-26 14:52] Train Step 0910/1000, Batch Size = 128, Examples/Sec = 13394.65, Accuracy = 0.62, Loss = 1.298\n",
      "[2024-06-26 14:52] Train Step 0920/1000, Batch Size = 128, Examples/Sec = 11985.33, Accuracy = 0.61, Loss = 1.172\n",
      "[2024-06-26 14:52] Train Step 0930/1000, Batch Size = 128, Examples/Sec = 14556.84, Accuracy = 0.63, Loss = 1.000\n",
      "[2024-06-26 14:52] Train Step 0940/1000, Batch Size = 128, Examples/Sec = 14550.14, Accuracy = 0.66, Loss = 1.257\n",
      "[2024-06-26 14:52] Train Step 0950/1000, Batch Size = 128, Examples/Sec = 14568.69, Accuracy = 0.69, Loss = 0.848\n",
      "[2024-06-26 14:52] Train Step 0960/1000, Batch Size = 128, Examples/Sec = 9485.85, Accuracy = 0.73, Loss = 0.902\n",
      "[2024-06-26 14:52] Train Step 0970/1000, Batch Size = 128, Examples/Sec = 11382.82, Accuracy = 0.66, Loss = 1.214\n",
      "[2024-06-26 14:52] Train Step 0980/1000, Batch Size = 128, Examples/Sec = 8210.29, Accuracy = 0.73, Loss = 0.965\n",
      "[2024-06-26 14:53] Train Step 0990/1000, Batch Size = 128, Examples/Sec = 12878.62, Accuracy = 0.68, Loss = 0.916\n",
      "[2024-06-26 14:53] Train Step 1000/1000, Batch Size = 128, Examples/Sec = 8592.27, Accuracy = 0.73, Loss = 0.944\n",
      "Done training.\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.model_type = \"RNN\"\n",
    "        self.input_length = 5\n",
    "        self.input_dim = 1\n",
    "        self.num_classes = 10\n",
    "        self.num_hidden = 128\n",
    "        self.batch_size = 128\n",
    "        self.learning_rate = 0.001\n",
    "        self.train_steps = 1000\n",
    "        self.max_norm = 10.0\n",
    "        self.device = \"mps\"\n",
    "\n",
    "config = Config()\n",
    "\n",
    "config.model_type = \"RNN\"\n",
    "\n",
    "model = train(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's 128 examples to make sure it actually worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Expected input size (128, 5, 1), got torch.Size([10, 5, 1])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m data_loader:\n\u001b[1;32m      5\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mzip\u001b[39m(x, y, preds\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/LMU/SoSe 25/GenAI/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/LMU/SoSe 25/GenAI/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/LMU/SoSe 25/GenAI/Exercise9/part1/vanilla_rnn.py:55\u001b[0m, in \u001b[0;36mVanillaRNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 55\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m x\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m==\u001b[39m (\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_length,\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_dim,\n\u001b[1;32m     59\u001b[0m     ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected input size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m), got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# Initialize hidden state\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     h_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_hidden)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Expected input size (128, 5, 1), got torch.Size([10, 5, 1])"
     ]
    }
   ],
   "source": [
    "dataset = PalindromeDataset(6)\n",
    "data_loader = DataLoader(dataset, 10)\n",
    "\n",
    "for x, y in data_loader:\n",
    "    x = x.unsqueeze(-1)\n",
    "    preds = model(x.to(\"mps\"))\n",
    "    results = tuple(zip(x, y, preds.argmax(-1)))\n",
    "    \n",
    "    break\n",
    "\n",
    "for x, y, pred in results:\n",
    "    print(f\"{[int(x) for x in x.flatten().tolist()]}, \"\n",
    "        + f\"prediction = {pred.item()}, \"\n",
    "        + f\"groud truth = {y.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is not making that many mistakes, let us now increase $T$.\n",
    "\n",
    "### Question 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flyboy/Documents/LMU/SoSe 25/GenAI/Exercise9/part1/train.py:100: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), max_norm=config.max_norm)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-26 14:39] Train Step 0000/1000, Batch Size = 128, Examples/Sec = 2468.56, Accuracy = 0.15, Loss = 18.271\n",
      "[2024-06-26 14:39] Train Step 0010/1000, Batch Size = 128, Examples/Sec = 13171.51, Accuracy = 0.20, Loss = 9.508\n",
      "[2024-06-26 14:39] Train Step 0020/1000, Batch Size = 128, Examples/Sec = 12645.65, Accuracy = 0.23, Loss = 7.229\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.model_type = \"RNN\"\n",
    "        self.input_length = 5\n",
    "        self.input_dim = 1\n",
    "        self.num_classes = 10\n",
    "        self.num_hidden = 128\n",
    "        self.batch_size = 128\n",
    "        self.learning_rate = 0.001\n",
    "        self.train_steps = 1000\n",
    "        self.max_norm = 10.0\n",
    "        self.device = \"mps\"\n",
    "\n",
    "config = Config()\n",
    "\n",
    "config.model_type = \"RNN\"\n",
    "\n",
    "model = train(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
